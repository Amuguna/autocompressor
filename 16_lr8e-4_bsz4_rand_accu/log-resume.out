Traceback (most recent call last):
  File "/home/jyjang/prompt_compression/AutoCompressors/train.py", line 17, in <module>
    from transformers.utils import check_min_version, send_example_telemetry
ImportError: cannot import name 'send_example_telemetry' from 'transformers.utils' (/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/transformers/utils/__init__.py)
E0104 20:33:02.345000 140365089252416 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 413202) of binary: /home/jyjang/anaconda3/envs/prompt/bin/python3.10
Traceback (most recent call last):
  File "/home/jyjang/anaconda3/envs/prompt/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-04_20:33:02
  host      : thor2
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 413202)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/home/jyjang/prompt_compression/AutoCompressors/train.py", line 21, in <module>
    from substep_trainer import SubstepTrainer
  File "/home/jyjang/prompt_compression/AutoCompressors/substep_trainer.py", line 4, in <module>
    from base_trainer import BaseTrainer
  File "/home/jyjang/prompt_compression/AutoCompressors/base_trainer.py", line 38, in <module>
    from transformers.utils import (
ImportError: cannot import name 'is_torch_tpu_available' from 'transformers.utils' (/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/transformers/utils/__init__.py)
E0104 20:38:53.116000 140634171769920 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 414644) of binary: /home/jyjang/anaconda3/envs/prompt/bin/python3.10
Traceback (most recent call last):
  File "/home/jyjang/anaconda3/envs/prompt/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-04_20:38:53
  host      : thor2
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 414644)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/home/jyjang/prompt_compression/AutoCompressors/train.py", line 21, in <module>
    from substep_trainer import SubstepTrainer
  File "/home/jyjang/prompt_compression/AutoCompressors/substep_trainer.py", line 4, in <module>
    from base_trainer import BaseTrainer
  File "/home/jyjang/prompt_compression/AutoCompressors/base_trainer.py", line 38, in <module>
    from transformers.utils import (
ImportError: cannot import name 'is_torch_tpu_available' from 'transformers.utils' (/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/transformers/utils/__init__.py)
E0104 20:39:47.764000 139759272031296 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 414805) of binary: /home/jyjang/anaconda3/envs/prompt/bin/python3.10
Traceback (most recent call last):
  File "/home/jyjang/anaconda3/envs/prompt/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-04_20:39:47
  host      : thor2
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 414805)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/home/jyjang/prompt_compression/AutoCompressors/train.py", line 21, in <module>
    from substep_trainer import SubstepTrainer
  File "/home/jyjang/prompt_compression/AutoCompressors/substep_trainer.py", line 4, in <module>
    from base_trainer import BaseTrainer
  File "/home/jyjang/prompt_compression/AutoCompressors/base_trainer.py", line 43, in <module>
    from transformers.utils.import_utils import is_torch_tpu_available
ImportError: cannot import name 'is_torch_tpu_available' from 'transformers.utils.import_utils' (/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/transformers/utils/import_utils.py)
E0104 20:41:47.643000 140563513218112 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 415803) of binary: /home/jyjang/anaconda3/envs/prompt/bin/python3.10
Traceback (most recent call last):
  File "/home/jyjang/anaconda3/envs/prompt/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-04_20:41:47
  host      : thor2
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 415803)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/home/jyjang/prompt_compression/AutoCompressors/train.py", line 21, in <module>
    from substep_trainer import SubstepTrainer
  File "/home/jyjang/prompt_compression/AutoCompressors/substep_trainer.py", line 4, in <module>
    from base_trainer import BaseTrainer
  File "/home/jyjang/prompt_compression/AutoCompressors/base_trainer.py", line 56, in <module>
    from transformers.deepspeed import deepspeed_init, is_deepspeed_zero3_enabled
ModuleNotFoundError: No module named 'transformers.deepspeed'
E0104 20:43:19.808000 140548594459712 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 416339) of binary: /home/jyjang/anaconda3/envs/prompt/bin/python3.10
Traceback (most recent call last):
  File "/home/jyjang/anaconda3/envs/prompt/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/jyjang/anaconda3/envs/prompt/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-04_20:43:19
  host      : thor2
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 416339)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/home/work/prompt/dpc/autocompressor/train.py", line 21, in <module>
    from substep_trainer import SubstepTrainer
  File "/home/work/prompt/dpc/autocompressor/substep_trainer.py", line 4, in <module>
    from base_trainer import BaseTrainer
  File "/home/work/prompt/dpc/autocompressor/base_trainer.py", line 56, in <module>
    from transformers.deepspeed import deepspeed_init, is_deepspeed_zero3_enabled
ModuleNotFoundError: No module named 'transformers.deepspeed'
[2026-01-05 14:16:49,077] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2290914) of binary: /home/work/.conda/envs/prompt4/bin/python3.10
Traceback (most recent call last):
  File "/home/work/.conda/envs/prompt4/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-05_14:16:49
  host      : main1
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2290914)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/home/work/prompt/dpc/autocompressor/train.py", line 21, in <module>
    from substep_trainer import SubstepTrainer
  File "/home/work/prompt/dpc/autocompressor/substep_trainer.py", line 4, in <module>
    from base_trainer import BaseTrainer
  File "/home/work/prompt/dpc/autocompressor/base_trainer.py", line 56, in <module>
    from transformers.deepspeed import deepspeed_init, is_deepspeed_zero3_enabled
ModuleNotFoundError: No module named 'transformers.deepspeed'
[2026-01-05 14:18:24,150] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2291873) of binary: /home/work/.conda/envs/prompt4/bin/python3.10
Traceback (most recent call last):
  File "/home/work/.conda/envs/prompt4/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-05_14:18:24
  host      : main1
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2291873)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/home/work/prompt/dpc/autocompressor/train.py", line 286, in <module>
    main()
  File "/home/work/prompt/dpc/autocompressor/train.py", line 47, in main
    model_args, data_args, training_args = parser.parse_args_into_dataclasses()
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/transformers/hf_argparser.py", line 354, in parse_args_into_dataclasses
    raise ValueError(f"Some specified arguments are not used by the HfArgumentParser: {remaining_args}")
ValueError: Some specified arguments are not used by the HfArgumentParser: ['Qwen/Qwen2.5-7B-Instruct', 'Qwen/Qwen2.5-7B-Instruct', 'Qwen/Qwen2.5-7B-Instruct', '8', '16_lr8e-4_bsz4_rand_accu', '8', '16_lr8e-4_bsz4_rand_accu', '8', '16']
[2026-01-05 14:24:17,127] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2295013) of binary: /home/work/.conda/envs/prompt4/bin/python3.10
Traceback (most recent call last):
  File "/home/work/.conda/envs/prompt4/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-05_14:24:17
  host      : main1
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2295013)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Ignoring unused CLI arguments: ['Qwen/Qwen2.5-7B-Instruct', 'Qwen/Qwen2.5-7B-Instruct', 'Qwen/Qwen2.5-7B-Instruct', '8', '16_lr8e-4_bsz4_rand_accu', '8', '16_lr8e-4_bsz4_rand_accu', '8', '16']
01/05/2026 14:28:33 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
01/05/2026 14:28:33 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
accumulate_summary=True,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=6,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=True,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
fast_attention=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=2,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0008,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=checkpoints/ac_Qwen2.5-7B-Instruct_sub2_seg2_sum4/runs/Jan05_14-28-33_main1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_position_embeddings=None,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=checkpoints/ac_Qwen2.5-7B-Instruct_sub2_seg2_sum4,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=2,
per_device_train_batch_size=2,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
randomize_substeps=True,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=true,
run_name=ac_Qwen2.5-7B-Instruct_sub2_seg2_sum4,
save_logits=False,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=5000,
save_strategy=steps,
save_total_limit=None,
seed=42,
segment_gradient_checkpointing=False,
segment_lengths=[],
segments_per_substep=2,
skip_memory_metrics=True,
summary_length=4,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
train_data_index=None,
train_data_percentage=1.0,
training_substeps=2,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=5000,
weight_decay=0.0,
)
Traceback (most recent call last):
  File "/home/work/prompt/dpc/autocompressor/train.py", line 291, in <module>
    main()
  File "/home/work/prompt/dpc/autocompressor/train.py", line 88, in main
    lm_datasets = preprocess_datasets(raw_datasets, tokenizer, data_args, training_args)
UnboundLocalError: local variable 'tokenizer' referenced before assignment
[2026-01-05 14:28:37,462] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2296837) of binary: /home/work/.conda/envs/prompt4/bin/python3.10
Traceback (most recent call last):
  File "/home/work/.conda/envs/prompt4/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-05_14:28:37
  host      : main1
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2296837)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Ignoring unused CLI arguments: ['Qwen/Qwen2.5-7B-Instruct', 'Qwen/Qwen2.5-7B-Instruct', 'Qwen/Qwen2.5-7B-Instruct', '8', '16_lr8e-4_bsz4_rand_accu', '8', '16_lr8e-4_bsz4_rand_accu', '8', '16']
01/05/2026 14:30:42 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
01/05/2026 14:30:42 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
accumulate_summary=True,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=6,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=True,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
fast_attention=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=2,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0008,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=checkpoints/ac_Qwen2.5-7B-Instruct_sub2_seg2_sum4/runs/Jan05_14-30-42_main1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_position_embeddings=None,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=checkpoints/ac_Qwen2.5-7B-Instruct_sub2_seg2_sum4,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=2,
per_device_train_batch_size=2,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
randomize_substeps=True,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=true,
run_name=ac_Qwen2.5-7B-Instruct_sub2_seg2_sum4,
save_logits=False,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=5000,
save_strategy=steps,
save_total_limit=None,
seed=42,
segment_gradient_checkpointing=False,
segment_lengths=[],
segments_per_substep=2,
skip_memory_metrics=True,
summary_length=4,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
train_data_index=None,
train_data_percentage=1.0,
training_substeps=2,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=5000,
weight_decay=0.0,
)
[INFO|tokenization_auto.py:922] 2026-01-05 14:30:42,477 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
Traceback (most recent call last):
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1010, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1117, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1658, in _raise_on_head_call_error
    raise head_call_error
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1546, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1463, in get_hf_file_metadata
    r = _request_wrapper(
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 286, in _request_wrapper
    response = _request_wrapper(
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 310, in _request_wrapper
    hf_raise_for_status(response)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 426, in hf_raise_for_status
    raise _format(GatedRepoError, message, response) from e
huggingface_hub.errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-695b4c82-183985ab72147c110db58bd6;4d1cfd87-9e2e-4b2c-893e-d323b324c91b)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/work/prompt/dpc/autocompressor/train.py", line 292, in <module>
    main()
  File "/home/work/prompt/dpc/autocompressor/train.py", line 86, in main
    tokenizer = AutoTokenizer.from_pretrained(model_args.tokenizer_name, **tokenizer_kwargs)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 1093, in from_pretrained
    config = AutoConfig.from_pretrained(
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1332, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/transformers/configuration_utils.py", line 662, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/transformers/configuration_utils.py", line 721, in _get_config_dict
    resolved_config_file = cached_file(
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/transformers/utils/hub.py", line 543, in cached_files
    raise OSError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-695b4c82-183985ab72147c110db58bd6;4d1cfd87-9e2e-4b2c-893e-d323b324c91b)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
[2026-01-05 14:30:45,857] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2298472) of binary: /home/work/.conda/envs/prompt4/bin/python3.10
Traceback (most recent call last):
  File "/home/work/.conda/envs/prompt4/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-05_14:30:45
  host      : main1
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2298472)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Ignoring unused CLI arguments: ['8', '16_lr8e-4_bsz4_rand_accu', '8', '16_lr8e-4_bsz4_rand_accu', '8', '16']
01/05/2026 14:31:22 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
01/05/2026 14:31:22 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
accumulate_summary=True,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=6,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=True,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
fast_attention=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=2,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0008,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=checkpoints/ac_Llama-3.1-8B-Instruct_sub2_seg2_sum4/runs/Jan05_14-31-22_main1,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_position_embeddings=None,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=checkpoints/ac_Llama-3.1-8B-Instruct_sub2_seg2_sum4,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=2,
per_device_train_batch_size=2,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
randomize_substeps=True,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=true,
run_name=ac_Llama-3.1-8B-Instruct_sub2_seg2_sum4,
save_logits=False,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=5000,
save_strategy=steps,
save_total_limit=None,
seed=42,
segment_gradient_checkpointing=False,
segment_lengths=[],
segments_per_substep=2,
skip_memory_metrics=True,
summary_length=4,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
train_data_index=None,
train_data_percentage=1.0,
training_substeps=2,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=5000,
weight_decay=0.0,
)
[INFO|tokenization_utils_base.py:2093] 2026-01-05 14:31:22,558 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2093] 2026-01-05 14:31:22,558 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2093] 2026-01-05 14:31:22,558 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2093] 2026-01-05 14:31:22,558 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2093] 2026-01-05 14:31:22,558 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2093] 2026-01-05 14:31:22,558 >> loading file chat_template.jinja
[INFO|tokenization_utils_base.py:2364] 2026-01-05 14:31:22,985 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Removing special tokens in tokenization
Process #0 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00000_of_00006.arrow
01/05/2026 14:31:23 - INFO - datasets.arrow_dataset - Process #0 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00000_of_00006.arrow
Process #1 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00001_of_00006.arrow
01/05/2026 14:31:23 - INFO - datasets.arrow_dataset - Process #1 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00001_of_00006.arrow
Process #2 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00002_of_00006.arrow
01/05/2026 14:31:23 - INFO - datasets.arrow_dataset - Process #2 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00002_of_00006.arrow
Process #3 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00003_of_00006.arrow
01/05/2026 14:31:23 - INFO - datasets.arrow_dataset - Process #3 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00003_of_00006.arrow
Process #4 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00004_of_00006.arrow
01/05/2026 14:31:23 - INFO - datasets.arrow_dataset - Process #4 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00004_of_00006.arrow
Process #5 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00005_of_00006.arrow
01/05/2026 14:31:23 - INFO - datasets.arrow_dataset - Process #5 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00005_of_00006.arrow
Spawning 6 processes
01/05/2026 14:31:23 - INFO - datasets.arrow_dataset - Spawning 6 processes
Tokenizing texts... (num_proc=6):   0%|          | 0/2105244 [00:00<?, ? examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00000_of_00006.arrow
01/05/2026 14:31:24 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00000_of_00006.arrow
Tokenizing texts... (num_proc=6):   0%|          | 1000/2105244 [00:01<54:06, 648.11 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00001_of_00006.arrow
01/05/2026 14:31:25 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00001_of_00006.arrow
Tokenizing texts... (num_proc=6):   0%|          | 2000/2105244 [00:01<26:05, 1343.60 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00002_of_00006.arrow
01/05/2026 14:31:25 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00002_of_00006.arrow
Tokenizing texts... (num_proc=6):   0%|          | 3000/2105244 [00:01<16:38, 2104.90 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00003_of_00006.arrow
01/05/2026 14:31:25 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00003_of_00006.arrow
Tokenizing texts... (num_proc=6):   0%|          | 4000/2105244 [00:02<13:34, 2579.77 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00004_of_00006.arrow
01/05/2026 14:31:25 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00004_of_00006.arrow
Tokenizing texts... (num_proc=6):   0%|          | 6000/2105244 [00:02<08:12, 4266.29 examples/s]Tokenizing texts... (num_proc=6):   0%|          | 8000/2105244 [00:02<06:00, 5821.01 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00005_of_00006.arrow
01/05/2026 14:31:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-c4e7cc91319ec5fa_00005_of_00006.arrow
Tokenizing texts... (num_proc=6):   0%|          | 9000/2105244 [00:02<06:00, 5807.88 examples/s]Tokenizing texts... (num_proc=6):   0%|          | 10000/2105244 [00:02<05:23, 6479.74 examples/s]Tokenizing texts... (num_proc=6):   1%|          | 12000/2105244 [00:02<04:22, 7975.93 examples/s]Tokenizing texts... (num_proc=6):   1%|          | 14000/2105244 [00:03<03:59, 8734.52 examples/s]Tokenizing texts... (num_proc=6):   1%|          | 15000/2105244 [00:03<04:53, 7133.58 examples/s]Tokenizing texts... (num_proc=6):   1%|          | 18000/2105244 [00:03<03:36, 9658.04 examples/s]Tokenizing texts... (num_proc=6):   1%|          | 20000/2105244 [00:03<03:35, 9694.06 examples/s]Tokenizing texts... (num_proc=6):   1%|          | 22000/2105244 [00:04<04:00, 8663.78 examples/s]Tokenizing texts... (num_proc=6):   1%|          | 25000/2105244 [00:04<03:50, 9043.39 examples/s]Tokenizing texts... (num_proc=6):   1%|▏         | 27000/2105244 [00:04<03:21, 10306.80 examples/s]Tokenizing texts... (num_proc=6):   1%|▏         | 29000/2105244 [00:04<03:43, 9283.42 examples/s] Tokenizing texts... (num_proc=6):   1%|▏         | 31000/2105244 [00:05<03:55, 8804.68 examples/s]Tokenizing texts... (num_proc=6):   2%|▏         | 34000/2105244 [00:05<03:56, 8740.30 examples/s]Tokenizing texts... (num_proc=6):   2%|▏         | 37000/2105244 [00:05<03:38, 9465.46 examples/s]Tokenizing texts... (num_proc=6):   2%|▏         | 40000/2105244 [00:05<03:45, 9158.76 examples/s]Tokenizing texts... (num_proc=6):   2%|▏         | 42000/2105244 [00:06<03:25, 10025.24 examples/s]Tokenizing texts... (num_proc=6):   2%|▏         | 44000/2105244 [00:06<03:16, 10503.49 examples/s]Tokenizing texts... (num_proc=6):   2%|▏         | 46000/2105244 [00:06<03:51, 8908.77 examples/s] Tokenizing texts... (num_proc=6):   2%|▏         | 48000/2105244 [00:06<03:29, 9821.09 examples/s]Tokenizing texts... (num_proc=6):   2%|▏         | 50000/2105244 [00:06<03:18, 10369.65 examples/s]Tokenizing texts... (num_proc=6):   2%|▏         | 52000/2105244 [00:07<03:45, 9106.44 examples/s] Tokenizing texts... (num_proc=6):   3%|▎         | 53000/2105244 [00:07<03:43, 9166.52 examples/s]Tokenizing texts... (num_proc=6):   3%|▎         | 55000/2105244 [00:07<03:38, 9374.06 examples/s]Tokenizing texts... (num_proc=6):   3%|▎         | 57000/2105244 [00:07<03:35, 9489.10 examples/s]Tokenizing texts... (num_proc=6):   3%|▎         | 58000/2105244 [00:07<03:42, 9211.66 examples/s]Tokenizing texts... (num_proc=6):   3%|▎         | 59000/2105244 [00:07<03:57, 8619.06 examples/s]Tokenizing texts... (num_proc=6):   3%|▎         | 60000/2105244 [00:08<03:55, 8668.80 examples/s]Tokenizing texts... (num_proc=6):   3%|▎         | 63000/2105244 [00:08<03:40, 9247.15 examples/s]Tokenizing texts... (num_proc=6):   3%|▎         | 64000/2105244 [00:08<04:30, 7535.28 examples/s]Tokenizing texts... (num_proc=6):   3%|▎         | 67000/2105244 [00:08<03:36, 9404.31 examples/s]Tokenizing texts... (num_proc=6):   3%|▎         | 68000/2105244 [00:09<04:04, 8340.06 examples/s]Tokenizing texts... (num_proc=6):   3%|▎         | 70000/2105244 [00:09<03:44, 9058.69 examples/s]Tokenizing texts... (num_proc=6):   3%|▎         | 72000/2105244 [00:09<04:05, 8281.00 examples/s]Tokenizing texts... (num_proc=6):   4%|▎         | 74000/2105244 [00:09<03:37, 9336.05 examples/s]Tokenizing texts... (num_proc=6):   4%|▎         | 75000/2105244 [00:09<03:41, 9163.71 examples/s]Tokenizing texts... (num_proc=6):   4%|▎         | 76000/2105244 [00:09<03:41, 9157.45 examples/s]Tokenizing texts... (num_proc=6):   4%|▎         | 78000/2105244 [00:10<03:57, 8547.45 examples/s]Tokenizing texts... (num_proc=6):   4%|▍         | 79000/2105244 [00:10<04:01, 8392.14 examples/s]Tokenizing texts... (num_proc=6):   4%|▍         | 81000/2105244 [00:10<03:32, 9531.16 examples/s]Tokenizing texts... (num_proc=6):   4%|▍         | 83000/2105244 [00:10<03:38, 9258.84 examples/s]Tokenizing texts... (num_proc=6):   4%|▍         | 84000/2105244 [00:10<03:55, 8577.41 examples/s]Tokenizing texts... (num_proc=6):   4%|▍         | 87000/2105244 [00:11<03:40, 9132.79 examples/s]Tokenizing texts... (num_proc=6):   4%|▍         | 89000/2105244 [00:11<03:41, 9112.32 examples/s]Tokenizing texts... (num_proc=6):   4%|▍         | 90000/2105244 [00:11<03:41, 9098.73 examples/s]Tokenizing texts... (num_proc=6):   4%|▍         | 93000/2105244 [00:11<03:36, 9286.32 examples/s]Tokenizing texts... (num_proc=6):   5%|▍         | 95000/2105244 [00:12<03:44, 8972.12 examples/s]Tokenizing texts... (num_proc=6):   5%|▍         | 97000/2105244 [00:12<03:23, 9882.33 examples/s]Tokenizing texts... (num_proc=6):   5%|▍         | 99000/2105244 [00:12<03:26, 9738.47 examples/s]Tokenizing texts... (num_proc=6):   5%|▍         | 101000/2105244 [00:12<03:14, 10304.88 examples/s]Tokenizing texts... (num_proc=6):   5%|▍         | 103000/2105244 [00:12<03:27, 9654.73 examples/s] Tokenizing texts... (num_proc=6):   5%|▍         | 105000/2105244 [00:12<03:26, 9696.03 examples/s]Tokenizing texts... (num_proc=6):   5%|▌         | 106000/2105244 [00:13<03:33, 9347.39 examples/s]Tokenizing texts... (num_proc=6):   5%|▌         | 108000/2105244 [00:13<04:00, 8310.80 examples/s]Tokenizing texts... (num_proc=6):   5%|▌         | 111000/2105244 [00:13<03:14, 10262.01 examples/s]Tokenizing texts... (num_proc=6):   5%|▌         | 113000/2105244 [00:13<03:23, 9784.94 examples/s] Tokenizing texts... (num_proc=6):   5%|▌         | 115000/2105244 [00:14<03:40, 9045.45 examples/s]Tokenizing texts... (num_proc=6):   6%|▌         | 117000/2105244 [00:14<03:08, 10529.68 examples/s]Tokenizing texts... (num_proc=6):   6%|▌         | 119000/2105244 [00:14<03:42, 8918.96 examples/s] Tokenizing texts... (num_proc=6):   6%|▌         | 121000/2105244 [00:14<03:45, 8794.88 examples/s]Tokenizing texts... (num_proc=6):   6%|▌         | 125000/2105244 [00:15<03:42, 8883.23 examples/s]Tokenizing texts... (num_proc=6):   6%|▌         | 128000/2105244 [00:15<03:16, 10050.01 examples/s]Tokenizing texts... (num_proc=6):   6%|▌         | 131000/2105244 [00:15<03:43, 8846.55 examples/s] Tokenizing texts... (num_proc=6):   6%|▋         | 134000/2105244 [00:16<03:13, 10209.80 examples/s]Tokenizing texts... (num_proc=6):   7%|▋         | 137000/2105244 [00:16<03:30, 9358.81 examples/s] Tokenizing texts... (num_proc=6):   7%|▋         | 139000/2105244 [00:16<03:23, 9663.24 examples/s]Tokenizing texts... (num_proc=6):   7%|▋         | 141000/2105244 [00:16<03:09, 10370.01 examples/s]Tokenizing texts... (num_proc=6):   7%|▋         | 143000/2105244 [00:16<03:19, 9813.19 examples/s] Tokenizing texts... (num_proc=6):   7%|▋         | 145000/2105244 [00:17<03:41, 8830.62 examples/s]Tokenizing texts... (num_proc=6):   7%|▋         | 147000/2105244 [00:17<03:19, 9805.36 examples/s]Tokenizing texts... (num_proc=6):   7%|▋         | 150000/2105244 [00:17<03:50, 8485.10 examples/s]Tokenizing texts... (num_proc=6):   7%|▋         | 152000/2105244 [00:17<03:16, 9951.67 examples/s]Tokenizing texts... (num_proc=6):   7%|▋         | 154000/2105244 [00:18<02:55, 11112.19 examples/s]Tokenizing texts... (num_proc=6):   7%|▋         | 156000/2105244 [00:18<03:56, 8237.83 examples/s] Tokenizing texts... (num_proc=6):   8%|▊         | 158000/2105244 [00:18<03:25, 9468.09 examples/s]Tokenizing texts... (num_proc=6):   8%|▊         | 160000/2105244 [00:18<02:59, 10824.04 examples/s]Tokenizing texts... (num_proc=6):   8%|▊         | 162000/2105244 [00:19<03:44, 8669.59 examples/s] Tokenizing texts... (num_proc=6):   8%|▊         | 165000/2105244 [00:19<03:18, 9774.89 examples/s]Tokenizing texts... (num_proc=6):   8%|▊         | 167000/2105244 [00:19<03:05, 10428.22 examples/s]Tokenizing texts... (num_proc=6):   8%|▊         | 169000/2105244 [00:19<03:20, 9653.68 examples/s] Tokenizing texts... (num_proc=6):   8%|▊         | 171000/2105244 [00:19<03:34, 9025.29 examples/s]Tokenizing texts... (num_proc=6):   8%|▊         | 173000/2105244 [00:20<03:17, 9783.47 examples/s]Tokenizing texts... (num_proc=6):   8%|▊         | 175000/2105244 [00:20<02:58, 10837.71 examples/s]Tokenizing texts... (num_proc=6):   8%|▊         | 177000/2105244 [00:20<03:54, 8229.10 examples/s] Tokenizing texts... (num_proc=6):   9%|▊         | 179000/2105244 [00:20<03:32, 9069.17 examples/s]Tokenizing texts... (num_proc=6):   9%|▊         | 182000/2105244 [00:20<02:46, 11564.49 examples/s]Tokenizing texts... (num_proc=6):   9%|▊         | 184000/2105244 [00:21<03:40, 8697.40 examples/s] Tokenizing texts... (num_proc=6):   9%|▉         | 186000/2105244 [00:21<03:20, 9577.80 examples/s]Tokenizing texts... (num_proc=6):   9%|▉         | 189000/2105244 [00:21<03:49, 8349.52 examples/s]Tokenizing texts... (num_proc=6):   9%|▉         | 192000/2105244 [00:22<03:10, 10064.32 examples/s]Tokenizing texts... (num_proc=6):   9%|▉         | 195000/2105244 [00:22<03:29, 9139.19 examples/s] Tokenizing texts... (num_proc=6):   9%|▉         | 197000/2105244 [00:22<03:16, 9718.91 examples/s]Tokenizing texts... (num_proc=6):   9%|▉         | 199000/2105244 [00:22<02:57, 10717.21 examples/s]Tokenizing texts... (num_proc=6):  10%|▉         | 201000/2105244 [00:23<03:51, 8225.58 examples/s] Tokenizing texts... (num_proc=6):  10%|▉         | 203000/2105244 [00:23<03:24, 9317.73 examples/s]Tokenizing texts... (num_proc=6):  10%|▉         | 206000/2105244 [00:23<02:59, 10603.84 examples/s]Tokenizing texts... (num_proc=6):  10%|▉         | 208000/2105244 [00:23<03:49, 8253.77 examples/s] Tokenizing texts... (num_proc=6):  10%|█         | 212000/2105244 [00:24<03:07, 10111.11 examples/s]Tokenizing texts... (num_proc=6):  10%|█         | 214000/2105244 [00:24<03:36, 8721.66 examples/s] Tokenizing texts... (num_proc=6):  10%|█         | 215000/2105244 [00:24<03:33, 8844.38 examples/s]Tokenizing texts... (num_proc=6):  10%|█         | 218000/2105244 [00:24<03:02, 10342.44 examples/s]Tokenizing texts... (num_proc=6):  10%|█         | 220000/2105244 [00:25<04:02, 7780.49 examples/s] Tokenizing texts... (num_proc=6):  11%|█         | 224000/2105244 [00:25<02:39, 11825.93 examples/s]Tokenizing texts... (num_proc=6):  11%|█         | 226000/2105244 [00:25<03:49, 8198.56 examples/s] Tokenizing texts... (num_proc=6):  11%|█         | 229000/2105244 [00:26<02:53, 10842.09 examples/s]Tokenizing texts... (num_proc=6):  11%|█         | 231000/2105244 [00:26<03:10, 9858.99 examples/s] Tokenizing texts... (num_proc=6):  11%|█         | 233000/2105244 [00:26<03:28, 8965.79 examples/s]Tokenizing texts... (num_proc=6):  11%|█         | 235000/2105244 [00:26<03:01, 10322.11 examples/s]Tokenizing texts... (num_proc=6):  11%|█▏        | 237000/2105244 [00:26<03:28, 8945.18 examples/s] Tokenizing texts... (num_proc=6):  11%|█▏        | 239000/2105244 [00:27<03:31, 8812.91 examples/s]Tokenizing texts... (num_proc=6):  11%|█▏        | 241000/2105244 [00:27<03:04, 10088.77 examples/s]Tokenizing texts... (num_proc=6):  12%|█▏        | 243000/2105244 [00:27<03:38, 8504.05 examples/s] Tokenizing texts... (num_proc=6):  12%|█▏        | 245000/2105244 [00:27<03:18, 9380.77 examples/s]Tokenizing texts... (num_proc=6):  12%|█▏        | 247000/2105244 [00:27<02:59, 10369.08 examples/s]Tokenizing texts... (num_proc=6):  12%|█▏        | 249000/2105244 [00:28<03:11, 9692.28 examples/s] Tokenizing texts... (num_proc=6):  12%|█▏        | 251000/2105244 [00:28<03:27, 8936.52 examples/s]Tokenizing texts... (num_proc=6):  12%|█▏        | 252000/2105244 [00:28<03:35, 8580.85 examples/s]Tokenizing texts... (num_proc=6):  12%|█▏        | 253000/2105244 [00:28<03:42, 8329.07 examples/s]Tokenizing texts... (num_proc=6):  12%|█▏        | 256000/2105244 [00:29<03:25, 9017.38 examples/s]Tokenizing texts... (num_proc=6):  12%|█▏        | 257000/2105244 [00:29<03:27, 8918.53 examples/s]Tokenizing texts... (num_proc=6):  12%|█▏        | 259000/2105244 [00:29<03:05, 9933.22 examples/s]Tokenizing texts... (num_proc=6):  12%|█▏        | 261000/2105244 [00:29<02:46, 11060.35 examples/s]Tokenizing texts... (num_proc=6):  12%|█▏        | 263000/2105244 [00:29<03:43, 8243.27 examples/s] Tokenizing texts... (num_proc=6):  13%|█▎        | 266000/2105244 [00:30<03:15, 9401.28 examples/s]Tokenizing texts... (num_proc=6):  13%|█▎        | 268000/2105244 [00:30<03:07, 9793.44 examples/s]Tokenizing texts... (num_proc=6):  13%|█▎        | 270000/2105244 [00:30<03:09, 9669.69 examples/s]Tokenizing texts... (num_proc=6):  13%|█▎        | 272000/2105244 [00:30<03:31, 8653.27 examples/s]Tokenizing texts... (num_proc=6):  13%|█▎        | 274000/2105244 [00:30<03:01, 10091.41 examples/s]Tokenizing texts... (num_proc=6):  13%|█▎        | 276000/2105244 [00:31<03:09, 9659.69 examples/s] Tokenizing texts... (num_proc=6):  13%|█▎        | 278000/2105244 [00:31<03:37, 8386.47 examples/s]Tokenizing texts... (num_proc=6):  13%|█▎        | 281000/2105244 [00:31<02:37, 11585.75 examples/s]Tokenizing texts... (num_proc=6):  13%|█▎        | 283000/2105244 [00:31<03:14, 9350.30 examples/s] Tokenizing texts... (num_proc=6):  14%|█▎        | 285000/2105244 [00:32<03:23, 8945.96 examples/s]Tokenizing texts... (num_proc=6):  14%|█▎        | 288000/2105244 [00:32<03:09, 9569.37 examples/s]Tokenizing texts... (num_proc=6):  14%|█▍        | 290000/2105244 [00:32<03:24, 8881.77 examples/s]Tokenizing texts... (num_proc=6):  14%|█▍        | 292000/2105244 [00:32<02:54, 10405.20 examples/s]Tokenizing texts... (num_proc=6):  14%|█▍        | 294000/2105244 [00:33<03:08, 9595.60 examples/s] Tokenizing texts... (num_proc=6):  14%|█▍        | 296000/2105244 [00:33<03:07, 9646.10 examples/s]Tokenizing texts... (num_proc=6):  14%|█▍        | 298000/2105244 [00:33<03:00, 10021.05 examples/s]Tokenizing texts... (num_proc=6):  14%|█▍        | 300000/2105244 [00:33<03:16, 9189.60 examples/s] Tokenizing texts... (num_proc=6):  14%|█▍        | 301000/2105244 [00:33<03:19, 9039.07 examples/s]Tokenizing texts... (num_proc=6):  14%|█▍        | 303000/2105244 [00:34<03:18, 9064.91 examples/s]Tokenizing texts... (num_proc=6):  14%|█▍        | 305000/2105244 [00:34<02:58, 10100.46 examples/s]Tokenizing texts... (num_proc=6):  15%|█▍        | 307000/2105244 [00:34<02:53, 10359.68 examples/s]Tokenizing texts... (num_proc=6):  15%|█▍        | 309000/2105244 [00:34<03:08, 9548.20 examples/s] Tokenizing texts... (num_proc=6):  15%|█▍        | 310000/2105244 [00:34<03:24, 8799.79 examples/s]Tokenizing texts... (num_proc=6):  15%|█▍        | 311000/2105244 [00:34<03:21, 8903.92 examples/s]Tokenizing texts... (num_proc=6):  15%|█▍        | 314000/2105244 [00:35<03:29, 8545.28 examples/s]Tokenizing texts... (num_proc=6):  15%|█▌        | 316000/2105244 [00:35<03:13, 9233.20 examples/s]Tokenizing texts... (num_proc=6):  15%|█▌        | 318000/2105244 [00:35<02:57, 10063.71 examples/s]Tokenizing texts... (num_proc=6):  15%|█▌        | 320000/2105244 [00:35<03:21, 8875.92 examples/s] Tokenizing texts... (num_proc=6):  15%|█▌        | 321000/2105244 [00:35<03:18, 8971.20 examples/s]Tokenizing texts... (num_proc=6):  15%|█▌        | 323000/2105244 [00:36<02:42, 10986.38 examples/s]Tokenizing texts... (num_proc=6):  15%|█▌        | 325000/2105244 [00:36<02:42, 10974.16 examples/s]Tokenizing texts... (num_proc=6):  16%|█▌        | 327000/2105244 [00:36<03:30, 8450.78 examples/s] Tokenizing texts... (num_proc=6):  16%|█▌        | 329000/2105244 [00:36<02:59, 9904.36 examples/s]Tokenizing texts... (num_proc=6):  16%|█▌        | 331000/2105244 [00:36<03:05, 9557.44 examples/s]Tokenizing texts... (num_proc=6):  16%|█▌        | 333000/2105244 [00:37<03:09, 9357.05 examples/s]Tokenizing texts... (num_proc=6):  16%|█▌        | 335000/2105244 [00:37<03:05, 9549.22 examples/s]Tokenizing texts... (num_proc=6):  16%|█▌        | 337000/2105244 [00:37<03:17, 8944.59 examples/s]Tokenizing texts... (num_proc=6):  16%|█▌        | 339000/2105244 [00:37<02:45, 10696.30 examples/s]Tokenizing texts... (num_proc=6):  16%|█▌        | 341000/2105244 [00:38<03:15, 9033.57 examples/s] Tokenizing texts... (num_proc=6):  16%|█▋        | 343000/2105244 [00:38<03:23, 8665.18 examples/s]Tokenizing texts... (num_proc=6):  16%|█▋        | 345000/2105244 [00:38<03:03, 9610.83 examples/s]Tokenizing texts... (num_proc=6):  16%|█▋        | 347000/2105244 [00:38<03:12, 9132.13 examples/s]Tokenizing texts... (num_proc=6):  17%|█▋        | 349000/2105244 [00:38<03:21, 8731.86 examples/s]Tokenizing texts... (num_proc=6):  17%|█▋        | 352000/2105244 [00:39<03:34, 8186.91 examples/s]Tokenizing texts... (num_proc=6):  17%|█▋        | 355000/2105244 [00:39<02:59, 9770.24 examples/s]Tokenizing texts... (num_proc=6):  17%|█▋        | 357000/2105244 [00:39<02:45, 10547.35 examples/s]Tokenizing texts... (num_proc=6):  17%|█▋        | 359000/2105244 [00:40<03:24, 8547.29 examples/s] Tokenizing texts... (num_proc=6):  17%|█▋        | 362000/2105244 [00:40<02:33, 11382.37 examples/s]Tokenizing texts... (num_proc=6):  17%|█▋        | 364000/2105244 [00:40<03:46, 7677.28 examples/s] Tokenizing texts... (num_proc=6):  18%|█▊        | 369000/2105244 [00:41<03:10, 9103.40 examples/s]Tokenizing texts... (num_proc=6):  18%|█▊        | 371000/2105244 [00:41<03:10, 9124.45 examples/s]Tokenizing texts... (num_proc=6):  18%|█▊        | 374000/2105244 [00:41<02:29, 11608.50 examples/s]Tokenizing texts... (num_proc=6):  18%|█▊        | 376000/2105244 [00:41<03:20, 8636.58 examples/s] Tokenizing texts... (num_proc=6):  18%|█▊        | 378000/2105244 [00:41<02:58, 9698.84 examples/s]Tokenizing texts... (num_proc=6):  18%|█▊        | 380000/2105244 [00:42<02:41, 10677.71 examples/s]Tokenizing texts... (num_proc=6):  18%|█▊        | 382000/2105244 [00:42<03:19, 8622.00 examples/s] Tokenizing texts... (num_proc=6):  18%|█▊        | 384000/2105244 [00:42<03:03, 9366.18 examples/s]Tokenizing texts... (num_proc=6):  18%|█▊        | 386000/2105244 [00:42<02:52, 9957.56 examples/s]Tokenizing texts... (num_proc=6):  18%|█▊        | 388000/2105244 [00:43<03:27, 8286.66 examples/s]Tokenizing texts... (num_proc=6):  18%|█▊        | 389000/2105244 [00:43<03:33, 8020.24 examples/s]Tokenizing texts... (num_proc=6):  19%|█▊        | 392000/2105244 [00:43<02:49, 10132.18 examples/s]Tokenizing texts... (num_proc=6):  19%|█▊        | 394000/2105244 [00:43<03:30, 8120.72 examples/s] Tokenizing texts... (num_proc=6):  19%|█▉        | 396000/2105244 [00:43<02:57, 9608.27 examples/s]Tokenizing texts... (num_proc=6):  19%|█▉        | 398000/2105244 [00:44<02:45, 10291.82 examples/s]Tokenizing texts... (num_proc=6):  19%|█▉        | 400000/2105244 [00:44<03:43, 7626.20 examples/s] Tokenizing texts... (num_proc=6):  19%|█▉        | 404000/2105244 [00:44<02:27, 11557.19 examples/s]Tokenizing texts... (num_proc=6):  19%|█▉        | 406000/2105244 [00:45<03:34, 7940.09 examples/s] Tokenizing texts... (num_proc=6):  19%|█▉        | 410000/2105244 [00:45<02:50, 9937.68 examples/s]Tokenizing texts... (num_proc=6):  20%|█▉        | 412000/2105244 [00:45<03:19, 8504.01 examples/s]Tokenizing texts... (num_proc=6):  20%|█▉        | 414000/2105244 [00:45<02:51, 9838.63 examples/s]Tokenizing texts... (num_proc=6):  20%|█▉        | 416000/2105244 [00:46<02:52, 9767.26 examples/s]Tokenizing texts... (num_proc=6):  20%|█▉        | 418000/2105244 [00:46<03:07, 8983.50 examples/s]Tokenizing texts... (num_proc=6):  20%|█▉        | 420000/2105244 [00:46<02:56, 9560.20 examples/s]Tokenizing texts... (num_proc=6):  20%|██        | 422000/2105244 [00:46<02:57, 9476.90 examples/s]Tokenizing texts... (num_proc=6):  20%|██        | 424000/2105244 [00:46<03:05, 9070.80 examples/s]Tokenizing texts... (num_proc=6):  20%|██        | 426000/2105244 [00:47<02:56, 9522.07 examples/s]Tokenizing texts... (num_proc=6):  20%|██        | 428000/2105244 [00:47<03:23, 8252.57 examples/s]Tokenizing texts... (num_proc=6):  20%|██        | 430000/2105244 [00:47<02:54, 9597.26 examples/s]Tokenizing texts... (num_proc=6):  21%|██        | 432000/2105244 [00:47<02:43, 10235.48 examples/s]Tokenizing texts... (num_proc=6):  21%|██        | 434000/2105244 [00:48<03:05, 8994.74 examples/s] Tokenizing texts... (num_proc=6):  21%|██        | 436000/2105244 [00:48<02:52, 9703.17 examples/s]Tokenizing texts... (num_proc=6):  21%|██        | 438000/2105244 [00:48<02:45, 10066.83 examples/s]Tokenizing texts... (num_proc=6):  21%|██        | 440000/2105244 [00:48<03:10, 8755.55 examples/s] Tokenizing texts... (num_proc=6):  21%|██        | 441000/2105244 [00:48<03:17, 8407.51 examples/s]Tokenizing texts... (num_proc=6):  21%|██        | 443000/2105244 [00:49<02:59, 9284.26 examples/s]Tokenizing texts... (num_proc=6):  21%|██        | 445000/2105244 [00:49<02:40, 10340.09 examples/s]Tokenizing texts... (num_proc=6):  21%|██        | 447000/2105244 [00:49<03:07, 8860.21 examples/s] Tokenizing texts... (num_proc=6):  21%|██▏       | 448000/2105244 [00:49<03:05, 8918.28 examples/s]Tokenizing texts... (num_proc=6):  21%|██▏       | 449000/2105244 [00:49<03:03, 9040.34 examples/s]Tokenizing texts... (num_proc=6):  21%|██▏       | 452000/2105244 [00:50<03:13, 8541.51 examples/s]Tokenizing texts... (num_proc=6):  22%|██▏       | 454000/2105244 [00:50<03:14, 8472.46 examples/s]Tokenizing texts... (num_proc=6):  22%|██▏       | 458000/2105244 [00:50<03:01, 9060.18 examples/s]Tokenizing texts... (num_proc=6):  22%|██▏       | 460000/2105244 [00:50<02:49, 9700.78 examples/s]Tokenizing texts... (num_proc=6):  22%|██▏       | 462000/2105244 [00:51<02:37, 10437.92 examples/s]Tokenizing texts... (num_proc=6):  22%|██▏       | 464000/2105244 [00:51<03:05, 8847.33 examples/s] Tokenizing texts... (num_proc=6):  22%|██▏       | 467000/2105244 [00:51<02:45, 9902.71 examples/s]Tokenizing texts... (num_proc=6):  22%|██▏       | 469000/2105244 [00:51<02:37, 10397.93 examples/s]Tokenizing texts... (num_proc=6):  22%|██▏       | 471000/2105244 [00:51<02:54, 9369.48 examples/s] Tokenizing texts... (num_proc=6):  22%|██▏       | 473000/2105244 [00:52<02:53, 9385.16 examples/s]Tokenizing texts... (num_proc=6):  23%|██▎       | 474000/2105244 [00:52<03:19, 8168.69 examples/s]Tokenizing texts... (num_proc=6):  23%|██▎       | 476000/2105244 [00:52<02:54, 9339.33 examples/s]Tokenizing texts... (num_proc=6):  23%|██▎       | 478000/2105244 [00:52<02:36, 10415.14 examples/s]Tokenizing texts... (num_proc=6):  23%|██▎       | 480000/2105244 [00:53<03:28, 7799.35 examples/s] Tokenizing texts... (num_proc=6):  23%|██▎       | 484000/2105244 [00:53<02:38, 10243.55 examples/s]Tokenizing texts... (num_proc=6):  23%|██▎       | 486000/2105244 [00:53<03:21, 8020.08 examples/s] Tokenizing texts... (num_proc=6):  23%|██▎       | 489000/2105244 [00:53<02:32, 10578.55 examples/s]Tokenizing texts... (num_proc=6):  23%|██▎       | 491000/2105244 [00:54<02:39, 10094.97 examples/s]Tokenizing texts... (num_proc=6):  23%|██▎       | 493000/2105244 [00:54<02:59, 8994.67 examples/s] Tokenizing texts... (num_proc=6):  24%|██▎       | 495000/2105244 [00:54<02:56, 9109.10 examples/s]Tokenizing texts... (num_proc=6):  24%|██▎       | 497000/2105244 [00:54<02:36, 10299.12 examples/s]Tokenizing texts... (num_proc=6):  24%|██▎       | 499000/2105244 [00:54<02:49, 9487.70 examples/s] Tokenizing texts... (num_proc=6):  24%|██▍       | 501000/2105244 [00:55<03:17, 8104.11 examples/s]Tokenizing texts... (num_proc=6):  24%|██▍       | 504000/2105244 [00:55<02:39, 10016.58 examples/s]Tokenizing texts... (num_proc=6):  24%|██▍       | 506000/2105244 [00:55<03:09, 8428.64 examples/s] Tokenizing texts... (num_proc=6):  24%|██▍       | 507000/2105244 [00:56<03:18, 8061.05 examples/s]Tokenizing texts... (num_proc=6):  24%|██▍       | 511000/2105244 [00:56<02:29, 10645.83 examples/s]Tokenizing texts... (num_proc=6):  24%|██▍       | 513000/2105244 [00:56<03:09, 8407.61 examples/s] Tokenizing texts... (num_proc=6):  25%|██▍       | 516000/2105244 [00:56<02:32, 10423.86 examples/s]Tokenizing texts... (num_proc=6):  25%|██▍       | 518000/2105244 [00:57<03:12, 8244.08 examples/s] Tokenizing texts... (num_proc=6):  25%|██▍       | 521000/2105244 [00:57<02:41, 9803.51 examples/s]Tokenizing texts... (num_proc=6):  25%|██▍       | 523000/2105244 [00:57<02:28, 10681.55 examples/s]Tokenizing texts... (num_proc=6):  25%|██▍       | 525000/2105244 [00:57<03:03, 8617.18 examples/s] Tokenizing texts... (num_proc=6):  25%|██▌       | 527000/2105244 [00:58<02:51, 9220.35 examples/s]Tokenizing texts... (num_proc=6):  25%|██▌       | 529000/2105244 [00:58<02:47, 9402.26 examples/s]Tokenizing texts... (num_proc=6):  25%|██▌       | 531000/2105244 [00:58<02:50, 9253.53 examples/s]Tokenizing texts... (num_proc=6):  25%|██▌       | 532000/2105244 [00:58<02:56, 8931.88 examples/s]Tokenizing texts... (num_proc=6):  25%|██▌       | 533000/2105244 [00:58<02:57, 8873.32 examples/s]Tokenizing texts... (num_proc=6):  25%|██▌       | 534000/2105244 [00:58<03:11, 8224.06 examples/s]Tokenizing texts... (num_proc=6):  25%|██▌       | 536000/2105244 [00:59<02:34, 10137.74 examples/s]Tokenizing texts... (num_proc=6):  26%|██▌       | 538000/2105244 [00:59<03:04, 8473.79 examples/s] Tokenizing texts... (num_proc=6):  26%|██▌       | 540000/2105244 [00:59<02:38, 9891.45 examples/s]Tokenizing texts... (num_proc=6):  26%|██▌       | 542000/2105244 [00:59<02:56, 8837.05 examples/s]Tokenizing texts... (num_proc=6):  26%|██▌       | 544000/2105244 [00:59<03:05, 8414.11 examples/s]Tokenizing texts... (num_proc=6):  26%|██▌       | 547000/2105244 [01:00<02:21, 11040.57 examples/s]Tokenizing texts... (num_proc=6):  26%|██▌       | 549000/2105244 [01:00<03:13, 8034.47 examples/s] Tokenizing texts... (num_proc=6):  26%|██▌       | 551000/2105244 [01:00<02:43, 9518.47 examples/s]Tokenizing texts... (num_proc=6):  26%|██▋       | 553000/2105244 [01:00<02:18, 11214.89 examples/s]Tokenizing texts... (num_proc=6):  26%|██▋       | 555000/2105244 [01:01<03:00, 8575.84 examples/s] Tokenizing texts... (num_proc=6):  26%|██▋       | 557000/2105244 [01:01<03:02, 8491.99 examples/s]Tokenizing texts... (num_proc=6):  27%|██▋       | 560000/2105244 [01:01<02:54, 8859.53 examples/s]Tokenizing texts... (num_proc=6):  27%|██▋       | 562000/2105244 [01:01<02:40, 9642.21 examples/s]Tokenizing texts... (num_proc=6):  27%|██▋       | 564000/2105244 [01:02<02:42, 9499.05 examples/s]Tokenizing texts... (num_proc=6):  27%|██▋       | 566000/2105244 [01:02<02:38, 9699.85 examples/s]Tokenizing texts... (num_proc=6):  27%|██▋       | 568000/2105244 [01:02<03:04, 8320.17 examples/s]Tokenizing texts... (num_proc=6):  27%|██▋       | 570000/2105244 [01:02<02:48, 9134.49 examples/s]Tokenizing texts... (num_proc=6):  27%|██▋       | 573000/2105244 [01:03<02:51, 8920.83 examples/s]Tokenizing texts... (num_proc=6):  27%|██▋       | 574000/2105244 [01:03<02:57, 8642.77 examples/s]Tokenizing texts... (num_proc=6):  27%|██▋       | 576000/2105244 [01:03<02:32, 10020.18 examples/s]Tokenizing texts... (num_proc=6):  27%|██▋       | 578000/2105244 [01:03<02:38, 9615.03 examples/s] Tokenizing texts... (num_proc=6):  28%|██▊       | 580000/2105244 [01:03<02:55, 8689.92 examples/s]Tokenizing texts... (num_proc=6):  28%|██▊       | 583000/2105244 [01:04<02:39, 9524.22 examples/s]Tokenizing texts... (num_proc=6):  28%|██▊       | 584000/2105244 [01:04<02:44, 9255.00 examples/s]Tokenizing texts... (num_proc=6):  28%|██▊       | 586000/2105244 [01:04<02:49, 8968.92 examples/s]Tokenizing texts... (num_proc=6):  28%|██▊       | 589000/2105244 [01:04<02:46, 9120.23 examples/s]Tokenizing texts... (num_proc=6):  28%|██▊       | 590000/2105244 [01:04<02:48, 8975.59 examples/s]Tokenizing texts... (num_proc=6):  28%|██▊       | 592000/2105244 [01:05<02:29, 10151.39 examples/s]Tokenizing texts... (num_proc=6):  28%|██▊       | 594000/2105244 [01:05<02:17, 11015.19 examples/s]Tokenizing texts... (num_proc=6):  28%|██▊       | 596000/2105244 [01:05<03:05, 8142.45 examples/s] Tokenizing texts... (num_proc=6):  28%|██▊       | 599000/2105244 [01:05<02:23, 10469.51 examples/s]Tokenizing texts... (num_proc=6):  29%|██▊       | 601000/2105244 [01:06<03:10, 7901.86 examples/s] Tokenizing texts... (num_proc=6):  29%|██▊       | 604000/2105244 [01:06<02:29, 10067.50 examples/s]Tokenizing texts... (num_proc=6):  29%|██▉       | 606000/2105244 [01:06<02:58, 8388.05 examples/s] Tokenizing texts... (num_proc=6):  29%|██▉       | 608000/2105244 [01:06<02:45, 9046.19 examples/s]Tokenizing texts... (num_proc=6):  29%|██▉       | 610000/2105244 [01:07<02:32, 9799.63 examples/s]Tokenizing texts... (num_proc=6):  29%|██▉       | 612000/2105244 [01:07<02:58, 8373.91 examples/s]Tokenizing texts... (num_proc=6):  29%|██▉       | 614000/2105244 [01:07<02:35, 9615.59 examples/s]Tokenizing texts... (num_proc=6):  29%|██▉       | 616000/2105244 [01:07<02:27, 10096.40 examples/s]Tokenizing texts... (num_proc=6):  29%|██▉       | 618000/2105244 [01:07<02:41, 9215.80 examples/s] Tokenizing texts... (num_proc=6):  29%|██▉       | 620000/2105244 [01:08<02:39, 9328.26 examples/s]Tokenizing texts... (num_proc=6):  30%|██▉       | 622000/2105244 [01:08<02:33, 9650.58 examples/s]Tokenizing texts... (num_proc=6):  30%|██▉       | 624000/2105244 [01:08<02:24, 10247.50 examples/s]Tokenizing texts... (num_proc=6):  30%|██▉       | 626000/2105244 [01:08<02:39, 9289.33 examples/s] Tokenizing texts... (num_proc=6):  30%|██▉       | 627000/2105244 [01:08<02:47, 8806.11 examples/s]Tokenizing texts... (num_proc=6):  30%|██▉       | 628000/2105244 [01:09<02:47, 8842.97 examples/s]Tokenizing texts... (num_proc=6):  30%|██▉       | 630000/2105244 [01:09<02:35, 9492.83 examples/s]Tokenizing texts... (num_proc=6):  30%|██▉       | 631000/2105244 [01:09<02:56, 8371.23 examples/s]Tokenizing texts... (num_proc=6):  30%|███       | 633000/2105244 [01:09<02:34, 9535.45 examples/s]Tokenizing texts... (num_proc=6):  30%|███       | 634000/2105244 [01:09<02:43, 8996.13 examples/s]Tokenizing texts... (num_proc=6):  30%|███       | 636000/2105244 [01:09<02:10, 11294.74 examples/s]Tokenizing texts... (num_proc=6):  30%|███       | 638000/2105244 [01:10<02:38, 9269.83 examples/s] Tokenizing texts... (num_proc=6):  30%|███       | 640000/2105244 [01:10<02:52, 8516.35 examples/s]Tokenizing texts... (num_proc=6):  30%|███       | 642000/2105244 [01:10<02:20, 10387.66 examples/s]Tokenizing texts... (num_proc=6):  31%|███       | 644000/2105244 [01:10<02:43, 8941.23 examples/s] Tokenizing texts... (num_proc=6):  31%|███       | 646000/2105244 [01:10<02:33, 9506.21 examples/s]Tokenizing texts... (num_proc=6):  31%|███       | 648000/2105244 [01:11<02:34, 9455.88 examples/s]Tokenizing texts... (num_proc=6):  31%|███       | 650000/2105244 [01:11<02:49, 8603.25 examples/s]Tokenizing texts... (num_proc=6):  31%|███       | 653000/2105244 [01:11<02:33, 9464.45 examples/s]Tokenizing texts... (num_proc=6):  31%|███       | 654000/2105244 [01:11<02:39, 9114.60 examples/s]Tokenizing texts... (num_proc=6):  31%|███       | 655000/2105244 [01:11<02:56, 8228.07 examples/s]Tokenizing texts... (num_proc=6):  31%|███▏      | 658000/2105244 [01:12<02:03, 11738.49 examples/s]Tokenizing texts... (num_proc=6):  31%|███▏      | 660000/2105244 [01:12<02:51, 8421.07 examples/s] Tokenizing texts... (num_proc=6):  31%|███▏      | 662000/2105244 [01:12<02:29, 9646.55 examples/s]Tokenizing texts... (num_proc=6):  32%|███▏      | 664000/2105244 [01:12<02:15, 10666.56 examples/s]Tokenizing texts... (num_proc=6):  32%|███▏      | 666000/2105244 [01:13<03:03, 7850.54 examples/s] Tokenizing texts... (num_proc=6):  32%|███▏      | 670000/2105244 [01:13<02:24, 9962.32 examples/s]Tokenizing texts... (num_proc=6):  32%|███▏      | 672000/2105244 [01:13<02:43, 8765.36 examples/s]Tokenizing texts... (num_proc=6):  32%|███▏      | 674000/2105244 [01:13<02:20, 10151.77 examples/s]Tokenizing texts... (num_proc=6):  32%|███▏      | 676000/2105244 [01:14<02:27, 9692.82 examples/s] Tokenizing texts... (num_proc=6):  32%|███▏      | 678000/2105244 [01:14<02:34, 9259.53 examples/s]Tokenizing texts... (num_proc=6):  32%|███▏      | 680000/2105244 [01:14<02:25, 9795.57 examples/s]Tokenizing texts... (num_proc=6):  32%|███▏      | 682000/2105244 [01:14<02:32, 9308.51 examples/s]Tokenizing texts... (num_proc=6):  32%|███▏      | 684000/2105244 [01:15<02:40, 8870.46 examples/s]Tokenizing texts... (num_proc=6):  33%|███▎      | 686000/2105244 [01:15<02:21, 10029.29 examples/s]Tokenizing texts... (num_proc=6):  33%|███▎      | 688000/2105244 [01:15<02:06, 11242.72 examples/s]Tokenizing texts... (num_proc=6):  33%|███▎      | 690000/2105244 [01:15<02:53, 8160.70 examples/s] Tokenizing texts... (num_proc=6):  33%|███▎      | 692000/2105244 [01:15<02:24, 9758.85 examples/s]Tokenizing texts... (num_proc=6):  33%|███▎      | 694000/2105244 [01:15<02:03, 11428.95 examples/s]Tokenizing texts... (num_proc=6):  33%|███▎      | 696000/2105244 [01:16<02:52, 8167.05 examples/s] Tokenizing texts... (num_proc=6):  33%|███▎      | 698000/2105244 [01:16<02:32, 9225.44 examples/s]Tokenizing texts... (num_proc=6):  33%|███▎      | 700000/2105244 [01:16<02:08, 10914.64 examples/s]Tokenizing texts... (num_proc=6):  33%|███▎      | 702000/2105244 [01:16<02:21, 9895.77 examples/s] Tokenizing texts... (num_proc=6):  33%|███▎      | 704000/2105244 [01:17<02:37, 8913.47 examples/s]Tokenizing texts... (num_proc=6):  34%|███▎      | 706000/2105244 [01:17<02:15, 10337.84 examples/s]Tokenizing texts... (num_proc=6):  34%|███▎      | 709000/2105244 [01:17<02:56, 7901.97 examples/s] Tokenizing texts... (num_proc=6):  34%|███▍      | 713000/2105244 [01:17<02:04, 11156.90 examples/s]Tokenizing texts... (num_proc=6):  34%|███▍      | 715000/2105244 [01:18<02:40, 8635.50 examples/s] Tokenizing texts... (num_proc=6):  34%|███▍      | 718000/2105244 [01:18<02:04, 11129.24 examples/s]Tokenizing texts... (num_proc=6):  34%|███▍      | 720000/2105244 [01:18<02:14, 10275.98 examples/s]Tokenizing texts... (num_proc=6):  34%|███▍      | 722000/2105244 [01:18<02:30, 9203.92 examples/s] Tokenizing texts... (num_proc=6):  34%|███▍      | 724000/2105244 [01:19<02:16, 10125.86 examples/s]Tokenizing texts... (num_proc=6):  34%|███▍      | 726000/2105244 [01:19<02:18, 9993.45 examples/s] Tokenizing texts... (num_proc=6):  35%|███▍      | 728000/2105244 [01:19<02:17, 9998.46 examples/s]Tokenizing texts... (num_proc=6):  35%|███▍      | 730000/2105244 [01:19<02:29, 9216.86 examples/s]Tokenizing texts... (num_proc=6):  35%|███▍      | 733000/2105244 [01:20<02:19, 9830.52 examples/s]Tokenizing texts... (num_proc=6):  35%|███▍      | 735000/2105244 [01:20<02:16, 10027.53 examples/s]Tokenizing texts... (num_proc=6):  35%|███▌      | 737000/2105244 [01:20<02:16, 9999.68 examples/s] Tokenizing texts... (num_proc=6):  35%|███▌      | 739000/2105244 [01:20<02:21, 9628.03 examples/s]Tokenizing texts... (num_proc=6):  35%|███▌      | 741000/2105244 [01:20<02:14, 10117.09 examples/s]Tokenizing texts... (num_proc=6):  35%|███▌      | 743000/2105244 [01:21<02:28, 9146.59 examples/s] Tokenizing texts... (num_proc=6):  35%|███▌      | 745000/2105244 [01:21<02:13, 10190.65 examples/s]Tokenizing texts... (num_proc=6):  35%|███▌      | 747000/2105244 [01:21<02:05, 10786.80 examples/s]Tokenizing texts... (num_proc=6):  36%|███▌      | 749000/2105244 [01:21<02:38, 8573.68 examples/s] Tokenizing texts... (num_proc=6):  36%|███▌      | 751000/2105244 [01:21<02:12, 10258.40 examples/s]Tokenizing texts... (num_proc=6):  36%|███▌      | 753000/2105244 [01:22<02:11, 10284.13 examples/s]Tokenizing texts... (num_proc=6):  36%|███▌      | 755000/2105244 [01:22<02:42, 8330.83 examples/s] Tokenizing texts... (num_proc=6):  36%|███▌      | 757000/2105244 [01:22<02:16, 9882.47 examples/s]Tokenizing texts... (num_proc=6):  36%|███▌      | 759000/2105244 [01:22<02:07, 10575.99 examples/s]Tokenizing texts... (num_proc=6):  36%|███▌      | 761000/2105244 [01:22<02:35, 8653.55 examples/s] Tokenizing texts... (num_proc=6):  36%|███▋      | 764000/2105244 [01:23<02:17, 9770.88 examples/s]Tokenizing texts... (num_proc=6):  36%|███▋      | 766000/2105244 [01:23<02:20, 9565.04 examples/s]Tokenizing texts... (num_proc=6):  36%|███▋      | 768000/2105244 [01:23<02:07, 10482.51 examples/s]Tokenizing texts... (num_proc=6):  37%|███▋      | 770000/2105244 [01:23<02:29, 8943.29 examples/s] Tokenizing texts... (num_proc=6):  37%|███▋      | 773000/2105244 [01:24<02:17, 9721.71 examples/s]Tokenizing texts... (num_proc=6):  37%|███▋      | 775000/2105244 [01:24<02:11, 10150.17 examples/s]Tokenizing texts... (num_proc=6):  37%|███▋      | 777000/2105244 [01:24<02:08, 10302.33 examples/s]Tokenizing texts... (num_proc=6):  37%|███▋      | 779000/2105244 [01:24<02:39, 8291.02 examples/s] Tokenizing texts... (num_proc=6):  37%|███▋      | 782000/2105244 [01:24<01:59, 11087.86 examples/s]Tokenizing texts... (num_proc=6):  37%|███▋      | 784000/2105244 [01:25<02:06, 10483.66 examples/s]Tokenizing texts... (num_proc=6):  37%|███▋      | 786000/2105244 [01:25<02:24, 9117.09 examples/s] Tokenizing texts... (num_proc=6):  37%|███▋      | 789000/2105244 [01:25<02:08, 10231.31 examples/s]Tokenizing texts... (num_proc=6):  38%|███▊      | 791000/2105244 [01:26<02:23, 9185.90 examples/s] Tokenizing texts... (num_proc=6):  38%|███▊      | 793000/2105244 [01:26<02:26, 8947.39 examples/s]Tokenizing texts... (num_proc=6):  38%|███▊      | 796000/2105244 [01:26<02:13, 9803.29 examples/s]Tokenizing texts... (num_proc=6):  38%|███▊      | 798000/2105244 [01:26<02:06, 10367.50 examples/s]Tokenizing texts... (num_proc=6):  38%|███▊      | 800000/2105244 [01:26<02:16, 9556.95 examples/s] Tokenizing texts... (num_proc=6):  38%|███▊      | 802000/2105244 [01:27<02:01, 10760.75 examples/s]Tokenizing texts... (num_proc=6):  38%|███▊      | 804000/2105244 [01:27<02:06, 10285.74 examples/s]Tokenizing texts... (num_proc=6):  38%|███▊      | 806000/2105244 [01:27<02:25, 8938.69 examples/s] Tokenizing texts... (num_proc=6):  38%|███▊      | 809000/2105244 [01:27<02:16, 9503.05 examples/s]Tokenizing texts... (num_proc=6):  39%|███▊      | 811000/2105244 [01:28<02:20, 9232.80 examples/s]Tokenizing texts... (num_proc=6):  39%|███▊      | 813000/2105244 [01:28<02:04, 10355.48 examples/s]Tokenizing texts... (num_proc=6):  39%|███▊      | 815000/2105244 [01:28<02:11, 9820.12 examples/s] Tokenizing texts... (num_proc=6):  39%|███▉      | 817000/2105244 [01:28<02:00, 10677.94 examples/s]Tokenizing texts... (num_proc=6):  39%|███▉      | 819000/2105244 [01:28<02:11, 9803.69 examples/s] Tokenizing texts... (num_proc=6):  39%|███▉      | 821000/2105244 [01:29<02:08, 10003.28 examples/s]Tokenizing texts... (num_proc=6):  39%|███▉      | 823000/2105244 [01:29<01:50, 11637.28 examples/s]Tokenizing texts... (num_proc=6):  39%|███▉      | 825000/2105244 [01:29<02:20, 9114.22 examples/s] Tokenizing texts... (num_proc=6):  39%|███▉      | 827000/2105244 [01:29<02:06, 10132.47 examples/s]Tokenizing texts... (num_proc=6):  39%|███▉      | 829000/2105244 [01:29<01:58, 10749.35 examples/s]Tokenizing texts... (num_proc=6):  39%|███▉      | 831000/2105244 [01:30<02:23, 8850.17 examples/s] Tokenizing texts... (num_proc=6):  40%|███▉      | 833000/2105244 [01:30<02:02, 10418.19 examples/s]Tokenizing texts... (num_proc=6):  40%|███▉      | 835000/2105244 [01:30<02:14, 9413.67 examples/s] Tokenizing texts... (num_proc=6):  40%|███▉      | 837000/2105244 [01:30<02:13, 9480.64 examples/s]Tokenizing texts... (num_proc=6):  40%|███▉      | 839000/2105244 [01:30<01:55, 10989.55 examples/s]Tokenizing texts... (num_proc=6):  40%|███▉      | 841000/2105244 [01:31<02:26, 8604.71 examples/s] Tokenizing texts... (num_proc=6):  40%|████      | 843000/2105244 [01:31<02:13, 9487.25 examples/s]Tokenizing texts... (num_proc=6):  40%|████      | 846000/2105244 [01:31<02:27, 8540.06 examples/s]Tokenizing texts... (num_proc=6):  40%|████      | 849000/2105244 [01:31<02:09, 9700.46 examples/s]Tokenizing texts... (num_proc=6):  40%|████      | 852000/2105244 [01:32<02:03, 10133.62 examples/s]Tokenizing texts... (num_proc=6):  41%|████      | 854000/2105244 [01:32<02:16, 9184.06 examples/s] Tokenizing texts... (num_proc=6):  41%|████      | 856000/2105244 [01:32<01:59, 10449.08 examples/s]Tokenizing texts... (num_proc=6):  41%|████      | 858000/2105244 [01:32<01:46, 11669.07 examples/s]Tokenizing texts... (num_proc=6):  41%|████      | 860000/2105244 [01:33<02:21, 8787.08 examples/s] Tokenizing texts... (num_proc=6):  41%|████      | 862000/2105244 [01:33<02:04, 9974.54 examples/s]Tokenizing texts... (num_proc=6):  41%|████      | 865000/2105244 [01:33<02:29, 8318.57 examples/s]Tokenizing texts... (num_proc=6):  41%|████      | 868000/2105244 [01:33<01:54, 10840.88 examples/s]Tokenizing texts... (num_proc=6):  41%|████▏     | 871000/2105244 [01:34<02:16, 9028.91 examples/s] Tokenizing texts... (num_proc=6):  41%|████▏     | 873000/2105244 [01:34<02:13, 9217.20 examples/s]Tokenizing texts... (num_proc=6):  42%|████▏     | 877000/2105244 [01:34<01:58, 10372.49 examples/s]Tokenizing texts... (num_proc=6):  42%|████▏     | 879000/2105244 [01:35<02:21, 8694.19 examples/s] Tokenizing texts... (num_proc=6):  42%|████▏     | 882000/2105244 [01:35<01:52, 10908.47 examples/s]Tokenizing texts... (num_proc=6):  42%|████▏     | 884000/2105244 [01:35<01:51, 10927.69 examples/s]Tokenizing texts... (num_proc=6):  42%|████▏     | 886000/2105244 [01:35<02:17, 8874.84 examples/s] Tokenizing texts... (num_proc=6):  42%|████▏     | 889000/2105244 [01:35<01:44, 11618.31 examples/s]Tokenizing texts... (num_proc=6):  42%|████▏     | 891000/2105244 [01:36<02:28, 8159.10 examples/s] Tokenizing texts... (num_proc=6):  42%|████▏     | 893000/2105244 [01:36<02:09, 9381.15 examples/s]Tokenizing texts... (num_proc=6):  43%|████▎     | 896000/2105244 [01:36<01:40, 11986.26 examples/s]Tokenizing texts... (num_proc=6):  43%|████▎     | 898000/2105244 [01:37<02:18, 8725.70 examples/s] Tokenizing texts... (num_proc=6):  43%|████▎     | 900000/2105244 [01:37<02:09, 9311.86 examples/s]Tokenizing texts... (num_proc=6):  43%|████▎     | 903000/2105244 [01:37<02:12, 9061.04 examples/s]Tokenizing texts... (num_proc=6):  43%|████▎     | 905000/2105244 [01:37<02:14, 8899.58 examples/s]Tokenizing texts... (num_proc=6):  43%|████▎     | 909000/2105244 [01:38<01:53, 10577.11 examples/s]Tokenizing texts... (num_proc=6):  43%|████▎     | 911000/2105244 [01:38<02:05, 9500.17 examples/s] Tokenizing texts... (num_proc=6):  43%|████▎     | 913000/2105244 [01:38<01:52, 10604.42 examples/s]Tokenizing texts... (num_proc=6):  43%|████▎     | 915000/2105244 [01:38<01:41, 11750.45 examples/s]Tokenizing texts... (num_proc=6):  44%|████▎     | 917000/2105244 [01:38<02:11, 9055.30 examples/s] Tokenizing texts... (num_proc=6):  44%|████▎     | 919000/2105244 [01:39<02:03, 9642.11 examples/s]Tokenizing texts... (num_proc=6):  44%|████▎     | 921000/2105244 [01:39<01:46, 11159.82 examples/s]Tokenizing texts... (num_proc=6):  44%|████▍     | 923000/2105244 [01:39<02:09, 9157.13 examples/s] Tokenizing texts... (num_proc=6):  44%|████▍     | 925000/2105244 [01:39<02:06, 9329.48 examples/s]Tokenizing texts... (num_proc=6):  44%|████▍     | 927000/2105244 [01:39<01:59, 9841.99 examples/s]Tokenizing texts... (num_proc=6):  44%|████▍     | 929000/2105244 [01:40<01:59, 9840.93 examples/s]Tokenizing texts... (num_proc=6):  44%|████▍     | 931000/2105244 [01:40<02:07, 9228.99 examples/s]Tokenizing texts... (num_proc=6):  44%|████▍     | 932000/2105244 [01:40<02:26, 8018.71 examples/s]Tokenizing texts... (num_proc=6):  44%|████▍     | 935000/2105244 [01:40<01:49, 10730.18 examples/s]Tokenizing texts... (num_proc=6):  45%|████▍     | 937000/2105244 [01:41<02:05, 9299.99 examples/s] Tokenizing texts... (num_proc=6):  45%|████▍     | 939000/2105244 [01:41<02:09, 9037.63 examples/s]Tokenizing texts... (num_proc=6):  45%|████▍     | 941000/2105244 [01:41<01:48, 10768.71 examples/s]Tokenizing texts... (num_proc=6):  45%|████▍     | 943000/2105244 [01:41<02:07, 9124.87 examples/s] Tokenizing texts... (num_proc=6):  45%|████▍     | 945000/2105244 [01:41<02:19, 8300.76 examples/s]Tokenizing texts... (num_proc=6):  45%|████▌     | 949000/2105244 [01:42<01:49, 10528.16 examples/s]Tokenizing texts... (num_proc=6):  45%|████▌     | 951000/2105244 [01:42<02:12, 8682.29 examples/s] Tokenizing texts... (num_proc=6):  45%|████▌     | 954000/2105244 [01:42<01:43, 11084.45 examples/s]Tokenizing texts... (num_proc=6):  45%|████▌     | 956000/2105244 [01:42<01:51, 10349.30 examples/s]Tokenizing texts... (num_proc=6):  46%|████▌     | 958000/2105244 [01:43<02:00, 9551.75 examples/s] Tokenizing texts... (num_proc=6):  46%|████▌     | 960000/2105244 [01:43<01:47, 10654.86 examples/s]Tokenizing texts... (num_proc=6):  46%|████▌     | 962000/2105244 [01:43<01:57, 9735.74 examples/s] Tokenizing texts... (num_proc=6):  46%|████▌     | 964000/2105244 [01:43<01:47, 10632.18 examples/s]Tokenizing texts... (num_proc=6):  46%|████▌     | 966000/2105244 [01:43<01:59, 9501.70 examples/s] Tokenizing texts... (num_proc=6):  46%|████▌     | 968000/2105244 [01:44<01:56, 9769.26 examples/s]Tokenizing texts... (num_proc=6):  46%|████▌     | 970000/2105244 [01:44<01:42, 11107.70 examples/s]Tokenizing texts... (num_proc=6):  46%|████▌     | 972000/2105244 [01:44<02:11, 8585.40 examples/s] Tokenizing texts... (num_proc=6):  46%|████▋     | 974000/2105244 [01:44<02:03, 9162.62 examples/s]Tokenizing texts... (num_proc=6):  46%|████▋     | 977000/2105244 [01:45<01:58, 9558.55 examples/s]Tokenizing texts... (num_proc=6):  47%|████▋     | 979000/2105244 [01:45<01:54, 9874.74 examples/s]Tokenizing texts... (num_proc=6):  47%|████▋     | 981000/2105244 [01:45<01:49, 10310.40 examples/s]Tokenizing texts... (num_proc=6):  47%|████▋     | 983000/2105244 [01:45<01:39, 11265.02 examples/s]Tokenizing texts... (num_proc=6):  47%|████▋     | 985000/2105244 [01:45<02:06, 8838.10 examples/s] Tokenizing texts... (num_proc=6):  47%|████▋     | 987000/2105244 [01:46<01:53, 9856.80 examples/s]Tokenizing texts... (num_proc=6):  47%|████▋     | 990000/2105244 [01:46<01:52, 9888.91 examples/s]Tokenizing texts... (num_proc=6):  47%|████▋     | 992000/2105244 [01:46<01:54, 9725.05 examples/s]Tokenizing texts... (num_proc=6):  47%|████▋     | 994000/2105244 [01:46<01:48, 10287.16 examples/s]Tokenizing texts... (num_proc=6):  47%|████▋     | 996000/2105244 [01:47<01:55, 9608.53 examples/s] Tokenizing texts... (num_proc=6):  47%|████▋     | 998000/2105244 [01:47<01:51, 9922.33 examples/s]Tokenizing texts... (num_proc=6):  48%|████▊     | 1000000/2105244 [01:47<01:52, 9861.34 examples/s]Tokenizing texts... (num_proc=6):  48%|████▊     | 1002000/2105244 [01:47<01:48, 10208.38 examples/s]Tokenizing texts... (num_proc=6):  48%|████▊     | 1004000/2105244 [01:47<01:47, 10289.23 examples/s]Tokenizing texts... (num_proc=6):  48%|████▊     | 1006000/2105244 [01:48<02:02, 8997.76 examples/s] Tokenizing texts... (num_proc=6):  48%|████▊     | 1008000/2105244 [01:48<01:50, 9938.12 examples/s]Tokenizing texts... (num_proc=6):  48%|████▊     | 1010000/2105244 [01:48<01:40, 10902.77 examples/s]Tokenizing texts... (num_proc=6):  48%|████▊     | 1012000/2105244 [01:48<01:48, 10065.33 examples/s]Tokenizing texts... (num_proc=6):  48%|████▊     | 1014000/2105244 [01:48<02:00, 9087.70 examples/s] Tokenizing texts... (num_proc=6):  48%|████▊     | 1017000/2105244 [01:49<01:38, 11056.77 examples/s]Tokenizing texts... (num_proc=6):  48%|████▊     | 1019000/2105244 [01:49<01:53, 9570.83 examples/s] Tokenizing texts... (num_proc=6):  48%|████▊     | 1021000/2105244 [01:49<01:51, 9681.27 examples/s]Tokenizing texts... (num_proc=6):  49%|████▊     | 1023000/2105244 [01:49<01:38, 10998.39 examples/s]Tokenizing texts... (num_proc=6):  49%|████▊     | 1025000/2105244 [01:49<01:59, 9059.44 examples/s] Tokenizing texts... (num_proc=6):  49%|████▉     | 1027000/2105244 [01:50<01:54, 9417.30 examples/s]Tokenizing texts... (num_proc=6):  49%|████▉     | 1029000/2105244 [01:50<01:43, 10429.90 examples/s]Tokenizing texts... (num_proc=6):  49%|████▉     | 1031000/2105244 [01:50<02:02, 8746.00 examples/s] Tokenizing texts... (num_proc=6):  49%|████▉     | 1034000/2105244 [01:50<01:52, 9547.81 examples/s]Tokenizing texts... (num_proc=6):  49%|████▉     | 1036000/2105244 [01:51<02:06, 8434.54 examples/s]Tokenizing texts... (num_proc=6):  49%|████▉     | 1039000/2105244 [01:51<01:33, 11394.21 examples/s]Tokenizing texts... (num_proc=6):  49%|████▉     | 1041000/2105244 [01:51<02:04, 8548.76 examples/s] Tokenizing texts... (num_proc=6):  50%|████▉     | 1043000/2105244 [01:51<01:46, 10000.31 examples/s]Tokenizing texts... (num_proc=6):  50%|████▉     | 1045000/2105244 [01:51<01:37, 10858.83 examples/s]Tokenizing texts... (num_proc=6):  50%|████▉     | 1047000/2105244 [01:52<02:06, 8358.35 examples/s] Tokenizing texts... (num_proc=6):  50%|████▉     | 1050000/2105244 [01:52<01:58, 8894.99 examples/s]Tokenizing texts... (num_proc=6):  50%|████▉     | 1052000/2105244 [01:52<01:48, 9732.22 examples/s]Tokenizing texts... (num_proc=6):  50%|█████     | 1054000/2105244 [01:52<01:46, 9884.46 examples/s]Tokenizing texts... (num_proc=6):  50%|█████     | 1056000/2105244 [01:53<01:58, 8854.04 examples/s]Tokenizing texts... (num_proc=6):  50%|█████     | 1058000/2105244 [01:53<01:47, 9776.59 examples/s]Tokenizing texts... (num_proc=6):  50%|█████     | 1060000/2105244 [01:53<01:35, 10955.44 examples/s]Tokenizing texts... (num_proc=6):  50%|█████     | 1062000/2105244 [01:53<01:59, 8734.36 examples/s] Tokenizing texts... (num_proc=6):  51%|█████     | 1065000/2105244 [01:54<01:34, 10974.56 examples/s]Tokenizing texts... (num_proc=6):  51%|█████     | 1067000/2105244 [01:54<02:10, 7946.08 examples/s] Tokenizing texts... (num_proc=6):  51%|█████     | 1070000/2105244 [01:54<01:39, 10412.71 examples/s]Tokenizing texts... (num_proc=6):  51%|█████     | 1073000/2105244 [01:55<01:50, 9302.91 examples/s] Tokenizing texts... (num_proc=6):  51%|█████     | 1075000/2105244 [01:55<01:43, 9940.43 examples/s]Tokenizing texts... (num_proc=6):  51%|█████     | 1077000/2105244 [01:55<01:31, 11242.89 examples/s]Tokenizing texts... (num_proc=6):  51%|█████▏    | 1079000/2105244 [01:55<01:43, 9918.30 examples/s] Tokenizing texts... (num_proc=6):  51%|█████▏    | 1081000/2105244 [01:55<01:57, 8689.08 examples/s]Tokenizing texts... (num_proc=6):  52%|█████▏    | 1085000/2105244 [01:56<01:32, 11077.42 examples/s]Tokenizing texts... (num_proc=6):  52%|█████▏    | 1087000/2105244 [01:56<02:03, 8258.28 examples/s] Tokenizing texts... (num_proc=6):  52%|█████▏    | 1091000/2105244 [01:56<01:23, 12175.64 examples/s]Tokenizing texts... (num_proc=6):  52%|█████▏    | 1093000/2105244 [01:57<02:03, 8187.29 examples/s] Tokenizing texts... (num_proc=6):  52%|█████▏    | 1096000/2105244 [01:57<01:37, 10362.71 examples/s]Tokenizing texts... (num_proc=6):  52%|█████▏    | 1098000/2105244 [01:57<02:04, 8101.37 examples/s] Tokenizing texts... (num_proc=6):  52%|█████▏    | 1102000/2105244 [01:57<01:41, 9904.79 examples/s]Tokenizing texts... (num_proc=6):  52%|█████▏    | 1104000/2105244 [01:58<01:46, 9363.54 examples/s]Tokenizing texts... (num_proc=6):  53%|█████▎    | 1106000/2105244 [01:58<01:42, 9774.73 examples/s]Tokenizing texts... (num_proc=6):  53%|█████▎    | 1108000/2105244 [01:58<01:47, 9299.23 examples/s]Tokenizing texts... (num_proc=6):  53%|█████▎    | 1110000/2105244 [01:58<01:36, 10339.83 examples/s]Tokenizing texts... (num_proc=6):  53%|█████▎    | 1112000/2105244 [01:59<01:42, 9670.59 examples/s] Tokenizing texts... (num_proc=6):  53%|█████▎    | 1114000/2105244 [01:59<01:46, 9295.87 examples/s]Tokenizing texts... (num_proc=6):  53%|█████▎    | 1116000/2105244 [01:59<01:41, 9698.71 examples/s]Tokenizing texts... (num_proc=6):  53%|█████▎    | 1118000/2105244 [01:59<01:41, 9722.80 examples/s]Tokenizing texts... (num_proc=6):  53%|█████▎    | 1120000/2105244 [01:59<01:28, 11087.16 examples/s]Tokenizing texts... (num_proc=6):  53%|█████▎    | 1122000/2105244 [02:00<01:46, 9272.98 examples/s] Tokenizing texts... (num_proc=6):  53%|█████▎    | 1124000/2105244 [02:00<01:43, 9492.75 examples/s]Tokenizing texts... (num_proc=6):  54%|█████▎    | 1127000/2105244 [02:00<01:50, 8871.80 examples/s]Tokenizing texts... (num_proc=6):  54%|█████▎    | 1129000/2105244 [02:00<01:38, 9949.66 examples/s]Tokenizing texts... (num_proc=6):  54%|█████▍    | 1132000/2105244 [02:00<01:23, 11631.19 examples/s]Tokenizing texts... (num_proc=6):  54%|█████▍    | 1134000/2105244 [02:01<01:41, 9546.82 examples/s] Tokenizing texts... (num_proc=6):  54%|█████▍    | 1136000/2105244 [02:01<01:42, 9478.34 examples/s]Tokenizing texts... (num_proc=6):  54%|█████▍    | 1139000/2105244 [02:01<01:38, 9792.53 examples/s]Tokenizing texts... (num_proc=6):  54%|█████▍    | 1141000/2105244 [02:02<01:53, 8520.93 examples/s]Tokenizing texts... (num_proc=6):  54%|█████▍    | 1143000/2105244 [02:02<01:40, 9573.67 examples/s]Tokenizing texts... (num_proc=6):  54%|█████▍    | 1146000/2105244 [02:02<01:22, 11648.52 examples/s]Tokenizing texts... (num_proc=6):  55%|█████▍    | 1148000/2105244 [02:02<01:50, 8644.63 examples/s] Tokenizing texts... (num_proc=6):  55%|█████▍    | 1151000/2105244 [02:02<01:25, 11139.91 examples/s]Tokenizing texts... (num_proc=6):  55%|█████▍    | 1153000/2105244 [02:03<01:49, 8695.75 examples/s] Tokenizing texts... (num_proc=6):  55%|█████▍    | 1155000/2105244 [02:03<01:40, 9477.52 examples/s]Tokenizing texts... (num_proc=6):  55%|█████▍    | 1157000/2105244 [02:03<01:28, 10720.60 examples/s]Tokenizing texts... (num_proc=6):  55%|█████▌    | 1159000/2105244 [02:03<01:25, 11010.11 examples/s]Tokenizing texts... (num_proc=6):  55%|█████▌    | 1161000/2105244 [02:04<01:51, 8485.40 examples/s] Tokenizing texts... (num_proc=6):  55%|█████▌    | 1164000/2105244 [02:04<01:28, 10673.75 examples/s]Tokenizing texts... (num_proc=6):  55%|█████▌    | 1166000/2105244 [02:04<01:43, 9054.96 examples/s] Tokenizing texts... (num_proc=6):  55%|█████▌    | 1168000/2105244 [02:04<01:41, 9275.50 examples/s]Tokenizing texts... (num_proc=6):  56%|█████▌    | 1171000/2105244 [02:04<01:21, 11399.75 examples/s]Tokenizing texts... (num_proc=6):  56%|█████▌    | 1173000/2105244 [02:05<01:42, 9116.77 examples/s] Tokenizing texts... (num_proc=6):  56%|█████▌    | 1175000/2105244 [02:05<01:30, 10277.49 examples/s]Tokenizing texts... (num_proc=6):  56%|█████▌    | 1177000/2105244 [02:05<01:33, 9918.07 examples/s] Tokenizing texts... (num_proc=6):  56%|█████▌    | 1179000/2105244 [02:05<01:32, 10042.58 examples/s]Tokenizing texts... (num_proc=6):  56%|█████▌    | 1181000/2105244 [02:06<01:33, 9842.36 examples/s] Tokenizing texts... (num_proc=6):  56%|█████▌    | 1183000/2105244 [02:06<01:35, 9639.98 examples/s]Tokenizing texts... (num_proc=6):  56%|█████▋    | 1185000/2105244 [02:06<01:38, 9302.00 examples/s]Tokenizing texts... (num_proc=6):  56%|█████▋    | 1186000/2105244 [02:06<01:39, 9206.28 examples/s]Tokenizing texts... (num_proc=6):  56%|█████▋    | 1188000/2105244 [02:06<01:28, 10416.46 examples/s]Tokenizing texts... (num_proc=6):  57%|█████▋    | 1190000/2105244 [02:07<01:38, 9316.84 examples/s] Tokenizing texts... (num_proc=6):  57%|█████▋    | 1192000/2105244 [02:07<01:41, 8967.65 examples/s]Tokenizing texts... (num_proc=6):  57%|█████▋    | 1195000/2105244 [02:07<01:27, 10402.53 examples/s]Tokenizing texts... (num_proc=6):  57%|█████▋    | 1197000/2105244 [02:07<01:29, 10153.02 examples/s]Tokenizing texts... (num_proc=6):  57%|█████▋    | 1199000/2105244 [02:07<01:27, 10328.51 examples/s]Tokenizing texts... (num_proc=6):  57%|█████▋    | 1201000/2105244 [02:08<01:36, 9356.05 examples/s] Tokenizing texts... (num_proc=6):  57%|█████▋    | 1202000/2105244 [02:08<01:36, 9399.30 examples/s]Tokenizing texts... (num_proc=6):  57%|█████▋    | 1204000/2105244 [02:08<01:23, 10783.96 examples/s]Tokenizing texts... (num_proc=6):  57%|█████▋    | 1206000/2105244 [02:08<01:30, 9883.45 examples/s] Tokenizing texts... (num_proc=6):  57%|█████▋    | 1208000/2105244 [02:08<01:28, 10103.09 examples/s]Tokenizing texts... (num_proc=6):  57%|█████▋    | 1210000/2105244 [02:09<01:37, 9225.77 examples/s] Tokenizing texts... (num_proc=6):  58%|█████▊    | 1212000/2105244 [02:09<01:31, 9745.44 examples/s]Tokenizing texts... (num_proc=6):  58%|█████▊    | 1214000/2105244 [02:09<01:27, 10183.13 examples/s]Tokenizing texts... (num_proc=6):  58%|█████▊    | 1216000/2105244 [02:09<01:43, 8629.02 examples/s] Tokenizing texts... (num_proc=6):  58%|█████▊    | 1219000/2105244 [02:10<01:34, 9373.62 examples/s]Tokenizing texts... (num_proc=6):  58%|█████▊    | 1221000/2105244 [02:10<01:21, 10848.10 examples/s]Tokenizing texts... (num_proc=6):  58%|█████▊    | 1223000/2105244 [02:10<01:30, 9772.40 examples/s] Tokenizing texts... (num_proc=6):  58%|█████▊    | 1225000/2105244 [02:10<01:31, 9668.40 examples/s]Tokenizing texts... (num_proc=6):  58%|█████▊    | 1227000/2105244 [02:10<01:29, 9819.38 examples/s]Tokenizing texts... (num_proc=6):  58%|█████▊    | 1229000/2105244 [02:10<01:28, 9902.93 examples/s]Tokenizing texts... (num_proc=6):  58%|█████▊    | 1231000/2105244 [02:11<01:30, 9618.83 examples/s]Tokenizing texts... (num_proc=6):  59%|█████▊    | 1232000/2105244 [02:11<01:32, 9420.02 examples/s]Tokenizing texts... (num_proc=6):  59%|█████▊    | 1234000/2105244 [02:11<01:19, 10968.30 examples/s]Tokenizing texts... (num_proc=6):  59%|█████▊    | 1236000/2105244 [02:11<01:44, 8330.86 examples/s] Tokenizing texts... (num_proc=6):  59%|█████▉    | 1239000/2105244 [02:11<01:21, 10641.85 examples/s]Tokenizing texts... (num_proc=6):  59%|█████▉    | 1241000/2105244 [02:12<01:26, 9959.94 examples/s] Tokenizing texts... (num_proc=6):  59%|█████▉    | 1243000/2105244 [02:12<01:38, 8733.45 examples/s]Tokenizing texts... (num_proc=6):  59%|█████▉    | 1245000/2105244 [02:12<01:22, 10406.67 examples/s]Tokenizing texts... (num_proc=6):  59%|█████▉    | 1247000/2105244 [02:12<01:25, 10060.74 examples/s]Tokenizing texts... (num_proc=6):  59%|█████▉    | 1249000/2105244 [02:13<01:36, 8868.29 examples/s] Tokenizing texts... (num_proc=6):  59%|█████▉    | 1251000/2105244 [02:13<01:25, 9976.69 examples/s]Tokenizing texts... (num_proc=6):  60%|█████▉    | 1253000/2105244 [02:13<01:21, 10428.72 examples/s]Tokenizing texts... (num_proc=6):  60%|█████▉    | 1255000/2105244 [02:13<01:30, 9356.01 examples/s] Tokenizing texts... (num_proc=6):  60%|█████▉    | 1257000/2105244 [02:13<01:27, 9724.31 examples/s]Tokenizing texts... (num_proc=6):  60%|█████▉    | 1259000/2105244 [02:14<01:24, 10066.19 examples/s]Tokenizing texts... (num_proc=6):  60%|█████▉    | 1261000/2105244 [02:14<01:24, 9975.28 examples/s] Tokenizing texts... (num_proc=6):  60%|█████▉    | 1263000/2105244 [02:14<01:32, 9140.01 examples/s]Tokenizing texts... (num_proc=6):  60%|██████    | 1265000/2105244 [02:14<01:24, 9941.55 examples/s]Tokenizing texts... (num_proc=6):  60%|██████    | 1267000/2105244 [02:14<01:19, 10585.34 examples/s]Tokenizing texts... (num_proc=6):  60%|██████    | 1269000/2105244 [02:15<01:32, 9034.16 examples/s] Tokenizing texts... (num_proc=6):  60%|██████    | 1271000/2105244 [02:15<01:25, 9743.10 examples/s]Tokenizing texts... (num_proc=6):  60%|██████    | 1273000/2105244 [02:15<01:15, 11093.22 examples/s]Tokenizing texts... (num_proc=6):  61%|██████    | 1275000/2105244 [02:15<01:35, 8672.90 examples/s] Tokenizing texts... (num_proc=6):  61%|██████    | 1277000/2105244 [02:15<01:26, 9560.08 examples/s]Tokenizing texts... (num_proc=6):  61%|██████    | 1280000/2105244 [02:16<01:22, 9970.48 examples/s]Tokenizing texts... (num_proc=6):  61%|██████    | 1282000/2105244 [02:16<01:35, 8584.26 examples/s]Tokenizing texts... (num_proc=6):  61%|██████    | 1286000/2105244 [02:16<01:24, 9659.95 examples/s]Tokenizing texts... (num_proc=6):  61%|██████    | 1288000/2105244 [02:17<01:23, 9761.19 examples/s]Tokenizing texts... (num_proc=6):  61%|██████▏   | 1290000/2105244 [02:17<01:15, 10825.12 examples/s]Tokenizing texts... (num_proc=6):  61%|██████▏   | 1292000/2105244 [02:17<01:29, 9084.08 examples/s] Tokenizing texts... (num_proc=6):  61%|██████▏   | 1294000/2105244 [02:17<01:27, 9267.61 examples/s]Tokenizing texts... (num_proc=6):  62%|██████▏   | 1296000/2105244 [02:17<01:16, 10627.25 examples/s]Tokenizing texts... (num_proc=6):  62%|██████▏   | 1298000/2105244 [02:18<01:30, 8924.23 examples/s] Tokenizing texts... (num_proc=6):  62%|██████▏   | 1300000/2105244 [02:18<01:28, 9148.70 examples/s]Tokenizing texts... (num_proc=6):  62%|██████▏   | 1303000/2105244 [02:18<01:22, 9731.41 examples/s]Tokenizing texts... (num_proc=6):  62%|██████▏   | 1305000/2105244 [02:18<01:23, 9552.15 examples/s]Tokenizing texts... (num_proc=6):  62%|██████▏   | 1307000/2105244 [02:19<01:15, 10611.86 examples/s]Tokenizing texts... (num_proc=6):  62%|██████▏   | 1309000/2105244 [02:19<01:09, 11518.84 examples/s]Tokenizing texts... (num_proc=6):  62%|██████▏   | 1311000/2105244 [02:19<01:33, 8516.76 examples/s] Tokenizing texts... (num_proc=6):  62%|██████▏   | 1314000/2105244 [02:19<01:07, 11706.16 examples/s]Tokenizing texts... (num_proc=6):  63%|██████▎   | 1316000/2105244 [02:20<01:39, 7918.29 examples/s] Tokenizing texts... (num_proc=6):  63%|██████▎   | 1319000/2105244 [02:20<01:14, 10539.78 examples/s]Tokenizing texts... (num_proc=6):  63%|██████▎   | 1321000/2105244 [02:20<01:06, 11761.59 examples/s]Tokenizing texts... (num_proc=6):  63%|██████▎   | 1323000/2105244 [02:20<01:27, 8911.93 examples/s] Tokenizing texts... (num_proc=6):  63%|██████▎   | 1325000/2105244 [02:20<01:23, 9295.01 examples/s]Tokenizing texts... (num_proc=6):  63%|██████▎   | 1328000/2105244 [02:21<01:09, 11138.08 examples/s]Tokenizing texts... (num_proc=6):  63%|██████▎   | 1330000/2105244 [02:21<01:35, 8128.67 examples/s] Tokenizing texts... (num_proc=6):  63%|██████▎   | 1334000/2105244 [02:21<01:04, 11950.80 examples/s]Tokenizing texts... (num_proc=6):  63%|██████▎   | 1336000/2105244 [02:22<01:26, 8848.38 examples/s] Tokenizing texts... (num_proc=6):  64%|██████▎   | 1338000/2105244 [02:22<01:19, 9593.10 examples/s]Tokenizing texts... (num_proc=6):  64%|██████▎   | 1340000/2105244 [02:22<01:08, 11107.69 examples/s]Tokenizing texts... (num_proc=6):  64%|██████▎   | 1342000/2105244 [02:22<01:13, 10325.70 examples/s]Tokenizing texts... (num_proc=6):  64%|██████▍   | 1344000/2105244 [02:22<01:26, 8806.06 examples/s] Tokenizing texts... (num_proc=6):  64%|██████▍   | 1346000/2105244 [02:23<01:17, 9774.56 examples/s]Tokenizing texts... (num_proc=6):  64%|██████▍   | 1349000/2105244 [02:23<01:37, 7764.10 examples/s]Tokenizing texts... (num_proc=6):  64%|██████▍   | 1354000/2105244 [02:23<01:02, 11958.83 examples/s]Tokenizing texts... (num_proc=6):  64%|██████▍   | 1356000/2105244 [02:24<01:27, 8568.84 examples/s] Tokenizing texts... (num_proc=6):  65%|██████▍   | 1360000/2105244 [02:24<01:08, 10859.69 examples/s]Tokenizing texts... (num_proc=6):  65%|██████▍   | 1362000/2105244 [02:24<01:24, 8789.40 examples/s] Tokenizing texts... (num_proc=6):  65%|██████▍   | 1365000/2105244 [02:24<01:05, 11234.16 examples/s]Tokenizing texts... (num_proc=6):  65%|██████▍   | 1367000/2105244 [02:25<01:07, 10914.47 examples/s]Tokenizing texts... (num_proc=6):  65%|██████▌   | 1369000/2105244 [02:25<01:23, 8778.09 examples/s] Tokenizing texts... (num_proc=6):  65%|██████▌   | 1373000/2105244 [02:25<01:12, 10086.06 examples/s]Tokenizing texts... (num_proc=6):  65%|██████▌   | 1375000/2105244 [02:25<01:16, 9530.41 examples/s] Tokenizing texts... (num_proc=6):  65%|██████▌   | 1378000/2105244 [02:26<01:04, 11237.05 examples/s]Tokenizing texts... (num_proc=6):  66%|██████▌   | 1380000/2105244 [02:26<01:17, 9406.74 examples/s] Tokenizing texts... (num_proc=6):  66%|██████▌   | 1382000/2105244 [02:26<01:18, 9191.41 examples/s]Tokenizing texts... (num_proc=6):  66%|██████▌   | 1384000/2105244 [02:26<01:09, 10428.06 examples/s]Tokenizing texts... (num_proc=6):  66%|██████▌   | 1386000/2105244 [02:27<01:16, 9359.07 examples/s] Tokenizing texts... (num_proc=6):  66%|██████▌   | 1388000/2105244 [02:27<01:18, 9148.50 examples/s]Tokenizing texts... (num_proc=6):  66%|██████▌   | 1390000/2105244 [02:27<01:11, 9934.50 examples/s]Tokenizing texts... (num_proc=6):  66%|██████▌   | 1392000/2105244 [02:27<01:12, 9817.34 examples/s]Tokenizing texts... (num_proc=6):  66%|██████▌   | 1394000/2105244 [02:27<01:18, 9016.77 examples/s]Tokenizing texts... (num_proc=6):  66%|██████▋   | 1396000/2105244 [02:28<01:14, 9575.77 examples/s]Tokenizing texts... (num_proc=6):  66%|██████▋   | 1398000/2105244 [02:28<01:20, 8746.50 examples/s]Tokenizing texts... (num_proc=6):  67%|██████▋   | 1401000/2105244 [02:28<01:04, 10936.49 examples/s]Tokenizing texts... (num_proc=6):  67%|██████▋   | 1403000/2105244 [02:28<01:07, 10457.80 examples/s]Tokenizing texts... (num_proc=6):  67%|██████▋   | 1405000/2105244 [02:29<01:08, 10205.79 examples/s]Tokenizing texts... (num_proc=6):  67%|██████▋   | 1407000/2105244 [02:29<01:07, 10351.01 examples/s]Tokenizing texts... (num_proc=6):  67%|██████▋   | 1409000/2105244 [02:29<01:15, 9241.48 examples/s] Tokenizing texts... (num_proc=6):  67%|██████▋   | 1411000/2105244 [02:29<01:06, 10508.87 examples/s]Tokenizing texts... (num_proc=6):  67%|██████▋   | 1413000/2105244 [02:29<01:10, 9863.95 examples/s] Tokenizing texts... (num_proc=6):  67%|██████▋   | 1415000/2105244 [02:30<01:14, 9280.79 examples/s]Tokenizing texts... (num_proc=6):  67%|██████▋   | 1417000/2105244 [02:30<01:03, 10854.96 examples/s]Tokenizing texts... (num_proc=6):  67%|██████▋   | 1419000/2105244 [02:30<01:18, 8762.02 examples/s] Tokenizing texts... (num_proc=6):  67%|██████▋   | 1421000/2105244 [02:30<01:15, 9072.89 examples/s]Tokenizing texts... (num_proc=6):  68%|██████▊   | 1424000/2105244 [02:31<01:13, 9306.56 examples/s]Tokenizing texts... (num_proc=6):  68%|██████▊   | 1426000/2105244 [02:31<01:08, 9969.21 examples/s]Tokenizing texts... (num_proc=6):  68%|██████▊   | 1428000/2105244 [02:31<01:05, 10308.60 examples/s]Tokenizing texts... (num_proc=6):  68%|██████▊   | 1430000/2105244 [02:31<01:18, 8567.49 examples/s] Tokenizing texts... (num_proc=6):  68%|██████▊   | 1432000/2105244 [02:31<01:13, 9161.56 examples/s]Tokenizing texts... (num_proc=6):  68%|██████▊   | 1434000/2105244 [02:32<01:06, 10165.06 examples/s]Tokenizing texts... (num_proc=6):  68%|██████▊   | 1436000/2105244 [02:32<01:05, 10207.94 examples/s]Tokenizing texts... (num_proc=6):  68%|██████▊   | 1438000/2105244 [02:32<01:17, 8595.53 examples/s] Tokenizing texts... (num_proc=6):  68%|██████▊   | 1440000/2105244 [02:32<01:05, 10191.72 examples/s]Tokenizing texts... (num_proc=6):  69%|██████▊   | 1443000/2105244 [02:32<01:02, 10534.80 examples/s]Tokenizing texts... (num_proc=6):  69%|██████▊   | 1445000/2105244 [02:33<01:13, 8972.00 examples/s] Tokenizing texts... (num_proc=6):  69%|██████▉   | 1448000/2105244 [02:33<01:00, 10951.87 examples/s]Tokenizing texts... (num_proc=6):  69%|██████▉   | 1450000/2105244 [02:33<01:12, 9018.59 examples/s] Tokenizing texts... (num_proc=6):  69%|██████▉   | 1452000/2105244 [02:33<01:09, 9387.46 examples/s]Tokenizing texts... (num_proc=6):  69%|██████▉   | 1454000/2105244 [02:34<01:11, 9141.51 examples/s]Tokenizing texts... (num_proc=6):  69%|██████▉   | 1457000/2105244 [02:34<00:58, 11093.19 examples/s]Tokenizing texts... (num_proc=6):  69%|██████▉   | 1459000/2105244 [02:34<01:09, 9311.40 examples/s] Tokenizing texts... (num_proc=6):  69%|██████▉   | 1461000/2105244 [02:34<01:03, 10222.13 examples/s]Tokenizing texts... (num_proc=6):  69%|██████▉   | 1463000/2105244 [02:34<00:55, 11492.23 examples/s]Tokenizing texts... (num_proc=6):  70%|██████▉   | 1465000/2105244 [02:35<01:04, 9862.17 examples/s] Tokenizing texts... (num_proc=6):  70%|██████▉   | 1467000/2105244 [02:35<01:08, 9318.97 examples/s]Tokenizing texts... (num_proc=6):  70%|██████▉   | 1469000/2105244 [02:35<00:59, 10706.00 examples/s]Tokenizing texts... (num_proc=6):  70%|██████▉   | 1471000/2105244 [02:35<01:08, 9315.52 examples/s] Tokenizing texts... (num_proc=6):  70%|██████▉   | 1473000/2105244 [02:36<01:08, 9292.20 examples/s]Tokenizing texts... (num_proc=6):  70%|███████   | 1476000/2105244 [02:36<00:54, 11464.96 examples/s]Tokenizing texts... (num_proc=6):  70%|███████   | 1478000/2105244 [02:36<01:15, 8295.99 examples/s] Tokenizing texts... (num_proc=6):  70%|███████   | 1482000/2105244 [02:36<00:58, 10700.51 examples/s]Tokenizing texts... (num_proc=6):  70%|███████   | 1484000/2105244 [02:37<01:04, 9625.60 examples/s] Tokenizing texts... (num_proc=6):  71%|███████   | 1486000/2105244 [02:37<01:01, 10024.57 examples/s]Tokenizing texts... (num_proc=6):  71%|███████   | 1488000/2105244 [02:37<01:02, 9858.65 examples/s] Tokenizing texts... (num_proc=6):  71%|███████   | 1490000/2105244 [02:37<01:05, 9416.08 examples/s]Tokenizing texts... (num_proc=6):  71%|███████   | 1491000/2105244 [02:37<01:04, 9471.65 examples/s]Tokenizing texts... (num_proc=6):  71%|███████   | 1493000/2105244 [02:38<01:02, 9729.88 examples/s]Tokenizing texts... (num_proc=6):  71%|███████   | 1495000/2105244 [02:38<00:54, 11222.29 examples/s]Tokenizing texts... (num_proc=6):  71%|███████   | 1497000/2105244 [02:38<01:03, 9601.35 examples/s] Tokenizing texts... (num_proc=6):  71%|███████▏  | 1500000/2105244 [02:38<01:09, 8730.30 examples/s]Tokenizing texts... (num_proc=6):  71%|███████▏  | 1501000/2105244 [02:38<01:09, 8667.56 examples/s]Tokenizing texts... (num_proc=6):  71%|███████▏  | 1504000/2105244 [02:39<00:49, 12087.55 examples/s]Tokenizing texts... (num_proc=6):  72%|███████▏  | 1506000/2105244 [02:39<01:12, 8250.48 examples/s] Tokenizing texts... (num_proc=6):  72%|███████▏  | 1508000/2105244 [02:39<01:01, 9639.65 examples/s]Tokenizing texts... (num_proc=6):  72%|███████▏  | 1511000/2105244 [02:39<00:48, 12293.97 examples/s]Tokenizing texts... (num_proc=6):  72%|███████▏  | 1513000/2105244 [02:40<01:07, 8756.06 examples/s] Tokenizing texts... (num_proc=6):  72%|███████▏  | 1515000/2105244 [02:40<01:01, 9600.42 examples/s]Tokenizing texts... (num_proc=6):  72%|███████▏  | 1517000/2105244 [02:40<00:58, 10109.73 examples/s]Tokenizing texts... (num_proc=6):  72%|███████▏  | 1519000/2105244 [02:40<01:08, 8578.15 examples/s] Tokenizing texts... (num_proc=6):  72%|███████▏  | 1521000/2105244 [02:40<01:02, 9401.61 examples/s]Tokenizing texts... (num_proc=6):  72%|███████▏  | 1524000/2105244 [02:41<00:51, 11387.47 examples/s]Tokenizing texts... (num_proc=6):  72%|███████▏  | 1526000/2105244 [02:41<01:02, 9255.24 examples/s] Tokenizing texts... (num_proc=6):  73%|███████▎  | 1528000/2105244 [02:41<00:58, 9951.97 examples/s]Tokenizing texts... (num_proc=6):  73%|███████▎  | 1530000/2105244 [02:41<00:51, 11277.01 examples/s]Tokenizing texts... (num_proc=6):  73%|███████▎  | 1532000/2105244 [02:42<00:56, 10155.46 examples/s]Tokenizing texts... (num_proc=6):  73%|███████▎  | 1534000/2105244 [02:42<01:02, 9096.63 examples/s] Tokenizing texts... (num_proc=6):  73%|███████▎  | 1536000/2105244 [02:42<00:54, 10387.75 examples/s]Tokenizing texts... (num_proc=6):  73%|███████▎  | 1538000/2105244 [02:42<00:53, 10571.24 examples/s]Tokenizing texts... (num_proc=6):  73%|███████▎  | 1540000/2105244 [02:42<01:05, 8679.72 examples/s] Tokenizing texts... (num_proc=6):  73%|███████▎  | 1543000/2105244 [02:43<00:52, 10627.54 examples/s]Tokenizing texts... (num_proc=6):  73%|███████▎  | 1545000/2105244 [02:43<01:08, 8171.04 examples/s] Tokenizing texts... (num_proc=6):  74%|███████▎  | 1548000/2105244 [02:43<00:53, 10479.42 examples/s]Tokenizing texts... (num_proc=6):  74%|███████▎  | 1550000/2105244 [02:43<00:49, 11148.16 examples/s]Tokenizing texts... (num_proc=6):  74%|███████▎  | 1552000/2105244 [02:44<01:06, 8346.10 examples/s] Tokenizing texts... (num_proc=6):  74%|███████▍  | 1554000/2105244 [02:44<00:55, 9959.30 examples/s]Tokenizing texts... (num_proc=6):  74%|███████▍  | 1556000/2105244 [02:44<00:54, 10124.99 examples/s]Tokenizing texts... (num_proc=6):  74%|███████▍  | 1558000/2105244 [02:44<01:08, 8043.75 examples/s] Tokenizing texts... (num_proc=6):  74%|███████▍  | 1560000/2105244 [02:45<00:59, 9169.92 examples/s]Tokenizing texts... (num_proc=6):  74%|███████▍  | 1562000/2105244 [02:45<00:50, 10687.53 examples/s]Tokenizing texts... (num_proc=6):  74%|███████▍  | 1564000/2105244 [02:45<01:10, 7716.61 examples/s] Tokenizing texts... (num_proc=6):  74%|███████▍  | 1567000/2105244 [02:45<00:49, 10804.81 examples/s]Tokenizing texts... (num_proc=6):  75%|███████▍  | 1569000/2105244 [02:45<00:52, 10179.31 examples/s]Tokenizing texts... (num_proc=6):  75%|███████▍  | 1571000/2105244 [02:46<01:03, 8461.45 examples/s] Tokenizing texts... (num_proc=6):  75%|███████▍  | 1575000/2105244 [02:46<00:55, 9566.88 examples/s]Tokenizing texts... (num_proc=6):  75%|███████▍  | 1577000/2105244 [02:46<00:59, 8810.41 examples/s]Tokenizing texts... (num_proc=6):  75%|███████▌  | 1581000/2105244 [02:47<00:49, 10488.31 examples/s]Tokenizing texts... (num_proc=6):  75%|███████▌  | 1583000/2105244 [02:47<00:58, 8960.00 examples/s] Tokenizing texts... (num_proc=6):  75%|███████▌  | 1586000/2105244 [02:47<00:46, 11150.51 examples/s]Tokenizing texts... (num_proc=6):  75%|███████▌  | 1588000/2105244 [02:47<00:57, 9052.30 examples/s] Tokenizing texts... (num_proc=6):  76%|███████▌  | 1590000/2105244 [02:48<00:53, 9704.11 examples/s]Tokenizing texts... (num_proc=6):  76%|███████▌  | 1593000/2105244 [02:48<00:41, 12410.38 examples/s]Tokenizing texts... (num_proc=6):  76%|███████▌  | 1595000/2105244 [02:48<00:56, 9073.32 examples/s] Tokenizing texts... (num_proc=6):  76%|███████▌  | 1597000/2105244 [02:48<00:48, 10398.23 examples/s]Tokenizing texts... (num_proc=6):  76%|███████▌  | 1599000/2105244 [02:48<00:44, 11310.23 examples/s]Tokenizing texts... (num_proc=6):  76%|███████▌  | 1601000/2105244 [02:49<01:01, 8259.19 examples/s] Tokenizing texts... (num_proc=6):  76%|███████▌  | 1604000/2105244 [02:49<00:51, 9700.60 examples/s]Tokenizing texts... (num_proc=6):  76%|███████▋  | 1607000/2105244 [02:49<00:54, 9085.46 examples/s]Tokenizing texts... (num_proc=6):  76%|███████▋  | 1609000/2105244 [02:50<00:49, 10107.51 examples/s]Tokenizing texts... (num_proc=6):  77%|███████▋  | 1611000/2105244 [02:50<00:46, 10731.29 examples/s]Tokenizing texts... (num_proc=6):  77%|███████▋  | 1613000/2105244 [02:50<00:54, 9050.71 examples/s] Tokenizing texts... (num_proc=6):  77%|███████▋  | 1615000/2105244 [02:50<00:49, 9840.34 examples/s]Tokenizing texts... (num_proc=6):  77%|███████▋  | 1617000/2105244 [02:50<00:48, 10083.07 examples/s]Tokenizing texts... (num_proc=6):  77%|███████▋  | 1619000/2105244 [02:51<00:51, 9505.89 examples/s] Tokenizing texts... (num_proc=6):  77%|███████▋  | 1621000/2105244 [02:51<00:50, 9605.75 examples/s]Tokenizing texts... (num_proc=6):  77%|███████▋  | 1623000/2105244 [02:51<00:50, 9506.55 examples/s]Tokenizing texts... (num_proc=6):  77%|███████▋  | 1625000/2105244 [02:51<00:46, 10263.49 examples/s]Tokenizing texts... (num_proc=6):  77%|███████▋  | 1627000/2105244 [02:51<00:49, 9719.64 examples/s] Tokenizing texts... (num_proc=6):  77%|███████▋  | 1629000/2105244 [02:52<00:52, 9152.42 examples/s]Tokenizing texts... (num_proc=6):  77%|███████▋  | 1631000/2105244 [02:52<00:46, 10093.94 examples/s]Tokenizing texts... (num_proc=6):  78%|███████▊  | 1633000/2105244 [02:52<00:48, 9646.19 examples/s] Tokenizing texts... (num_proc=6):  78%|███████▊  | 1635000/2105244 [02:52<00:53, 8858.59 examples/s]Tokenizing texts... (num_proc=6):  78%|███████▊  | 1638000/2105244 [02:53<00:47, 9912.25 examples/s]Tokenizing texts... (num_proc=6):  78%|███████▊  | 1640000/2105244 [02:53<00:43, 10661.52 examples/s]Tokenizing texts... (num_proc=6):  78%|███████▊  | 1642000/2105244 [02:53<00:49, 9297.28 examples/s] Tokenizing texts... (num_proc=6):  78%|███████▊  | 1644000/2105244 [02:53<00:48, 9461.62 examples/s]Tokenizing texts... (num_proc=6):  78%|███████▊  | 1647000/2105244 [02:54<00:53, 8632.76 examples/s]Tokenizing texts... (num_proc=6):  78%|███████▊  | 1649000/2105244 [02:54<00:45, 10105.85 examples/s]Tokenizing texts... (num_proc=6):  78%|███████▊  | 1651000/2105244 [02:54<00:43, 10498.35 examples/s]Tokenizing texts... (num_proc=6):  79%|███████▊  | 1653000/2105244 [02:54<00:51, 8749.18 examples/s] Tokenizing texts... (num_proc=6):  79%|███████▊  | 1656000/2105244 [02:54<00:44, 10121.89 examples/s]Tokenizing texts... (num_proc=6):  79%|███████▉  | 1658000/2105244 [02:55<00:40, 11096.15 examples/s]Tokenizing texts... (num_proc=6):  79%|███████▉  | 1660000/2105244 [02:55<00:44, 10102.48 examples/s]Tokenizing texts... (num_proc=6):  79%|███████▉  | 1662000/2105244 [02:55<00:51, 8638.73 examples/s] Tokenizing texts... (num_proc=6):  79%|███████▉  | 1664000/2105244 [02:55<00:43, 10247.41 examples/s]Tokenizing texts... (num_proc=6):  79%|███████▉  | 1666000/2105244 [02:55<00:41, 10673.81 examples/s]Tokenizing texts... (num_proc=6):  79%|███████▉  | 1668000/2105244 [02:56<00:49, 8774.81 examples/s] Tokenizing texts... (num_proc=6):  79%|███████▉  | 1671000/2105244 [02:56<00:40, 10837.60 examples/s]Tokenizing texts... (num_proc=6):  79%|███████▉  | 1673000/2105244 [02:56<00:44, 9746.01 examples/s] Tokenizing texts... (num_proc=6):  80%|███████▉  | 1675000/2105244 [02:56<00:48, 8802.98 examples/s]Tokenizing texts... (num_proc=6):  80%|███████▉  | 1677000/2105244 [02:57<00:42, 10027.97 examples/s]Tokenizing texts... (num_proc=6):  80%|███████▉  | 1679000/2105244 [02:57<00:39, 10812.98 examples/s]Tokenizing texts... (num_proc=6):  80%|███████▉  | 1681000/2105244 [02:57<00:58, 7298.29 examples/s] Tokenizing texts... (num_proc=6):  80%|████████  | 1685000/2105244 [02:57<00:38, 10798.79 examples/s]Tokenizing texts... (num_proc=6):  80%|████████  | 1687000/2105244 [02:58<00:46, 9074.71 examples/s] Tokenizing texts... (num_proc=6):  80%|████████  | 1689000/2105244 [02:58<00:41, 9938.14 examples/s]Tokenizing texts... (num_proc=6):  80%|████████  | 1691000/2105244 [02:58<00:43, 9621.67 examples/s]Tokenizing texts... (num_proc=6):  80%|████████  | 1693000/2105244 [02:58<00:46, 8835.08 examples/s]Tokenizing texts... (num_proc=6):  81%|████████  | 1695000/2105244 [02:58<00:40, 10199.19 examples/s]Tokenizing texts... (num_proc=6):  81%|████████  | 1697000/2105244 [02:59<00:44, 9232.65 examples/s] Tokenizing texts... (num_proc=6):  81%|████████  | 1699000/2105244 [02:59<00:37, 10942.72 examples/s]Tokenizing texts... (num_proc=6):  81%|████████  | 1701000/2105244 [02:59<00:41, 9687.10 examples/s] Tokenizing texts... (num_proc=6):  81%|████████  | 1703000/2105244 [02:59<00:42, 9376.37 examples/s]Tokenizing texts... (num_proc=6):  81%|████████  | 1705000/2105244 [02:59<00:37, 10691.61 examples/s]Tokenizing texts... (num_proc=6):  81%|████████  | 1707000/2105244 [03:00<00:42, 9381.28 examples/s] Tokenizing texts... (num_proc=6):  81%|████████  | 1709000/2105244 [03:00<00:40, 9847.04 examples/s]Tokenizing texts... (num_proc=6):  81%|████████▏ | 1711000/2105244 [03:00<00:42, 9299.61 examples/s]Tokenizing texts... (num_proc=6):  81%|████████▏ | 1713000/2105244 [03:00<00:39, 10009.33 examples/s]Tokenizing texts... (num_proc=6):  81%|████████▏ | 1715000/2105244 [03:01<00:42, 9211.58 examples/s] Tokenizing texts... (num_proc=6):  82%|████████▏ | 1716000/2105244 [03:01<00:42, 9210.12 examples/s]Tokenizing texts... (num_proc=6):  82%|████████▏ | 1717000/2105244 [03:01<00:44, 8785.67 examples/s]Tokenizing texts... (num_proc=6):  82%|████████▏ | 1720000/2105244 [03:01<00:33, 11497.12 examples/s]Tokenizing texts... (num_proc=6):  82%|████████▏ | 1722000/2105244 [03:01<00:42, 8992.75 examples/s] Tokenizing texts... (num_proc=6):  82%|████████▏ | 1724000/2105244 [03:01<00:41, 9260.43 examples/s]Tokenizing texts... (num_proc=6):  82%|████████▏ | 1727000/2105244 [03:02<00:40, 9346.03 examples/s]Tokenizing texts... (num_proc=6):  82%|████████▏ | 1729000/2105244 [03:02<00:42, 8930.15 examples/s]Tokenizing texts... (num_proc=6):  82%|████████▏ | 1731000/2105244 [03:02<00:37, 9985.95 examples/s]Tokenizing texts... (num_proc=6):  82%|████████▏ | 1733000/2105244 [03:02<00:33, 11080.19 examples/s]Tokenizing texts... (num_proc=6):  82%|████████▏ | 1735000/2105244 [03:03<00:41, 8853.52 examples/s] Tokenizing texts... (num_proc=6):  83%|████████▎ | 1737000/2105244 [03:03<00:37, 9783.72 examples/s]Tokenizing texts... (num_proc=6):  83%|████████▎ | 1739000/2105244 [03:03<00:32, 11271.35 examples/s]Tokenizing texts... (num_proc=6):  83%|████████▎ | 1741000/2105244 [03:03<00:39, 9318.74 examples/s] Tokenizing texts... (num_proc=6):  83%|████████▎ | 1743000/2105244 [03:03<00:34, 10448.36 examples/s]Tokenizing texts... (num_proc=6):  83%|████████▎ | 1745000/2105244 [03:04<00:37, 9582.03 examples/s] Tokenizing texts... (num_proc=6):  83%|████████▎ | 1747000/2105244 [03:04<00:38, 9407.33 examples/s]Tokenizing texts... (num_proc=6):  83%|████████▎ | 1749000/2105244 [03:04<00:35, 10084.17 examples/s]Tokenizing texts... (num_proc=6):  83%|████████▎ | 1751000/2105244 [03:04<00:36, 9592.61 examples/s] Tokenizing texts... (num_proc=6):  83%|████████▎ | 1753000/2105244 [03:04<00:35, 9824.84 examples/s]Tokenizing texts... (num_proc=6):  83%|████████▎ | 1755000/2105244 [03:05<00:36, 9679.96 examples/s]Tokenizing texts... (num_proc=6):  84%|████████▎ | 1758000/2105244 [03:05<00:38, 9111.18 examples/s]Tokenizing texts... (num_proc=6):  84%|████████▎ | 1760000/2105244 [03:05<00:35, 9791.09 examples/s]Tokenizing texts... (num_proc=6):  84%|████████▎ | 1762000/2105244 [03:05<00:31, 10903.42 examples/s]Tokenizing texts... (num_proc=6):  84%|████████▍ | 1764000/2105244 [03:06<00:37, 9048.75 examples/s] Tokenizing texts... (num_proc=6):  84%|████████▍ | 1766000/2105244 [03:06<00:35, 9471.90 examples/s]Tokenizing texts... (num_proc=6):  84%|████████▍ | 1768000/2105244 [03:06<00:32, 10266.27 examples/s]Tokenizing texts... (num_proc=6):  84%|████████▍ | 1770000/2105244 [03:06<00:35, 9392.59 examples/s] Tokenizing texts... (num_proc=6):  84%|████████▍ | 1772000/2105244 [03:06<00:34, 9554.59 examples/s]Tokenizing texts... (num_proc=6):  84%|████████▍ | 1774000/2105244 [03:07<00:34, 9702.37 examples/s]Tokenizing texts... (num_proc=6):  84%|████████▍ | 1776000/2105244 [03:07<00:33, 9720.68 examples/s]Tokenizing texts... (num_proc=6):  84%|████████▍ | 1778000/2105244 [03:07<00:37, 8629.66 examples/s]Tokenizing texts... (num_proc=6):  85%|████████▍ | 1780000/2105244 [03:07<00:32, 9978.42 examples/s]Tokenizing texts... (num_proc=6):  85%|████████▍ | 1782000/2105244 [03:07<00:31, 10415.04 examples/s]Tokenizing texts... (num_proc=6):  85%|████████▍ | 1784000/2105244 [03:08<00:40, 7993.71 examples/s] Tokenizing texts... (num_proc=6):  85%|████████▍ | 1788000/2105244 [03:08<00:26, 11805.33 examples/s]Tokenizing texts... (num_proc=6):  85%|████████▌ | 1790000/2105244 [03:08<00:40, 7836.11 examples/s] Tokenizing texts... (num_proc=6):  85%|████████▌ | 1795000/2105244 [03:09<00:25, 12381.23 examples/s]Tokenizing texts... (num_proc=6):  85%|████████▌ | 1797000/2105244 [03:09<00:36, 8392.16 examples/s] Tokenizing texts... (num_proc=6):  86%|████████▌ | 1802000/2105244 [03:09<00:31, 9724.74 examples/s]Tokenizing texts... (num_proc=6):  86%|████████▌ | 1804000/2105244 [03:10<00:31, 9452.28 examples/s]Tokenizing texts... (num_proc=6):  86%|████████▌ | 1806000/2105244 [03:10<00:28, 10639.93 examples/s]Tokenizing texts... (num_proc=6):  86%|████████▌ | 1808000/2105244 [03:10<00:28, 10437.96 examples/s]Tokenizing texts... (num_proc=6):  86%|████████▌ | 1810000/2105244 [03:10<00:32, 9023.46 examples/s] Tokenizing texts... (num_proc=6):  86%|████████▌ | 1812000/2105244 [03:11<00:31, 9390.10 examples/s]Tokenizing texts... (num_proc=6):  86%|████████▌ | 1815000/2105244 [03:11<00:32, 8965.12 examples/s]Tokenizing texts... (num_proc=6):  86%|████████▋ | 1817000/2105244 [03:11<00:30, 9325.31 examples/s]Tokenizing texts... (num_proc=6):  86%|████████▋ | 1819000/2105244 [03:11<00:28, 10149.76 examples/s]Tokenizing texts... (num_proc=6):  86%|████████▋ | 1821000/2105244 [03:12<00:30, 9199.14 examples/s] Tokenizing texts... (num_proc=6):  87%|████████▋ | 1823000/2105244 [03:12<00:26, 10589.01 examples/s]Tokenizing texts... (num_proc=6):  87%|████████▋ | 1825000/2105244 [03:12<00:30, 9057.61 examples/s] Tokenizing texts... (num_proc=6):  87%|████████▋ | 1827000/2105244 [03:12<00:28, 9761.77 examples/s]Tokenizing texts... (num_proc=6):  87%|████████▋ | 1829000/2105244 [03:12<00:31, 8787.10 examples/s]Tokenizing texts... (num_proc=6):  87%|████████▋ | 1831000/2105244 [03:13<00:32, 8536.85 examples/s]Tokenizing texts... (num_proc=6):  87%|████████▋ | 1834000/2105244 [03:13<00:27, 9734.26 examples/s]Tokenizing texts... (num_proc=6):  87%|████████▋ | 1836000/2105244 [03:13<00:26, 10008.02 examples/s]Tokenizing texts... (num_proc=6):  87%|████████▋ | 1838000/2105244 [03:13<00:28, 9453.55 examples/s] Tokenizing texts... (num_proc=6):  87%|████████▋ | 1841000/2105244 [03:13<00:23, 11232.51 examples/s]Tokenizing texts... (num_proc=6):  88%|████████▊ | 1843000/2105244 [03:14<00:29, 8854.23 examples/s] Tokenizing texts... (num_proc=6):  88%|████████▊ | 1845000/2105244 [03:14<00:25, 10140.42 examples/s]Tokenizing texts... (num_proc=6):  88%|████████▊ | 1847000/2105244 [03:14<00:28, 9130.08 examples/s] Tokenizing texts... (num_proc=6):  88%|████████▊ | 1849000/2105244 [03:14<00:24, 10583.41 examples/s]Tokenizing texts... (num_proc=6):  88%|████████▊ | 1851000/2105244 [03:15<00:27, 9170.32 examples/s] Tokenizing texts... (num_proc=6):  88%|████████▊ | 1853000/2105244 [03:15<00:25, 9835.24 examples/s]Tokenizing texts... (num_proc=6):  88%|████████▊ | 1855000/2105244 [03:15<00:24, 10095.99 examples/s]Tokenizing texts... (num_proc=6):  88%|████████▊ | 1857000/2105244 [03:15<00:28, 8835.63 examples/s] Tokenizing texts... (num_proc=6):  88%|████████▊ | 1859000/2105244 [03:15<00:26, 9423.47 examples/s]Tokenizing texts... (num_proc=6):  88%|████████▊ | 1861000/2105244 [03:16<00:23, 10565.51 examples/s]Tokenizing texts... (num_proc=6):  88%|████████▊ | 1863000/2105244 [03:16<00:22, 10640.29 examples/s]Tokenizing texts... (num_proc=6):  89%|████████▊ | 1865000/2105244 [03:16<00:27, 8682.16 examples/s] Tokenizing texts... (num_proc=6):  89%|████████▊ | 1866000/2105244 [03:16<00:29, 8053.70 examples/s]Tokenizing texts... (num_proc=6):  89%|████████▉ | 1870000/2105244 [03:17<00:25, 9282.84 examples/s]Tokenizing texts... (num_proc=6):  89%|████████▉ | 1871000/2105244 [03:17<00:25, 9196.58 examples/s]Tokenizing texts... (num_proc=6):  89%|████████▉ | 1873000/2105244 [03:17<00:23, 9864.65 examples/s]Tokenizing texts... (num_proc=6):  89%|████████▉ | 1876000/2105244 [03:17<00:24, 9357.66 examples/s]Tokenizing texts... (num_proc=6):  89%|████████▉ | 1878000/2105244 [03:17<00:21, 10764.39 examples/s]Tokenizing texts... (num_proc=6):  89%|████████▉ | 1880000/2105244 [03:18<00:22, 10178.39 examples/s]Tokenizing texts... (num_proc=6):  89%|████████▉ | 1882000/2105244 [03:18<00:20, 11012.94 examples/s]Tokenizing texts... (num_proc=6):  89%|████████▉ | 1884000/2105244 [03:18<00:22, 9833.93 examples/s] Tokenizing texts... (num_proc=6):  90%|████████▉ | 1886000/2105244 [03:18<00:23, 9411.50 examples/s]Tokenizing texts... (num_proc=6):  90%|████████▉ | 1888000/2105244 [03:18<00:20, 10414.17 examples/s]Tokenizing texts... (num_proc=6):  90%|████████▉ | 1890000/2105244 [03:19<00:22, 9532.99 examples/s] Tokenizing texts... (num_proc=6):  90%|████████▉ | 1893000/2105244 [03:19<00:20, 10301.93 examples/s]Tokenizing texts... (num_proc=6):  90%|█████████ | 1895000/2105244 [03:19<00:23, 9086.50 examples/s] Tokenizing texts... (num_proc=6):  90%|█████████ | 1897000/2105244 [03:19<00:19, 10439.04 examples/s]Tokenizing texts... (num_proc=6):  90%|█████████ | 1898874/2105244 [03:20<00:23, 8930.15 examples/s] Tokenizing texts... (num_proc=6):  90%|█████████ | 1900874/2105244 [03:20<00:22, 9066.30 examples/s]Tokenizing texts... (num_proc=6):  90%|█████████ | 1903874/2105244 [03:20<00:17, 11549.50 examples/s]Tokenizing texts... (num_proc=6):  91%|█████████ | 1905874/2105244 [03:20<00:26, 7405.90 examples/s] Tokenizing texts... (num_proc=6):  91%|█████████ | 1908874/2105244 [03:21<00:20, 9417.49 examples/s]Tokenizing texts... (num_proc=6):  91%|█████████ | 1910874/2105244 [03:21<00:25, 7556.21 examples/s]Tokenizing texts... (num_proc=6):  91%|█████████ | 1912874/2105244 [03:21<00:22, 8377.30 examples/s]Tokenizing texts... (num_proc=6):  91%|█████████ | 1914874/2105244 [03:22<00:26, 7310.24 examples/s]Tokenizing texts... (num_proc=6):  91%|█████████ | 1916874/2105244 [03:22<00:23, 7953.91 examples/s]Tokenizing texts... (num_proc=6):  91%|█████████ | 1917874/2105244 [03:22<00:23, 7854.14 examples/s]Tokenizing texts... (num_proc=6):  91%|█████████ | 1919874/2105244 [03:22<00:24, 7452.16 examples/s]Tokenizing texts... (num_proc=6):  91%|█████████▏| 1921874/2105244 [03:22<00:22, 8002.50 examples/s]Tokenizing texts... (num_proc=6):  91%|█████████▏| 1922874/2105244 [03:23<00:24, 7387.65 examples/s]Tokenizing texts... (num_proc=6):  91%|█████████▏| 1924874/2105244 [03:23<00:22, 8147.10 examples/s]Tokenizing texts... (num_proc=6):  92%|█████████▏| 1926874/2105244 [03:23<00:22, 7955.72 examples/s]Tokenizing texts... (num_proc=6):  92%|█████████▏| 1927874/2105244 [03:23<00:25, 6884.80 examples/s]Tokenizing texts... (num_proc=6):  92%|█████████▏| 1930874/2105244 [03:23<00:18, 9258.89 examples/s]Tokenizing texts... (num_proc=6):  92%|█████████▏| 1931874/2105244 [03:24<00:21, 7880.50 examples/s]Tokenizing texts... (num_proc=6):  92%|█████████▏| 1932874/2105244 [03:24<00:27, 6343.36 examples/s]Tokenizing texts... (num_proc=6):  92%|█████████▏| 1935874/2105244 [03:24<00:17, 9511.13 examples/s]Tokenizing texts... (num_proc=6):  92%|█████████▏| 1937874/2105244 [03:25<00:23, 7049.77 examples/s]Tokenizing texts... (num_proc=6):  92%|█████████▏| 1939874/2105244 [03:25<00:19, 8478.07 examples/s]Tokenizing texts... (num_proc=6):  92%|█████████▏| 1941874/2105244 [03:25<00:19, 8451.14 examples/s]Tokenizing texts... (num_proc=6):  92%|█████████▏| 1943748/2105244 [03:25<00:23, 6838.82 examples/s]Tokenizing texts... (num_proc=6):  92%|█████████▏| 1946748/2105244 [03:26<00:18, 8631.87 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 1948748/2105244 [03:26<00:23, 6525.83 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 1950748/2105244 [03:26<00:19, 7998.85 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 1952748/2105244 [03:27<00:25, 6039.75 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 1954748/2105244 [03:27<00:20, 7514.89 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 1956748/2105244 [03:27<00:25, 5745.43 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 1958748/2105244 [03:28<00:21, 6748.52 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 1960748/2105244 [03:28<00:25, 5618.43 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 1961748/2105244 [03:28<00:24, 5867.69 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 1963748/2105244 [03:29<00:25, 5513.12 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 1964748/2105244 [03:29<00:23, 6013.34 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 1965748/2105244 [03:29<00:22, 6093.31 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 1967748/2105244 [03:29<00:23, 5823.46 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▎| 1968748/2105244 [03:29<00:21, 6256.11 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▎| 1969748/2105244 [03:29<00:22, 5913.76 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▎| 1971748/2105244 [03:30<00:22, 6007.05 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▎| 1972748/2105244 [03:30<00:20, 6585.13 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1973748/2105244 [03:30<00:22, 5762.13 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1974748/2105244 [03:30<00:20, 6381.09 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1975748/2105244 [03:30<00:21, 6102.12 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1976748/2105244 [03:31<00:19, 6745.31 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1977748/2105244 [03:31<00:23, 5535.11 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1978748/2105244 [03:31<00:22, 5746.61 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1979748/2105244 [03:31<00:19, 6456.92 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1980748/2105244 [03:31<00:21, 5880.44 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1981748/2105244 [03:32<00:22, 5497.39 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1982748/2105244 [03:32<00:21, 5733.34 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1984748/2105244 [03:32<00:18, 6374.06 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1985748/2105244 [03:32<00:21, 5638.36 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1986748/2105244 [03:32<00:20, 5799.38 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 1988748/2105244 [03:33<00:16, 6973.21 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▍| 1989748/2105244 [03:33<00:20, 5565.92 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▍| 1990748/2105244 [03:33<00:18, 6131.41 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▍| 1992748/2105244 [03:33<00:15, 7149.29 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▍| 1993748/2105244 [03:34<00:20, 5370.85 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▍| 1995748/2105244 [03:34<00:16, 6676.53 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▍| 1997748/2105244 [03:34<00:19, 5485.20 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▍| 1999748/2105244 [03:34<00:16, 6306.54 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▌| 2001748/2105244 [03:35<00:18, 5653.21 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▌| 2003748/2105244 [03:35<00:15, 6455.37 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▌| 2004748/2105244 [03:35<00:16, 6280.19 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▌| 2005748/2105244 [03:35<00:17, 5631.29 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▌| 2007748/2105244 [03:36<00:14, 6799.67 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▌| 2008748/2105244 [03:36<00:16, 6014.75 examples/s]Tokenizing texts... (num_proc=6):  95%|█████████▌| 2009748/2105244 [03:36<00:16, 5663.01 examples/s]Tokenizing texts... (num_proc=6):  96%|█████████▌| 2011748/2105244 [03:36<00:13, 7026.66 examples/s]Tokenizing texts... (num_proc=6):  96%|█████████▌| 2012748/2105244 [03:37<00:15, 5813.62 examples/s]Tokenizing texts... (num_proc=6):  96%|█████████▌| 2013748/2105244 [03:37<00:18, 5073.97 examples/s]Tokenizing texts... (num_proc=6):  96%|█████████▌| 2016748/2105244 [03:37<00:14, 6017.40 examples/s]Tokenizing texts... (num_proc=6):  96%|█████████▌| 2017748/2105244 [03:38<00:16, 5451.03 examples/s]Tokenizing texts... (num_proc=6):  96%|█████████▌| 2020748/2105244 [03:38<00:13, 6083.09 examples/s]Tokenizing texts... (num_proc=6):  96%|█████████▌| 2021748/2105244 [03:38<00:14, 5721.98 examples/s]Tokenizing texts... (num_proc=6):  96%|█████████▌| 2024748/2105244 [03:39<00:13, 6022.89 examples/s]Tokenizing texts... (num_proc=6):  96%|█████████▌| 2025748/2105244 [03:39<00:13, 6069.60 examples/s]Tokenizing texts... (num_proc=6):  96%|█████████▋| 2028748/2105244 [03:39<00:13, 5860.65 examples/s]Tokenizing texts... (num_proc=6):  96%|█████████▋| 2030748/2105244 [03:39<00:10, 7220.07 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2032748/2105244 [03:40<00:13, 5524.44 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2035748/2105244 [03:40<00:09, 7374.19 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2037622/2105244 [03:41<00:11, 5923.19 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2039622/2105244 [03:41<00:09, 6952.80 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2040622/2105244 [03:41<00:13, 4897.99 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2042622/2105244 [03:42<00:10, 6168.02 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2043622/2105244 [03:42<00:13, 4568.30 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2045622/2105244 [03:42<00:10, 5631.99 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2046622/2105244 [03:43<00:13, 4423.24 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2047622/2105244 [03:43<00:12, 4797.22 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2048622/2105244 [03:43<00:10, 5477.92 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2049622/2105244 [03:43<00:12, 4339.98 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2050622/2105244 [03:43<00:12, 4482.90 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 2051622/2105244 [03:44<00:10, 5280.87 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2052622/2105244 [03:44<00:11, 4584.81 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2053622/2105244 [03:44<00:12, 4155.51 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2055622/2105244 [03:44<00:10, 4824.45 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2056622/2105244 [03:45<00:11, 4229.90 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2058622/2105244 [03:45<00:09, 4984.31 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2059622/2105244 [03:45<00:11, 4121.65 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2061622/2105244 [03:46<00:08, 5062.18 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2062622/2105244 [03:46<00:10, 3993.25 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2063496/2105244 [03:46<00:09, 4424.05 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2065496/2105244 [03:47<00:09, 3996.45 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2067496/2105244 [03:48<00:10, 3534.08 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2069496/2105244 [03:48<00:10, 3297.90 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2071496/2105244 [03:49<00:10, 3175.02 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 2073496/2105244 [03:50<00:10, 3080.32 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▊| 2075496/2105244 [03:50<00:09, 3050.76 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▊| 2077496/2105244 [03:51<00:09, 3004.84 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 2079496/2105244 [03:52<00:08, 3006.30 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 2081496/2105244 [03:52<00:07, 3011.05 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 2083496/2105244 [03:53<00:07, 3014.62 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 2085496/2105244 [03:54<00:06, 3036.43 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 2086496/2105244 [03:54<00:05, 3299.22 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 2087496/2105244 [03:54<00:06, 2943.82 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 2088496/2105244 [03:54<00:05, 3271.68 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 2089496/2105244 [03:55<00:05, 2927.30 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 2090496/2105244 [03:55<00:04, 3201.86 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 2091496/2105244 [03:56<00:04, 2923.44 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 2092496/2105244 [03:56<00:04, 3154.64 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 2093370/2105244 [03:56<00:03, 2988.41 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 2094370/2105244 [03:56<00:03, 3051.12 examples/s]Tokenizing texts... (num_proc=6): 100%|█████████▉| 2095370/2105244 [03:57<00:04, 2312.28 examples/s]Tokenizing texts... (num_proc=6): 100%|█████████▉| 2096370/2105244 [03:58<00:04, 2021.69 examples/s]Tokenizing texts... (num_proc=6): 100%|█████████▉| 2097370/2105244 [03:58<00:04, 1828.91 examples/s]Tokenizing texts... (num_proc=6): 100%|█████████▉| 2098370/2105244 [03:59<00:03, 1731.75 examples/s]Tokenizing texts... (num_proc=6): 100%|█████████▉| 2099370/2105244 [04:00<00:03, 1670.78 examples/s]Tokenizing texts... (num_proc=6): 100%|█████████▉| 2100370/2105244 [04:00<00:03, 1616.89 examples/s]Tokenizing texts... (num_proc=6): 100%|█████████▉| 2101370/2105244 [04:01<00:02, 1586.01 examples/s]Tokenizing texts... (num_proc=6): 100%|█████████▉| 2102370/2105244 [04:02<00:01, 1561.85 examples/s]Tokenizing texts... (num_proc=6): 100%|█████████▉| 2103370/2105244 [04:02<00:01, 1541.77 examples/s]Tokenizing texts... (num_proc=6): 100%|█████████▉| 2104370/2105244 [04:03<00:00, 1522.52 examples/s]Tokenizing texts... (num_proc=6): 100%|██████████| 2105244/2105244 [04:04<00:00, 1516.20 examples/s]Tokenizing texts... (num_proc=6): 100%|██████████| 2105244/2105244 [04:04<00:00, 8605.05 examples/s]
Concatenating 6 shards
01/05/2026 14:35:28 - INFO - datasets.arrow_dataset - Concatenating 6 shards
Process #0 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00000_of_00006.arrow
01/05/2026 14:35:28 - INFO - datasets.arrow_dataset - Process #0 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00000_of_00006.arrow
Process #1 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00001_of_00006.arrow
01/05/2026 14:35:28 - INFO - datasets.arrow_dataset - Process #1 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00001_of_00006.arrow
Process #2 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00002_of_00006.arrow
01/05/2026 14:35:28 - INFO - datasets.arrow_dataset - Process #2 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00002_of_00006.arrow
Process #3 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00003_of_00006.arrow
01/05/2026 14:35:28 - INFO - datasets.arrow_dataset - Process #3 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00003_of_00006.arrow
Process #4 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00004_of_00006.arrow
01/05/2026 14:35:28 - INFO - datasets.arrow_dataset - Process #4 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00004_of_00006.arrow
Process #5 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00005_of_00006.arrow
01/05/2026 14:35:28 - INFO - datasets.arrow_dataset - Process #5 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00005_of_00006.arrow
Spawning 6 processes
01/05/2026 14:35:28 - INFO - datasets.arrow_dataset - Spawning 6 processes
Tokenizing texts... (num_proc=6):   0%|          | 0/3000 [00:00<?, ? examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00000_of_00006.arrow
01/05/2026 14:35:29 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00000_of_00006.arrow
Tokenizing texts... (num_proc=6):  17%|█▋        | 500/3000 [00:01<00:06, 375.51 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00001_of_00006.arrow
01/05/2026 14:35:29 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00001_of_00006.arrow
Tokenizing texts... (num_proc=6):  33%|███▎      | 1000/3000 [00:01<00:02, 754.65 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00002_of_00006.arrow
01/05/2026 14:35:30 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00002_of_00006.arrow
Tokenizing texts... (num_proc=6):  50%|█████     | 1500/3000 [00:01<00:01, 1131.35 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00003_of_00006.arrow
01/05/2026 14:35:30 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00003_of_00006.arrow
Tokenizing texts... (num_proc=6):  67%|██████▋   | 2000/3000 [00:01<00:00, 1480.38 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00004_of_00006.arrow
01/05/2026 14:35:30 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00004_of_00006.arrow
Tokenizing texts... (num_proc=6):  83%|████████▎ | 2500/3000 [00:02<00:00, 1779.29 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00005_of_00006.arrow
01/05/2026 14:35:30 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-e208a8b984b7130c_00005_of_00006.arrow
Tokenizing texts... (num_proc=6): 100%|██████████| 3000/3000 [00:02<00:00, 1981.30 examples/s]Tokenizing texts... (num_proc=6): 100%|██████████| 3000/3000 [00:02<00:00, 1266.55 examples/s]
Concatenating 6 shards
01/05/2026 14:35:30 - INFO - datasets.arrow_dataset - Concatenating 6 shards
Process #0 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00000_of_00006.arrow
01/05/2026 14:35:31 - INFO - datasets.arrow_dataset - Process #0 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00000_of_00006.arrow
Process #1 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00001_of_00006.arrow
01/05/2026 14:35:31 - INFO - datasets.arrow_dataset - Process #1 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00001_of_00006.arrow
Process #2 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00002_of_00006.arrow
01/05/2026 14:35:31 - INFO - datasets.arrow_dataset - Process #2 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00002_of_00006.arrow
Process #3 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00003_of_00006.arrow
01/05/2026 14:35:31 - INFO - datasets.arrow_dataset - Process #3 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00003_of_00006.arrow
Process #4 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00004_of_00006.arrow
01/05/2026 14:35:31 - INFO - datasets.arrow_dataset - Process #4 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00004_of_00006.arrow
Process #5 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00005_of_00006.arrow
01/05/2026 14:35:31 - INFO - datasets.arrow_dataset - Process #5 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00005_of_00006.arrow
Spawning 6 processes
01/05/2026 14:35:31 - INFO - datasets.arrow_dataset - Spawning 6 processes
Tokenizing texts... (num_proc=6):   0%|          | 0/282635 [00:00<?, ? examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00000_of_00006.arrow
01/05/2026 14:35:32 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00000_of_00006.arrow
Tokenizing texts... (num_proc=6):   0%|          | 1000/282635 [00:01<07:43, 607.82 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00001_of_00006.arrow
01/05/2026 14:35:32 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00001_of_00006.arrow
Tokenizing texts... (num_proc=6):   1%|          | 2000/282635 [00:01<03:41, 1268.83 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00002_of_00006.arrow
01/05/2026 14:35:33 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00002_of_00006.arrow
Tokenizing texts... (num_proc=6):   1%|          | 3000/282635 [00:02<02:24, 1935.32 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00003_of_00006.arrow
01/05/2026 14:35:33 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00003_of_00006.arrow
Tokenizing texts... (num_proc=6):   1%|▏         | 4000/282635 [00:02<01:46, 2615.75 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00004_of_00006.arrow
01/05/2026 14:35:33 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00004_of_00006.arrow
Tokenizing texts... (num_proc=6):   2%|▏         | 5000/282635 [00:02<01:23, 3323.15 examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00005_of_00006.arrow
01/05/2026 14:35:33 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-f0f5c4b75fd665e2_00005_of_00006.arrow
Tokenizing texts... (num_proc=6):   2%|▏         | 7000/282635 [00:02<00:52, 5216.43 examples/s]Tokenizing texts... (num_proc=6):   3%|▎         | 9000/282635 [00:02<00:41, 6585.22 examples/s]Tokenizing texts... (num_proc=6):   4%|▎         | 10000/282635 [00:02<00:41, 6604.39 examples/s]Tokenizing texts... (num_proc=6):   4%|▍         | 11000/282635 [00:03<00:43, 6257.15 examples/s]Tokenizing texts... (num_proc=6):   5%|▍         | 13000/282635 [00:03<00:35, 7560.99 examples/s]Tokenizing texts... (num_proc=6):   5%|▌         | 15000/282635 [00:03<00:30, 8731.51 examples/s]Tokenizing texts... (num_proc=6):   6%|▌         | 16000/282635 [00:03<00:32, 8098.73 examples/s]Tokenizing texts... (num_proc=6):   6%|▌         | 17000/282635 [00:03<00:37, 7092.97 examples/s]Tokenizing texts... (num_proc=6):   7%|▋         | 19000/282635 [00:03<00:31, 8361.22 examples/s]Tokenizing texts... (num_proc=6):   7%|▋         | 21000/282635 [00:04<00:27, 9355.55 examples/s]Tokenizing texts... (num_proc=6):   8%|▊         | 22000/282635 [00:04<00:30, 8661.78 examples/s]Tokenizing texts... (num_proc=6):   8%|▊         | 23000/282635 [00:04<00:36, 7209.96 examples/s]Tokenizing texts... (num_proc=6):   9%|▉         | 25000/282635 [00:04<00:31, 8288.65 examples/s]Tokenizing texts... (num_proc=6):  10%|▉         | 27000/282635 [00:04<00:26, 9740.26 examples/s]Tokenizing texts... (num_proc=6):  10%|█         | 29000/282635 [00:05<00:33, 7520.11 examples/s]Tokenizing texts... (num_proc=6):  11%|█         | 31000/282635 [00:05<00:30, 8328.66 examples/s]Tokenizing texts... (num_proc=6):  12%|█▏        | 33000/282635 [00:05<00:25, 9725.03 examples/s]Tokenizing texts... (num_proc=6):  12%|█▏        | 35000/282635 [00:05<00:32, 7580.81 examples/s]Tokenizing texts... (num_proc=6):  13%|█▎        | 37000/282635 [00:06<00:29, 8233.37 examples/s]Tokenizing texts... (num_proc=6):  14%|█▍        | 39000/282635 [00:06<00:25, 9740.02 examples/s]Tokenizing texts... (num_proc=6):  15%|█▍        | 41000/282635 [00:06<00:31, 7592.45 examples/s]Tokenizing texts... (num_proc=6):  15%|█▌        | 43000/282635 [00:06<00:28, 8270.59 examples/s]Tokenizing texts... (num_proc=6):  16%|█▌        | 45000/282635 [00:06<00:24, 9745.31 examples/s]Tokenizing texts... (num_proc=6):  17%|█▋        | 47000/282635 [00:07<00:30, 7618.32 examples/s]Tokenizing texts... (num_proc=6):  17%|█▋        | 49000/282635 [00:07<00:27, 8396.85 examples/s]Tokenizing texts... (num_proc=6):  18%|█▊        | 51000/282635 [00:07<00:23, 9696.09 examples/s]Tokenizing texts... (num_proc=6):  19%|█▉        | 53000/282635 [00:08<00:30, 7542.09 examples/s]Tokenizing texts... (num_proc=6):  19%|█▉        | 55000/282635 [00:08<00:27, 8419.81 examples/s]Tokenizing texts... (num_proc=6):  20%|██        | 57000/282635 [00:08<00:22, 10049.08 examples/s]Tokenizing texts... (num_proc=6):  21%|██        | 59000/282635 [00:08<00:29, 7459.38 examples/s] Tokenizing texts... (num_proc=6):  22%|██▏       | 61000/282635 [00:08<00:26, 8215.61 examples/s]Tokenizing texts... (num_proc=6):  23%|██▎       | 65000/282635 [00:09<00:27, 8012.10 examples/s]Tokenizing texts... (num_proc=6):  24%|██▎       | 67000/282635 [00:09<00:25, 8515.65 examples/s]Tokenizing texts... (num_proc=6):  25%|██▍       | 70000/282635 [00:09<00:18, 11281.73 examples/s]Tokenizing texts... (num_proc=6):  25%|██▌       | 72000/282635 [00:10<00:26, 8059.78 examples/s] Tokenizing texts... (num_proc=6):  26%|██▌       | 74000/282635 [00:10<00:23, 8997.01 examples/s]Tokenizing texts... (num_proc=6):  27%|██▋       | 77000/282635 [00:10<00:27, 7508.39 examples/s]Tokenizing texts... (num_proc=6):  28%|██▊       | 79000/282635 [00:11<00:24, 8404.19 examples/s]Tokenizing texts... (num_proc=6):  29%|██▉       | 82000/282635 [00:11<00:17, 11162.53 examples/s]Tokenizing texts... (num_proc=6):  30%|██▉       | 84000/282635 [00:11<00:26, 7634.12 examples/s] Tokenizing texts... (num_proc=6):  30%|███       | 86000/282635 [00:11<00:21, 8971.35 examples/s]Tokenizing texts... (num_proc=6):  31%|███▏      | 89000/282635 [00:12<00:27, 6936.27 examples/s]Tokenizing texts... (num_proc=6):  32%|███▏      | 91000/282635 [00:12<00:24, 7805.32 examples/s]Tokenizing texts... (num_proc=6):  33%|███▎      | 93000/282635 [00:12<00:22, 8285.61 examples/s]Tokenizing texts... (num_proc=6):  34%|███▎      | 95000/282635 [00:13<00:29, 6327.80 examples/s]Tokenizing texts... (num_proc=6):  35%|███▍      | 98000/282635 [00:13<00:21, 8517.45 examples/s]Tokenizing texts... (num_proc=6):  35%|███▌      | 100000/282635 [00:13<00:18, 9955.23 examples/s]Tokenizing texts... (num_proc=6):  36%|███▌      | 102000/282635 [00:13<00:24, 7335.22 examples/s]Tokenizing texts... (num_proc=6):  37%|███▋      | 104000/282635 [00:14<00:21, 8477.76 examples/s]Tokenizing texts... (num_proc=6):  38%|███▊      | 106000/282635 [00:14<00:17, 10100.63 examples/s]Tokenizing texts... (num_proc=6):  38%|███▊      | 108000/282635 [00:14<00:24, 7226.59 examples/s] Tokenizing texts... (num_proc=6):  39%|███▉      | 110000/282635 [00:14<00:20, 8558.90 examples/s]Tokenizing texts... (num_proc=6):  40%|███▉      | 112000/282635 [00:14<00:16, 10117.83 examples/s]Tokenizing texts... (num_proc=6):  40%|████      | 114000/282635 [00:15<00:23, 7145.99 examples/s] Tokenizing texts... (num_proc=6):  41%|████      | 116000/282635 [00:15<00:19, 8495.84 examples/s]Tokenizing texts... (num_proc=6):  42%|████▏     | 118000/282635 [00:15<00:16, 9972.73 examples/s]Tokenizing texts... (num_proc=6):  42%|████▏     | 120000/282635 [00:16<00:22, 7160.51 examples/s]Tokenizing texts... (num_proc=6):  43%|████▎     | 122000/282635 [00:16<00:18, 8718.55 examples/s]Tokenizing texts... (num_proc=6):  44%|████▍     | 124000/282635 [00:16<00:15, 9991.08 examples/s]Tokenizing texts... (num_proc=6):  45%|████▍     | 126000/282635 [00:16<00:22, 7087.83 examples/s]Tokenizing texts... (num_proc=6):  45%|████▌     | 128000/282635 [00:16<00:17, 8606.54 examples/s]Tokenizing texts... (num_proc=6):  46%|████▋     | 131000/282635 [00:17<00:17, 8539.80 examples/s]Tokenizing texts... (num_proc=6):  47%|████▋     | 133000/282635 [00:17<00:19, 7738.22 examples/s]Tokenizing texts... (num_proc=6):  48%|████▊     | 135000/282635 [00:17<00:16, 9108.49 examples/s]Tokenizing texts... (num_proc=6):  48%|████▊     | 137000/282635 [00:17<00:16, 8914.13 examples/s]Tokenizing texts... (num_proc=6):  49%|████▉     | 139000/282635 [00:18<00:18, 7644.53 examples/s]Tokenizing texts... (num_proc=6):  50%|████▉     | 141000/282635 [00:18<00:15, 9088.16 examples/s]Tokenizing texts... (num_proc=6):  51%|█████     | 143000/282635 [00:18<00:15, 9038.71 examples/s]Tokenizing texts... (num_proc=6):  51%|█████▏    | 145000/282635 [00:19<00:18, 7457.61 examples/s]Tokenizing texts... (num_proc=6):  52%|█████▏    | 147000/282635 [00:19<00:14, 9055.10 examples/s]Tokenizing texts... (num_proc=6):  53%|█████▎    | 149000/282635 [00:19<00:14, 9250.58 examples/s]Tokenizing texts... (num_proc=6):  53%|█████▎    | 151000/282635 [00:19<00:17, 7313.25 examples/s]Tokenizing texts... (num_proc=6):  55%|█████▍    | 155000/282635 [00:20<00:12, 9903.80 examples/s]Tokenizing texts... (num_proc=6):  56%|█████▌    | 157000/282635 [00:20<00:16, 7467.55 examples/s]Tokenizing texts... (num_proc=6):  57%|█████▋    | 160000/282635 [00:20<00:12, 10041.38 examples/s]Tokenizing texts... (num_proc=6):  57%|█████▋    | 162000/282635 [00:21<00:17, 7031.39 examples/s] Tokenizing texts... (num_proc=6):  58%|█████▊    | 165000/282635 [00:21<00:12, 9049.83 examples/s]Tokenizing texts... (num_proc=6):  59%|█████▉    | 168000/282635 [00:21<00:15, 7414.21 examples/s]Tokenizing texts... (num_proc=6):  61%|██████    | 171000/282635 [00:21<00:12, 9150.79 examples/s]Tokenizing texts... (num_proc=6):  62%|██████▏   | 174000/282635 [00:22<00:14, 7543.13 examples/s]Tokenizing texts... (num_proc=6):  63%|██████▎   | 177000/282635 [00:22<00:11, 9490.77 examples/s]Tokenizing texts... (num_proc=6):  64%|██████▎   | 180000/282635 [00:23<00:13, 7572.84 examples/s]Tokenizing texts... (num_proc=6):  65%|██████▍   | 183000/282635 [00:23<00:10, 9790.18 examples/s]Tokenizing texts... (num_proc=6):  66%|██████▌   | 186000/282635 [00:23<00:12, 7550.59 examples/s]Tokenizing texts... (num_proc=6):  67%|██████▋   | 190000/282635 [00:24<00:09, 10221.23 examples/s]Tokenizing texts... (num_proc=6):  68%|██████▊   | 192000/282635 [00:24<00:12, 7360.41 examples/s] Tokenizing texts... (num_proc=6):  69%|██████▉   | 196000/282635 [00:24<00:08, 10058.57 examples/s]Tokenizing texts... (num_proc=6):  70%|███████   | 198000/282635 [00:25<00:11, 7386.19 examples/s] Tokenizing texts... (num_proc=6):  71%|███████   | 201000/282635 [00:25<00:08, 9505.32 examples/s]Tokenizing texts... (num_proc=6):  72%|███████▏  | 204000/282635 [00:26<00:10, 7665.19 examples/s]Tokenizing texts... (num_proc=6):  73%|███████▎  | 207000/282635 [00:26<00:08, 9357.16 examples/s]Tokenizing texts... (num_proc=6):  74%|███████▍  | 210000/282635 [00:26<00:09, 8004.02 examples/s]Tokenizing texts... (num_proc=6):  75%|███████▌  | 212000/282635 [00:26<00:08, 8821.77 examples/s]Tokenizing texts... (num_proc=6):  76%|███████▌  | 214000/282635 [00:26<00:06, 10140.71 examples/s]Tokenizing texts... (num_proc=6):  76%|███████▋  | 216000/282635 [00:27<00:08, 7921.39 examples/s] Tokenizing texts... (num_proc=6):  77%|███████▋  | 218000/282635 [00:27<00:07, 8471.00 examples/s]Tokenizing texts... (num_proc=6):  78%|███████▊  | 221000/282635 [00:27<00:05, 10968.19 examples/s]Tokenizing texts... (num_proc=6):  79%|███████▉  | 223000/282635 [00:28<00:08, 7354.67 examples/s] Tokenizing texts... (num_proc=6):  80%|███████▉  | 225000/282635 [00:28<00:06, 8535.54 examples/s]Tokenizing texts... (num_proc=6):  81%|████████  | 228000/282635 [00:28<00:06, 8080.47 examples/s]Tokenizing texts... (num_proc=6):  81%|████████▏ | 230000/282635 [00:28<00:06, 8301.30 examples/s]Tokenizing texts... (num_proc=6):  82%|████████▏ | 233000/282635 [00:29<00:04, 10946.74 examples/s]Tokenizing texts... (num_proc=6):  83%|████████▎ | 235000/282635 [00:29<00:06, 7128.13 examples/s] Tokenizing texts... (num_proc=6):  84%|████████▍ | 237000/282635 [00:29<00:05, 8563.73 examples/s]Tokenizing texts... (num_proc=6):  85%|████████▍ | 240000/282635 [00:30<00:04, 8662.62 examples/s]Tokenizing texts... (num_proc=6):  86%|████████▌ | 242000/282635 [00:30<00:05, 8107.70 examples/s]Tokenizing texts... (num_proc=6):  87%|████████▋ | 245000/282635 [00:30<00:03, 10874.27 examples/s]Tokenizing texts... (num_proc=6):  87%|████████▋ | 247000/282635 [00:31<00:05, 7111.66 examples/s] Tokenizing texts... (num_proc=6):  88%|████████▊ | 249000/282635 [00:31<00:03, 8438.02 examples/s]Tokenizing texts... (num_proc=6):  89%|████████▉ | 252000/282635 [00:31<00:03, 9266.64 examples/s]Tokenizing texts... (num_proc=6):  90%|████████▉ | 254000/282635 [00:31<00:03, 7947.50 examples/s]Tokenizing texts... (num_proc=6):  91%|█████████ | 256000/282635 [00:31<00:02, 9468.48 examples/s]Tokenizing texts... (num_proc=6):  91%|█████████▏| 258000/282635 [00:32<00:02, 9697.65 examples/s]Tokenizing texts... (num_proc=6):  92%|█████████▏| 260000/282635 [00:32<00:03, 7509.11 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 262000/282635 [00:32<00:02, 9140.82 examples/s]Tokenizing texts... (num_proc=6):  93%|█████████▎| 264000/282635 [00:32<00:01, 10049.35 examples/s]Tokenizing texts... (num_proc=6):  94%|█████████▍| 266000/282635 [00:33<00:02, 7208.08 examples/s] Tokenizing texts... (num_proc=6):  95%|█████████▌| 269000/282635 [00:33<00:01, 9953.22 examples/s]Tokenizing texts... (num_proc=6):  96%|█████████▌| 271106/282635 [00:33<00:01, 6644.93 examples/s]Tokenizing texts... (num_proc=6):  97%|█████████▋| 274106/282635 [00:34<00:00, 9226.88 examples/s]Tokenizing texts... (num_proc=6):  98%|█████████▊| 276106/282635 [00:34<00:01, 6288.56 examples/s]Tokenizing texts... (num_proc=6):  99%|█████████▉| 280106/282635 [00:34<00:00, 9472.35 examples/s]Tokenizing texts... (num_proc=6): 100%|█████████▉| 282424/282635 [00:35<00:00, 6558.92 examples/s]Tokenizing texts... (num_proc=6): 100%|██████████| 282635/282635 [00:35<00:00, 7913.05 examples/s]
Concatenating 6 shards
01/05/2026 14:36:06 - INFO - datasets.arrow_dataset - Concatenating 6 shards
Process #0 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00000_of_00006.arrow
01/05/2026 14:36:07 - INFO - datasets.arrow_dataset - Process #0 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00000_of_00006.arrow
Process #1 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00001_of_00006.arrow
01/05/2026 14:36:07 - INFO - datasets.arrow_dataset - Process #1 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00001_of_00006.arrow
Process #2 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00002_of_00006.arrow
01/05/2026 14:36:07 - INFO - datasets.arrow_dataset - Process #2 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00002_of_00006.arrow
Process #3 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00003_of_00006.arrow
01/05/2026 14:36:07 - INFO - datasets.arrow_dataset - Process #3 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00003_of_00006.arrow
Process #4 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00004_of_00006.arrow
01/05/2026 14:36:07 - INFO - datasets.arrow_dataset - Process #4 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00004_of_00006.arrow
Process #5 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00005_of_00006.arrow
01/05/2026 14:36:07 - INFO - datasets.arrow_dataset - Process #5 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00005_of_00006.arrow
Spawning 6 processes
01/05/2026 14:36:07 - INFO - datasets.arrow_dataset - Spawning 6 processes
Grouping texts in chunks of 512 (num_proc=6):   0%|          | 0/2105244 [00:00<?, ? examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00001_of_00006.arrow
01/05/2026 14:36:07 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00001_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00000_of_00006.arrow
01/05/2026 14:36:07 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00000_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00002_of_00006.arrow
01/05/2026 14:36:07 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00002_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00005_of_00006.arrow
01/05/2026 14:36:07 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00005_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00003_of_00006.arrow
01/05/2026 14:36:07 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00003_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00004_of_00006.arrow
01/05/2026 14:36:07 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/train/cache-24939b82b4fbb1a1_00004_of_00006.arrow
Grouping texts in chunks of 512 (num_proc=6):   0%|          | 1000/2105244 [00:00<13:32, 2591.37 examples/s]Grouping texts in chunks of 512 (num_proc=6):   0%|          | 7000/2105244 [00:00<02:53, 12076.18 examples/s]Grouping texts in chunks of 512 (num_proc=6):   1%|          | 13000/2105244 [00:00<02:12, 15793.56 examples/s]Grouping texts in chunks of 512 (num_proc=6):   1%|          | 17000/2105244 [00:01<01:49, 19002.90 examples/s]Grouping texts in chunks of 512 (num_proc=6):   1%|          | 20000/2105244 [00:01<02:00, 17323.94 examples/s]Grouping texts in chunks of 512 (num_proc=6):   1%|          | 23000/2105244 [00:01<01:50, 18841.00 examples/s]Grouping texts in chunks of 512 (num_proc=6):   1%|          | 26000/2105244 [00:01<01:52, 18504.18 examples/s]Grouping texts in chunks of 512 (num_proc=6):   1%|▏         | 28000/2105244 [00:01<01:53, 18236.43 examples/s]Grouping texts in chunks of 512 (num_proc=6):   2%|▏         | 32000/2105244 [00:01<01:49, 18904.08 examples/s]Grouping texts in chunks of 512 (num_proc=6):   2%|▏         | 34000/2105244 [00:02<01:55, 17970.01 examples/s]Grouping texts in chunks of 512 (num_proc=6):   2%|▏         | 38000/2105244 [00:02<01:45, 19586.45 examples/s]Grouping texts in chunks of 512 (num_proc=6):   2%|▏         | 40000/2105244 [00:02<01:53, 18226.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):   2%|▏         | 44000/2105244 [00:02<01:43, 19926.94 examples/s]Grouping texts in chunks of 512 (num_proc=6):   2%|▏         | 46000/2105244 [00:02<01:45, 19513.51 examples/s]Grouping texts in chunks of 512 (num_proc=6):   2%|▏         | 48000/2105244 [00:02<01:52, 18242.21 examples/s]Grouping texts in chunks of 512 (num_proc=6):   2%|▏         | 51000/2105244 [00:02<01:48, 19011.69 examples/s]Grouping texts in chunks of 512 (num_proc=6):   3%|▎         | 53000/2105244 [00:03<01:48, 18852.17 examples/s]Grouping texts in chunks of 512 (num_proc=6):   3%|▎         | 57000/2105244 [00:03<01:40, 20447.27 examples/s]Grouping texts in chunks of 512 (num_proc=6):   3%|▎         | 60000/2105244 [00:03<01:56, 17485.35 examples/s]Grouping texts in chunks of 512 (num_proc=6):   3%|▎         | 64000/2105244 [00:03<01:45, 19402.69 examples/s]Grouping texts in chunks of 512 (num_proc=6):   3%|▎         | 66000/2105244 [00:03<01:52, 18192.87 examples/s]Grouping texts in chunks of 512 (num_proc=6):   3%|▎         | 70000/2105244 [00:03<01:43, 19601.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):   3%|▎         | 72000/2105244 [00:04<01:45, 19326.40 examples/s]Grouping texts in chunks of 512 (num_proc=6):   4%|▎         | 75000/2105244 [00:04<01:33, 21622.99 examples/s]Grouping texts in chunks of 512 (num_proc=6):   4%|▎         | 78000/2105244 [00:04<01:46, 19085.32 examples/s]Grouping texts in chunks of 512 (num_proc=6):   4%|▍         | 81000/2105244 [00:04<01:41, 20019.60 examples/s]Grouping texts in chunks of 512 (num_proc=6):   4%|▍         | 84000/2105244 [00:04<01:43, 19458.29 examples/s]Grouping texts in chunks of 512 (num_proc=6):   4%|▍         | 87000/2105244 [00:04<01:45, 19141.76 examples/s]Grouping texts in chunks of 512 (num_proc=6):   4%|▍         | 89000/2105244 [00:04<01:50, 18271.33 examples/s]Grouping texts in chunks of 512 (num_proc=6):   4%|▍         | 92000/2105244 [00:05<01:55, 17447.84 examples/s]Grouping texts in chunks of 512 (num_proc=6):   5%|▍         | 96000/2105244 [00:05<01:32, 21723.06 examples/s]Grouping texts in chunks of 512 (num_proc=6):   5%|▍         | 99000/2105244 [00:05<01:53, 17707.16 examples/s]Grouping texts in chunks of 512 (num_proc=6):   5%|▍         | 103000/2105244 [00:05<01:40, 19921.01 examples/s]Grouping texts in chunks of 512 (num_proc=6):   5%|▌         | 106000/2105244 [00:05<01:44, 19138.25 examples/s]Grouping texts in chunks of 512 (num_proc=6):   5%|▌         | 109000/2105244 [00:05<01:40, 19776.36 examples/s]Grouping texts in chunks of 512 (num_proc=6):   5%|▌         | 112000/2105244 [00:06<01:47, 18624.44 examples/s]Grouping texts in chunks of 512 (num_proc=6):   5%|▌         | 115000/2105244 [00:06<01:42, 19342.84 examples/s]Grouping texts in chunks of 512 (num_proc=6):   6%|▌         | 117000/2105244 [00:06<01:53, 17551.16 examples/s]Grouping texts in chunks of 512 (num_proc=6):   6%|▌         | 121000/2105244 [00:06<01:41, 19495.65 examples/s]Grouping texts in chunks of 512 (num_proc=6):   6%|▌         | 123000/2105244 [00:06<01:47, 18470.23 examples/s]Grouping texts in chunks of 512 (num_proc=6):   6%|▌         | 127000/2105244 [00:06<01:33, 21164.44 examples/s]Grouping texts in chunks of 512 (num_proc=6):   6%|▌         | 130000/2105244 [00:07<01:45, 18664.22 examples/s]Grouping texts in chunks of 512 (num_proc=6):   6%|▋         | 134000/2105244 [00:07<01:35, 20561.63 examples/s]Grouping texts in chunks of 512 (num_proc=6):   7%|▋         | 137000/2105244 [00:07<01:41, 19478.55 examples/s]Grouping texts in chunks of 512 (num_proc=6):   7%|▋         | 140000/2105244 [00:07<01:41, 19317.43 examples/s]Grouping texts in chunks of 512 (num_proc=6):   7%|▋         | 142000/2105244 [00:07<01:46, 18476.13 examples/s]Grouping texts in chunks of 512 (num_proc=6):   7%|▋         | 144000/2105244 [00:07<01:44, 18796.58 examples/s]Grouping texts in chunks of 512 (num_proc=6):   7%|▋         | 146000/2105244 [00:07<01:43, 18985.99 examples/s]Grouping texts in chunks of 512 (num_proc=6):   7%|▋         | 149000/2105244 [00:08<01:40, 19449.82 examples/s]Grouping texts in chunks of 512 (num_proc=6):   7%|▋         | 151000/2105244 [00:08<01:43, 18913.38 examples/s]Grouping texts in chunks of 512 (num_proc=6):   7%|▋         | 155000/2105244 [00:08<01:40, 19333.55 examples/s]Grouping texts in chunks of 512 (num_proc=6):   7%|▋         | 157000/2105244 [00:08<01:45, 18403.91 examples/s]Grouping texts in chunks of 512 (num_proc=6):   8%|▊         | 161000/2105244 [00:08<01:39, 19517.09 examples/s]Grouping texts in chunks of 512 (num_proc=6):   8%|▊         | 163000/2105244 [00:08<01:43, 18699.08 examples/s]Grouping texts in chunks of 512 (num_proc=6):   8%|▊         | 167000/2105244 [00:08<01:41, 19143.56 examples/s]Grouping texts in chunks of 512 (num_proc=6):   8%|▊         | 170000/2105244 [00:09<01:34, 20497.72 examples/s]Grouping texts in chunks of 512 (num_proc=6):   8%|▊         | 173000/2105244 [00:09<01:42, 18822.46 examples/s]Grouping texts in chunks of 512 (num_proc=6):   8%|▊         | 176000/2105244 [00:09<01:36, 19963.45 examples/s]Grouping texts in chunks of 512 (num_proc=6):   9%|▊         | 179000/2105244 [00:09<01:42, 18883.39 examples/s]Grouping texts in chunks of 512 (num_proc=6):   9%|▊         | 182000/2105244 [00:09<01:41, 18882.34 examples/s]Grouping texts in chunks of 512 (num_proc=6):   9%|▉         | 185000/2105244 [00:09<01:37, 19654.10 examples/s]Grouping texts in chunks of 512 (num_proc=6):   9%|▉         | 188000/2105244 [00:10<01:46, 18055.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):   9%|▉         | 192000/2105244 [00:10<01:27, 21896.56 examples/s]Grouping texts in chunks of 512 (num_proc=6):   9%|▉         | 195000/2105244 [00:10<01:45, 18167.92 examples/s]Grouping texts in chunks of 512 (num_proc=6):  10%|▉         | 200000/2105244 [00:10<01:47, 17704.76 examples/s]Grouping texts in chunks of 512 (num_proc=6):  10%|▉         | 206000/2105244 [00:10<01:39, 19114.84 examples/s]Grouping texts in chunks of 512 (num_proc=6):  10%|▉         | 210000/2105244 [00:11<01:24, 22356.34 examples/s]Grouping texts in chunks of 512 (num_proc=6):  10%|█         | 213000/2105244 [00:11<01:46, 17753.21 examples/s]Grouping texts in chunks of 512 (num_proc=6):  10%|█         | 218000/2105244 [00:11<01:46, 17664.96 examples/s]Grouping texts in chunks of 512 (num_proc=6):  11%|█         | 224000/2105244 [00:11<01:41, 18486.84 examples/s]Grouping texts in chunks of 512 (num_proc=6):  11%|█         | 230000/2105244 [00:12<01:37, 19207.77 examples/s]Grouping texts in chunks of 512 (num_proc=6):  11%|█         | 233000/2105244 [00:12<01:31, 20415.63 examples/s]Grouping texts in chunks of 512 (num_proc=6):  11%|█         | 236000/2105244 [00:12<01:38, 18926.51 examples/s]Grouping texts in chunks of 512 (num_proc=6):  11%|█▏        | 239000/2105244 [00:12<01:34, 19713.35 examples/s]Grouping texts in chunks of 512 (num_proc=6):  11%|█▏        | 242000/2105244 [00:12<01:35, 19485.53 examples/s]Grouping texts in chunks of 512 (num_proc=6):  12%|█▏        | 245000/2105244 [00:13<01:36, 19332.42 examples/s]Grouping texts in chunks of 512 (num_proc=6):  12%|█▏        | 248000/2105244 [00:13<01:32, 20132.93 examples/s]Grouping texts in chunks of 512 (num_proc=6):  12%|█▏        | 251000/2105244 [00:13<01:40, 18360.02 examples/s]Grouping texts in chunks of 512 (num_proc=6):  12%|█▏        | 255000/2105244 [00:13<01:46, 17428.17 examples/s]Grouping texts in chunks of 512 (num_proc=6):  12%|█▏        | 259000/2105244 [00:13<01:28, 20773.08 examples/s]Grouping texts in chunks of 512 (num_proc=6):  12%|█▏        | 262000/2105244 [00:13<01:46, 17234.98 examples/s]Grouping texts in chunks of 512 (num_proc=6):  13%|█▎        | 266000/2105244 [00:14<01:56, 15834.87 examples/s]Grouping texts in chunks of 512 (num_proc=6):  13%|█▎        | 271000/2105244 [00:14<01:35, 19215.66 examples/s]Grouping texts in chunks of 512 (num_proc=6):  13%|█▎        | 274000/2105244 [00:14<01:47, 17001.71 examples/s]Grouping texts in chunks of 512 (num_proc=6):  13%|█▎        | 277000/2105244 [00:14<01:42, 17756.07 examples/s]Grouping texts in chunks of 512 (num_proc=6):  13%|█▎        | 280000/2105244 [00:15<01:50, 16458.82 examples/s]Grouping texts in chunks of 512 (num_proc=6):  13%|█▎        | 283000/2105244 [00:15<01:41, 18011.13 examples/s]Grouping texts in chunks of 512 (num_proc=6):  14%|█▎        | 286000/2105244 [00:15<01:49, 16681.05 examples/s]Grouping texts in chunks of 512 (num_proc=6):  14%|█▎        | 289000/2105244 [00:15<01:36, 18813.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):  14%|█▍        | 292000/2105244 [00:15<01:38, 18331.28 examples/s]Grouping texts in chunks of 512 (num_proc=6):  14%|█▍        | 295000/2105244 [00:15<01:36, 18751.50 examples/s]Grouping texts in chunks of 512 (num_proc=6):  14%|█▍        | 298000/2105244 [00:15<01:31, 19689.03 examples/s]Grouping texts in chunks of 512 (num_proc=6):  14%|█▍        | 301000/2105244 [00:16<01:33, 19284.36 examples/s]Grouping texts in chunks of 512 (num_proc=6):  14%|█▍        | 303000/2105244 [00:16<01:36, 18688.50 examples/s]Grouping texts in chunks of 512 (num_proc=6):  14%|█▍        | 305000/2105244 [00:16<01:43, 17415.71 examples/s]Grouping texts in chunks of 512 (num_proc=6):  15%|█▍        | 308000/2105244 [00:16<01:31, 19585.64 examples/s]Grouping texts in chunks of 512 (num_proc=6):  15%|█▍        | 311000/2105244 [00:16<01:41, 17708.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):  15%|█▍        | 313000/2105244 [00:16<01:42, 17458.12 examples/s]Grouping texts in chunks of 512 (num_proc=6):  15%|█▌        | 316000/2105244 [00:16<01:31, 19466.34 examples/s]Grouping texts in chunks of 512 (num_proc=6):  15%|█▌        | 319000/2105244 [00:17<01:35, 18621.21 examples/s]Grouping texts in chunks of 512 (num_proc=6):  15%|█▌        | 322000/2105244 [00:17<01:37, 18307.86 examples/s]Grouping texts in chunks of 512 (num_proc=6):  15%|█▌        | 325000/2105244 [00:17<01:26, 20630.47 examples/s]Grouping texts in chunks of 512 (num_proc=6):  16%|█▌        | 328000/2105244 [00:17<01:42, 17389.30 examples/s]Grouping texts in chunks of 512 (num_proc=6):  16%|█▌        | 332000/2105244 [00:17<01:36, 18353.31 examples/s]Grouping texts in chunks of 512 (num_proc=6):  16%|█▌        | 334000/2105244 [00:17<01:37, 18088.16 examples/s]Grouping texts in chunks of 512 (num_proc=6):  16%|█▌        | 338000/2105244 [00:18<01:36, 18242.85 examples/s]Grouping texts in chunks of 512 (num_proc=6):  16%|█▌        | 341000/2105244 [00:18<01:29, 19796.23 examples/s]Grouping texts in chunks of 512 (num_proc=6):  16%|█▋        | 344000/2105244 [00:18<01:38, 17853.03 examples/s]Grouping texts in chunks of 512 (num_proc=6):  17%|█▋        | 348000/2105244 [00:18<01:25, 20597.10 examples/s]Grouping texts in chunks of 512 (num_proc=6):  17%|█▋        | 351000/2105244 [00:18<01:32, 19059.38 examples/s]Grouping texts in chunks of 512 (num_proc=6):  17%|█▋        | 353000/2105244 [00:18<01:32, 18952.88 examples/s]Grouping texts in chunks of 512 (num_proc=6):  17%|█▋        | 356000/2105244 [00:19<01:34, 18454.57 examples/s]Grouping texts in chunks of 512 (num_proc=6):  17%|█▋        | 359000/2105244 [00:19<01:36, 18157.28 examples/s]Grouping texts in chunks of 512 (num_proc=6):  17%|█▋        | 362000/2105244 [00:19<01:28, 19765.20 examples/s]Grouping texts in chunks of 512 (num_proc=6):  17%|█▋        | 365000/2105244 [00:19<01:36, 17954.28 examples/s]Grouping texts in chunks of 512 (num_proc=6):  18%|█▊        | 369000/2105244 [00:19<01:31, 18912.38 examples/s]Grouping texts in chunks of 512 (num_proc=6):  18%|█▊        | 371000/2105244 [00:19<01:36, 17913.40 examples/s]Grouping texts in chunks of 512 (num_proc=6):  18%|█▊        | 375000/2105244 [00:20<01:25, 20123.81 examples/s]Grouping texts in chunks of 512 (num_proc=6):  18%|█▊        | 378000/2105244 [00:20<01:29, 19318.50 examples/s]Grouping texts in chunks of 512 (num_proc=6):  18%|█▊        | 380000/2105244 [00:20<01:33, 18532.35 examples/s]Grouping texts in chunks of 512 (num_proc=6):  18%|█▊        | 383000/2105244 [00:20<01:25, 20131.11 examples/s]Grouping texts in chunks of 512 (num_proc=6):  18%|█▊        | 386000/2105244 [00:20<01:35, 18029.04 examples/s]Grouping texts in chunks of 512 (num_proc=6):  19%|█▊        | 390000/2105244 [00:20<01:35, 18050.03 examples/s]Grouping texts in chunks of 512 (num_proc=6):  19%|█▊        | 392000/2105244 [00:21<01:39, 17300.84 examples/s]Grouping texts in chunks of 512 (num_proc=6):  19%|█▉        | 396000/2105244 [00:21<01:31, 18708.76 examples/s]Grouping texts in chunks of 512 (num_proc=6):  19%|█▉        | 399000/2105244 [00:21<01:30, 18808.76 examples/s]Grouping texts in chunks of 512 (num_proc=6):  19%|█▉        | 402000/2105244 [00:21<01:31, 18561.67 examples/s]Grouping texts in chunks of 512 (num_proc=6):  19%|█▉        | 405000/2105244 [00:21<01:32, 18364.40 examples/s]Grouping texts in chunks of 512 (num_proc=6):  19%|█▉        | 408000/2105244 [00:21<01:30, 18700.47 examples/s]Grouping texts in chunks of 512 (num_proc=6):  20%|█▉        | 411000/2105244 [00:22<01:34, 17871.60 examples/s]Grouping texts in chunks of 512 (num_proc=6):  20%|█▉        | 414000/2105244 [00:22<01:27, 19397.77 examples/s]Grouping texts in chunks of 512 (num_proc=6):  20%|█▉        | 417000/2105244 [00:22<01:38, 17110.97 examples/s]Grouping texts in chunks of 512 (num_proc=6):  20%|█▉        | 421000/2105244 [00:22<01:20, 20824.80 examples/s]Grouping texts in chunks of 512 (num_proc=6):  20%|██        | 424000/2105244 [00:22<01:33, 17979.33 examples/s]Grouping texts in chunks of 512 (num_proc=6):  20%|██        | 428000/2105244 [00:22<01:18, 21264.73 examples/s]Grouping texts in chunks of 512 (num_proc=6):  20%|██        | 431000/2105244 [00:23<01:32, 18146.06 examples/s]Grouping texts in chunks of 512 (num_proc=6):  21%|██        | 434000/2105244 [00:23<01:24, 19894.21 examples/s]Grouping texts in chunks of 512 (num_proc=6):  21%|██        | 437000/2105244 [00:23<01:35, 17513.97 examples/s]Grouping texts in chunks of 512 (num_proc=6):  21%|██        | 440000/2105244 [00:23<01:27, 18935.37 examples/s]Grouping texts in chunks of 512 (num_proc=6):  21%|██        | 443000/2105244 [00:23<01:34, 17600.60 examples/s]Grouping texts in chunks of 512 (num_proc=6):  21%|██        | 446000/2105244 [00:23<01:26, 19196.51 examples/s]Grouping texts in chunks of 512 (num_proc=6):  21%|██▏       | 449000/2105244 [00:24<01:35, 17328.72 examples/s]Grouping texts in chunks of 512 (num_proc=6):  22%|██▏       | 453000/2105244 [00:24<01:33, 17579.74 examples/s]Grouping texts in chunks of 512 (num_proc=6):  22%|██▏       | 455000/2105244 [00:24<01:32, 17805.06 examples/s]Grouping texts in chunks of 512 (num_proc=6):  22%|██▏       | 459000/2105244 [00:24<01:35, 17204.49 examples/s]Grouping texts in chunks of 512 (num_proc=6):  22%|██▏       | 463000/2105244 [00:24<01:17, 21184.19 examples/s]Grouping texts in chunks of 512 (num_proc=6):  22%|██▏       | 466000/2105244 [00:24<01:29, 18316.85 examples/s]Grouping texts in chunks of 512 (num_proc=6):  22%|██▏       | 470000/2105244 [00:25<01:18, 20744.10 examples/s]Grouping texts in chunks of 512 (num_proc=6):  22%|██▏       | 473000/2105244 [00:25<01:36, 16938.66 examples/s]Grouping texts in chunks of 512 (num_proc=6):  23%|██▎       | 477000/2105244 [00:25<01:24, 19163.02 examples/s]Grouping texts in chunks of 512 (num_proc=6):  23%|██▎       | 480000/2105244 [00:25<01:28, 18307.25 examples/s]Grouping texts in chunks of 512 (num_proc=6):  23%|██▎       | 483000/2105244 [00:25<01:21, 19853.27 examples/s]Grouping texts in chunks of 512 (num_proc=6):  23%|██▎       | 486000/2105244 [00:26<01:30, 17924.89 examples/s]Grouping texts in chunks of 512 (num_proc=6):  23%|██▎       | 489000/2105244 [00:26<01:20, 20171.41 examples/s]Grouping texts in chunks of 512 (num_proc=6):  23%|██▎       | 492000/2105244 [00:26<01:33, 17304.10 examples/s]Grouping texts in chunks of 512 (num_proc=6):  24%|██▎       | 495000/2105244 [00:26<01:23, 19364.92 examples/s]Grouping texts in chunks of 512 (num_proc=6):  24%|██▎       | 498000/2105244 [00:26<01:28, 18072.12 examples/s]Grouping texts in chunks of 512 (num_proc=6):  24%|██▍       | 500000/2105244 [00:26<01:27, 18299.87 examples/s]Grouping texts in chunks of 512 (num_proc=6):  24%|██▍       | 502000/2105244 [00:26<01:28, 18050.29 examples/s]Grouping texts in chunks of 512 (num_proc=6):  24%|██▍       | 504000/2105244 [00:27<01:29, 17901.19 examples/s]Grouping texts in chunks of 512 (num_proc=6):  24%|██▍       | 507000/2105244 [00:27<01:30, 17655.40 examples/s]Grouping texts in chunks of 512 (num_proc=6):  24%|██▍       | 510000/2105244 [00:27<01:27, 18263.78 examples/s]Grouping texts in chunks of 512 (num_proc=6):  24%|██▍       | 513000/2105244 [00:27<01:30, 17651.26 examples/s]Grouping texts in chunks of 512 (num_proc=6):  24%|██▍       | 515000/2105244 [00:27<01:34, 16859.07 examples/s]Grouping texts in chunks of 512 (num_proc=6):  25%|██▍       | 519000/2105244 [00:27<01:20, 19597.62 examples/s]Grouping texts in chunks of 512 (num_proc=6):  25%|██▍       | 521000/2105244 [00:28<01:33, 17010.98 examples/s]Grouping texts in chunks of 512 (num_proc=6):  25%|██▍       | 525000/2105244 [00:28<01:15, 20848.11 examples/s]Grouping texts in chunks of 512 (num_proc=6):  25%|██▌       | 528000/2105244 [00:28<01:32, 17127.03 examples/s]Grouping texts in chunks of 512 (num_proc=6):  25%|██▌       | 532000/2105244 [00:28<01:29, 17592.67 examples/s]Grouping texts in chunks of 512 (num_proc=6):  25%|██▌       | 535000/2105244 [00:28<01:20, 19597.73 examples/s]Grouping texts in chunks of 512 (num_proc=6):  26%|██▌       | 538000/2105244 [00:28<01:30, 17380.91 examples/s]Grouping texts in chunks of 512 (num_proc=6):  26%|██▌       | 542000/2105244 [00:29<01:23, 18621.55 examples/s]Grouping texts in chunks of 512 (num_proc=6):  26%|██▌       | 544000/2105244 [00:29<01:30, 17220.89 examples/s]Grouping texts in chunks of 512 (num_proc=6):  26%|██▌       | 548000/2105244 [00:29<01:23, 18688.30 examples/s]Grouping texts in chunks of 512 (num_proc=6):  26%|██▌       | 550000/2105244 [00:29<01:27, 17704.16 examples/s]Grouping texts in chunks of 512 (num_proc=6):  26%|██▋       | 554000/2105244 [00:29<01:24, 18305.52 examples/s]Grouping texts in chunks of 512 (num_proc=6):  26%|██▋       | 556000/2105244 [00:29<01:31, 17017.19 examples/s]Grouping texts in chunks of 512 (num_proc=6):  27%|██▋       | 560000/2105244 [00:30<01:23, 18544.54 examples/s]Grouping texts in chunks of 512 (num_proc=6):  27%|██▋       | 562000/2105244 [00:30<01:27, 17620.29 examples/s]Grouping texts in chunks of 512 (num_proc=6):  27%|██▋       | 566000/2105244 [00:30<01:16, 20143.24 examples/s]Grouping texts in chunks of 512 (num_proc=6):  27%|██▋       | 569000/2105244 [00:30<01:21, 18965.01 examples/s]Grouping texts in chunks of 512 (num_proc=6):  27%|██▋       | 571000/2105244 [00:30<01:20, 19133.15 examples/s]Grouping texts in chunks of 512 (num_proc=6):  27%|██▋       | 574000/2105244 [00:30<01:23, 18424.87 examples/s]Grouping texts in chunks of 512 (num_proc=6):  27%|██▋       | 576000/2105244 [00:30<01:23, 18355.77 examples/s]Grouping texts in chunks of 512 (num_proc=6):  28%|██▊       | 579000/2105244 [00:31<01:20, 19010.81 examples/s]Grouping texts in chunks of 512 (num_proc=6):  28%|██▊       | 581000/2105244 [00:31<01:24, 18116.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):  28%|██▊       | 584000/2105244 [00:31<01:16, 19798.34 examples/s]Grouping texts in chunks of 512 (num_proc=6):  28%|██▊       | 586000/2105244 [00:31<01:17, 19725.79 examples/s]Grouping texts in chunks of 512 (num_proc=6):  28%|██▊       | 589000/2105244 [00:31<01:24, 17881.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):  28%|██▊       | 591000/2105244 [00:31<01:24, 17885.81 examples/s]Grouping texts in chunks of 512 (num_proc=6):  28%|██▊       | 594000/2105244 [00:31<01:15, 20071.29 examples/s]Grouping texts in chunks of 512 (num_proc=6):  28%|██▊       | 597000/2105244 [00:32<01:21, 18490.88 examples/s]Grouping texts in chunks of 512 (num_proc=6):  29%|██▊       | 600000/2105244 [00:32<01:16, 19596.47 examples/s]Grouping texts in chunks of 512 (num_proc=6):  29%|██▊       | 603000/2105244 [00:32<01:21, 18508.37 examples/s]Grouping texts in chunks of 512 (num_proc=6):  29%|██▉       | 606000/2105244 [00:32<01:17, 19239.85 examples/s]Grouping texts in chunks of 512 (num_proc=6):  29%|██▉       | 608000/2105244 [00:32<01:24, 17767.73 examples/s]Grouping texts in chunks of 512 (num_proc=6):  29%|██▉       | 611000/2105244 [00:32<01:15, 19763.93 examples/s]Grouping texts in chunks of 512 (num_proc=6):  29%|██▉       | 614000/2105244 [00:33<01:23, 17871.31 examples/s]Grouping texts in chunks of 512 (num_proc=6):  29%|██▉       | 617000/2105244 [00:33<01:19, 18821.53 examples/s]Grouping texts in chunks of 512 (num_proc=6):  29%|██▉       | 619000/2105244 [00:33<01:19, 18797.37 examples/s]Grouping texts in chunks of 512 (num_proc=6):  29%|██▉       | 621000/2105244 [00:33<01:23, 17853.20 examples/s]Grouping texts in chunks of 512 (num_proc=6):  30%|██▉       | 623000/2105244 [00:33<01:22, 18049.75 examples/s]Grouping texts in chunks of 512 (num_proc=6):  30%|██▉       | 626000/2105244 [00:33<01:17, 19143.11 examples/s]Grouping texts in chunks of 512 (num_proc=6):  30%|██▉       | 628000/2105244 [00:33<01:27, 16929.89 examples/s]Grouping texts in chunks of 512 (num_proc=6):  30%|███       | 632000/2105244 [00:33<01:14, 19896.32 examples/s]Grouping texts in chunks of 512 (num_proc=6):  30%|███       | 634000/2105244 [00:34<01:27, 16843.17 examples/s]Grouping texts in chunks of 512 (num_proc=6):  30%|███       | 638000/2105244 [00:34<01:11, 20461.04 examples/s]Grouping texts in chunks of 512 (num_proc=6):  30%|███       | 641000/2105244 [00:34<01:20, 18090.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):  31%|███       | 644000/2105244 [00:34<01:12, 20194.80 examples/s]Grouping texts in chunks of 512 (num_proc=6):  31%|███       | 647000/2105244 [00:34<01:21, 17802.35 examples/s]Grouping texts in chunks of 512 (num_proc=6):  31%|███       | 651000/2105244 [00:34<01:17, 18850.78 examples/s]Grouping texts in chunks of 512 (num_proc=6):  31%|███       | 653000/2105244 [00:35<01:21, 17720.11 examples/s]Grouping texts in chunks of 512 (num_proc=6):  31%|███       | 657000/2105244 [00:35<01:11, 20123.54 examples/s]Grouping texts in chunks of 512 (num_proc=6):  31%|███▏      | 660000/2105244 [00:35<01:20, 17947.58 examples/s]Grouping texts in chunks of 512 (num_proc=6):  32%|███▏      | 664000/2105244 [00:35<01:26, 16670.53 examples/s]Grouping texts in chunks of 512 (num_proc=6):  32%|███▏      | 668000/2105244 [00:35<01:09, 20681.16 examples/s]Grouping texts in chunks of 512 (num_proc=6):  32%|███▏      | 671000/2105244 [00:36<01:20, 17807.82 examples/s]Grouping texts in chunks of 512 (num_proc=6):  32%|███▏      | 675000/2105244 [00:36<01:10, 20409.45 examples/s]Grouping texts in chunks of 512 (num_proc=6):  32%|███▏      | 678000/2105244 [00:36<01:15, 18949.18 examples/s]Grouping texts in chunks of 512 (num_proc=6):  32%|███▏      | 681000/2105244 [00:36<01:14, 19023.66 examples/s]Grouping texts in chunks of 512 (num_proc=6):  32%|███▏      | 684000/2105244 [00:36<01:14, 19070.34 examples/s]Grouping texts in chunks of 512 (num_proc=6):  33%|███▎      | 687000/2105244 [00:36<01:18, 18120.91 examples/s]Grouping texts in chunks of 512 (num_proc=6):  33%|███▎      | 690000/2105244 [00:37<01:13, 19233.04 examples/s]Grouping texts in chunks of 512 (num_proc=6):  33%|███▎      | 693000/2105244 [00:37<01:10, 19909.41 examples/s]Grouping texts in chunks of 512 (num_proc=6):  33%|███▎      | 696000/2105244 [00:37<01:15, 18777.14 examples/s]Grouping texts in chunks of 512 (num_proc=6):  33%|███▎      | 698000/2105244 [00:37<01:18, 17968.20 examples/s]Grouping texts in chunks of 512 (num_proc=6):  33%|███▎      | 701000/2105244 [00:37<01:14, 18743.62 examples/s]Grouping texts in chunks of 512 (num_proc=6):  33%|███▎      | 704000/2105244 [00:37<01:20, 17485.14 examples/s]Grouping texts in chunks of 512 (num_proc=6):  34%|███▎      | 708000/2105244 [00:37<01:04, 21524.24 examples/s]Grouping texts in chunks of 512 (num_proc=6):  34%|███▍      | 711000/2105244 [00:38<01:14, 18804.56 examples/s]Grouping texts in chunks of 512 (num_proc=6):  34%|███▍      | 714000/2105244 [00:38<01:06, 21076.87 examples/s]Grouping texts in chunks of 512 (num_proc=6):  34%|███▍      | 717000/2105244 [00:38<01:06, 20820.96 examples/s]Grouping texts in chunks of 512 (num_proc=6):  34%|███▍      | 720000/2105244 [00:38<01:08, 20104.76 examples/s]Grouping texts in chunks of 512 (num_proc=6):  34%|███▍      | 723000/2105244 [00:38<01:05, 21169.47 examples/s]Grouping texts in chunks of 512 (num_proc=6):  34%|███▍      | 726000/2105244 [00:38<01:10, 19453.91 examples/s]Grouping texts in chunks of 512 (num_proc=6):  35%|███▍      | 729000/2105244 [00:39<01:05, 20909.05 examples/s]Grouping texts in chunks of 512 (num_proc=6):  35%|███▍      | 732000/2105244 [00:39<01:14, 18433.45 examples/s]Grouping texts in chunks of 512 (num_proc=6):  35%|███▍      | 735000/2105244 [00:39<01:07, 20295.92 examples/s]Grouping texts in chunks of 512 (num_proc=6):  35%|███▌      | 738000/2105244 [00:39<01:17, 17530.83 examples/s]Grouping texts in chunks of 512 (num_proc=6):  35%|███▌      | 743000/2105244 [00:39<01:13, 18489.18 examples/s]Grouping texts in chunks of 512 (num_proc=6):  35%|███▌      | 746000/2105244 [00:39<01:06, 20448.88 examples/s]Grouping texts in chunks of 512 (num_proc=6):  36%|███▌      | 749000/2105244 [00:40<01:12, 18655.55 examples/s]Grouping texts in chunks of 512 (num_proc=6):  36%|███▌      | 752000/2105244 [00:40<01:08, 19761.09 examples/s]Grouping texts in chunks of 512 (num_proc=6):  36%|███▌      | 755000/2105244 [00:40<01:11, 18966.18 examples/s]Grouping texts in chunks of 512 (num_proc=6):  36%|███▌      | 758000/2105244 [00:40<01:11, 18810.25 examples/s]Grouping texts in chunks of 512 (num_proc=6):  36%|███▌      | 762000/2105244 [00:40<01:02, 21398.77 examples/s]Grouping texts in chunks of 512 (num_proc=6):  36%|███▋      | 765000/2105244 [00:40<01:09, 19150.92 examples/s]Grouping texts in chunks of 512 (num_proc=6):  37%|███▋      | 769000/2105244 [00:41<01:02, 21409.04 examples/s]Grouping texts in chunks of 512 (num_proc=6):  37%|███▋      | 772000/2105244 [00:41<01:11, 18768.09 examples/s]Grouping texts in chunks of 512 (num_proc=6):  37%|███▋      | 776000/2105244 [00:41<01:00, 21806.74 examples/s]Grouping texts in chunks of 512 (num_proc=6):  37%|███▋      | 779000/2105244 [00:41<01:09, 19070.55 examples/s]Grouping texts in chunks of 512 (num_proc=6):  37%|███▋      | 783000/2105244 [00:41<01:17, 17087.20 examples/s]Grouping texts in chunks of 512 (num_proc=6):  37%|███▋      | 789000/2105244 [00:42<01:10, 18610.02 examples/s]Grouping texts in chunks of 512 (num_proc=6):  38%|███▊      | 794000/2105244 [00:42<00:57, 22815.69 examples/s]Grouping texts in chunks of 512 (num_proc=6):  38%|███▊      | 797000/2105244 [00:42<01:11, 18236.13 examples/s]Grouping texts in chunks of 512 (num_proc=6):  38%|███▊      | 801000/2105244 [00:42<01:00, 21396.10 examples/s]Grouping texts in chunks of 512 (num_proc=6):  38%|███▊      | 804000/2105244 [00:42<01:10, 18486.90 examples/s]Grouping texts in chunks of 512 (num_proc=6):  38%|███▊      | 808000/2105244 [00:43<01:03, 20312.10 examples/s]Grouping texts in chunks of 512 (num_proc=6):  39%|███▊      | 811000/2105244 [00:43<01:05, 19618.11 examples/s]Grouping texts in chunks of 512 (num_proc=6):  39%|███▊      | 814000/2105244 [00:43<01:02, 20551.96 examples/s]Grouping texts in chunks of 512 (num_proc=6):  39%|███▉      | 817000/2105244 [00:43<01:08, 18939.35 examples/s]Grouping texts in chunks of 512 (num_proc=6):  39%|███▉      | 820000/2105244 [00:43<01:01, 20749.00 examples/s]Grouping texts in chunks of 512 (num_proc=6):  39%|███▉      | 823000/2105244 [00:43<01:09, 18445.07 examples/s]Grouping texts in chunks of 512 (num_proc=6):  39%|███▉      | 827000/2105244 [00:43<00:59, 21362.73 examples/s]Grouping texts in chunks of 512 (num_proc=6):  39%|███▉      | 830000/2105244 [00:44<01:06, 19154.35 examples/s]Grouping texts in chunks of 512 (num_proc=6):  40%|███▉      | 833000/2105244 [00:44<01:04, 19779.79 examples/s]Grouping texts in chunks of 512 (num_proc=6):  40%|███▉      | 836000/2105244 [00:44<01:06, 19167.12 examples/s]Grouping texts in chunks of 512 (num_proc=6):  40%|███▉      | 839000/2105244 [00:44<01:08, 18618.65 examples/s]Grouping texts in chunks of 512 (num_proc=6):  40%|███▉      | 842000/2105244 [00:44<01:05, 19234.51 examples/s]Grouping texts in chunks of 512 (num_proc=6):  40%|████      | 845000/2105244 [00:44<01:04, 19524.16 examples/s]Grouping texts in chunks of 512 (num_proc=6):  40%|████      | 848000/2105244 [00:45<01:04, 19568.74 examples/s]Grouping texts in chunks of 512 (num_proc=6):  40%|████      | 850000/2105244 [00:45<01:04, 19570.41 examples/s]Grouping texts in chunks of 512 (num_proc=6):  40%|████      | 852000/2105244 [00:45<01:05, 19086.87 examples/s]Grouping texts in chunks of 512 (num_proc=6):  41%|████      | 855000/2105244 [00:45<01:00, 20668.37 examples/s]Grouping texts in chunks of 512 (num_proc=6):  41%|████      | 858000/2105244 [00:45<01:05, 19084.22 examples/s]Grouping texts in chunks of 512 (num_proc=6):  41%|████      | 862000/2105244 [00:45<00:56, 22111.02 examples/s]Grouping texts in chunks of 512 (num_proc=6):  41%|████      | 865000/2105244 [00:45<01:04, 19101.70 examples/s]Grouping texts in chunks of 512 (num_proc=6):  41%|████      | 868000/2105244 [00:46<01:00, 20615.18 examples/s]Grouping texts in chunks of 512 (num_proc=6):  41%|████▏     | 871000/2105244 [00:46<00:59, 20770.04 examples/s]Grouping texts in chunks of 512 (num_proc=6):  42%|████▏     | 874000/2105244 [00:46<01:04, 19163.62 examples/s]Grouping texts in chunks of 512 (num_proc=6):  42%|████▏     | 876000/2105244 [00:46<01:07, 18240.47 examples/s]Grouping texts in chunks of 512 (num_proc=6):  42%|████▏     | 879000/2105244 [00:46<01:06, 18561.57 examples/s]Grouping texts in chunks of 512 (num_proc=6):  42%|████▏     | 882000/2105244 [00:46<01:05, 18796.63 examples/s]Grouping texts in chunks of 512 (num_proc=6):  42%|████▏     | 885000/2105244 [00:47<01:03, 19259.75 examples/s]Grouping texts in chunks of 512 (num_proc=6):  42%|████▏     | 888000/2105244 [00:47<01:03, 19101.04 examples/s]Grouping texts in chunks of 512 (num_proc=6):  42%|████▏     | 892000/2105244 [00:47<01:04, 18924.00 examples/s]Grouping texts in chunks of 512 (num_proc=6):  43%|████▎     | 895000/2105244 [00:47<00:58, 20829.73 examples/s]Grouping texts in chunks of 512 (num_proc=6):  43%|████▎     | 898000/2105244 [00:47<01:06, 18259.98 examples/s]Grouping texts in chunks of 512 (num_proc=6):  43%|████▎     | 903000/2105244 [00:47<00:57, 20851.71 examples/s]Grouping texts in chunks of 512 (num_proc=6):  43%|████▎     | 906000/2105244 [00:48<00:59, 20069.08 examples/s]Grouping texts in chunks of 512 (num_proc=6):  43%|████▎     | 909000/2105244 [00:48<01:01, 19365.14 examples/s]Grouping texts in chunks of 512 (num_proc=6):  43%|████▎     | 911000/2105244 [00:48<01:03, 18721.52 examples/s]Grouping texts in chunks of 512 (num_proc=6):  43%|████▎     | 915000/2105244 [00:48<01:03, 18813.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):  44%|████▎     | 918000/2105244 [00:48<00:58, 20133.77 examples/s]Grouping texts in chunks of 512 (num_proc=6):  44%|████▎     | 921000/2105244 [00:48<00:57, 20710.51 examples/s]Grouping texts in chunks of 512 (num_proc=6):  44%|████▍     | 924000/2105244 [00:49<01:01, 19159.79 examples/s]Grouping texts in chunks of 512 (num_proc=6):  44%|████▍     | 928000/2105244 [00:49<01:02, 18771.17 examples/s]Grouping texts in chunks of 512 (num_proc=6):  44%|████▍     | 930000/2105244 [00:49<01:02, 18751.24 examples/s]Grouping texts in chunks of 512 (num_proc=6):  44%|████▍     | 933000/2105244 [00:49<00:55, 21028.35 examples/s]Grouping texts in chunks of 512 (num_proc=6):  44%|████▍     | 936000/2105244 [00:49<00:58, 19919.42 examples/s]Grouping texts in chunks of 512 (num_proc=6):  45%|████▍     | 939000/2105244 [00:49<01:01, 18865.49 examples/s]Grouping texts in chunks of 512 (num_proc=6):  45%|████▍     | 942000/2105244 [00:49<00:56, 20463.28 examples/s]Grouping texts in chunks of 512 (num_proc=6):  45%|████▍     | 945000/2105244 [00:50<01:03, 18335.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):  45%|████▌     | 948000/2105244 [00:50<00:59, 19481.60 examples/s]Grouping texts in chunks of 512 (num_proc=6):  45%|████▌     | 951000/2105244 [00:50<00:59, 19504.38 examples/s]Grouping texts in chunks of 512 (num_proc=6):  45%|████▌     | 954000/2105244 [00:50<01:02, 18348.49 examples/s]Grouping texts in chunks of 512 (num_proc=6):  46%|████▌     | 958000/2105244 [00:50<00:50, 22716.40 examples/s]Grouping texts in chunks of 512 (num_proc=6):  46%|████▌     | 961000/2105244 [00:50<01:01, 18620.07 examples/s]Grouping texts in chunks of 512 (num_proc=6):  46%|████▌     | 965000/2105244 [00:51<01:01, 18515.91 examples/s]Grouping texts in chunks of 512 (num_proc=6):  46%|████▌     | 968000/2105244 [00:51<00:56, 20017.82 examples/s]Grouping texts in chunks of 512 (num_proc=6):  46%|████▌     | 971000/2105244 [00:51<01:04, 17629.97 examples/s]Grouping texts in chunks of 512 (num_proc=6):  46%|████▋     | 975000/2105244 [00:51<00:52, 21725.99 examples/s]Grouping texts in chunks of 512 (num_proc=6):  46%|████▋     | 978000/2105244 [00:51<01:00, 18543.18 examples/s]Grouping texts in chunks of 512 (num_proc=6):  47%|████▋     | 982000/2105244 [00:51<00:50, 22226.98 examples/s]Grouping texts in chunks of 512 (num_proc=6):  47%|████▋     | 985000/2105244 [00:52<01:01, 18318.25 examples/s]Grouping texts in chunks of 512 (num_proc=6):  47%|████▋     | 990000/2105244 [00:52<01:01, 18180.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):  47%|████▋     | 994000/2105244 [00:52<00:53, 20847.96 examples/s]Grouping texts in chunks of 512 (num_proc=6):  47%|████▋     | 997000/2105244 [00:52<00:55, 20035.68 examples/s]Grouping texts in chunks of 512 (num_proc=6):  48%|████▊     | 1000000/2105244 [00:52<00:56, 19711.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):  48%|████▊     | 1003000/2105244 [00:53<00:53, 20601.56 examples/s]Grouping texts in chunks of 512 (num_proc=6):  48%|████▊     | 1006000/2105244 [00:53<00:58, 18757.89 examples/s]Grouping texts in chunks of 512 (num_proc=6):  48%|████▊     | 1010000/2105244 [00:53<00:59, 18539.28 examples/s]Grouping texts in chunks of 512 (num_proc=6):  48%|████▊     | 1012000/2105244 [00:53<01:00, 18080.72 examples/s]Grouping texts in chunks of 512 (num_proc=6):  48%|████▊     | 1016000/2105244 [00:53<00:52, 20838.98 examples/s]Grouping texts in chunks of 512 (num_proc=6):  48%|████▊     | 1019000/2105244 [00:53<00:56, 19150.68 examples/s]Grouping texts in chunks of 512 (num_proc=6):  49%|████▊     | 1023000/2105244 [00:54<00:52, 20652.66 examples/s]Grouping texts in chunks of 512 (num_proc=6):  49%|████▊     | 1026000/2105244 [00:54<00:56, 19187.23 examples/s]Grouping texts in chunks of 512 (num_proc=6):  49%|████▉     | 1028000/2105244 [00:54<00:57, 18821.02 examples/s]Grouping texts in chunks of 512 (num_proc=6):  49%|████▉     | 1031000/2105244 [00:54<00:51, 20728.78 examples/s]Grouping texts in chunks of 512 (num_proc=6):  49%|████▉     | 1034000/2105244 [00:54<00:57, 18567.32 examples/s]Grouping texts in chunks of 512 (num_proc=6):  49%|████▉     | 1038000/2105244 [00:54<01:00, 17504.52 examples/s]Grouping texts in chunks of 512 (num_proc=6):  50%|████▉     | 1043000/2105244 [00:55<00:47, 22561.78 examples/s]Grouping texts in chunks of 512 (num_proc=6):  50%|████▉     | 1046000/2105244 [00:55<00:55, 18982.27 examples/s]Grouping texts in chunks of 512 (num_proc=6):  50%|████▉     | 1050000/2105244 [00:55<00:54, 19468.21 examples/s]Grouping texts in chunks of 512 (num_proc=6):  50%|█████     | 1053000/2105244 [00:55<00:53, 19813.32 examples/s]Grouping texts in chunks of 512 (num_proc=6):  50%|█████     | 1056000/2105244 [00:55<00:50, 20687.98 examples/s]Grouping texts in chunks of 512 (num_proc=6):  50%|█████     | 1059000/2105244 [00:55<00:56, 18521.87 examples/s]Grouping texts in chunks of 512 (num_proc=6):  50%|█████     | 1062000/2105244 [00:56<00:55, 18671.38 examples/s]Grouping texts in chunks of 512 (num_proc=6):  51%|█████     | 1064000/2105244 [00:56<01:02, 16622.20 examples/s]Grouping texts in chunks of 512 (num_proc=6):  51%|█████     | 1067000/2105244 [00:56<00:53, 19318.32 examples/s]Grouping texts in chunks of 512 (num_proc=6):  51%|█████     | 1070000/2105244 [00:56<00:53, 19386.87 examples/s]Grouping texts in chunks of 512 (num_proc=6):  51%|█████     | 1073000/2105244 [00:56<00:52, 19578.03 examples/s]Grouping texts in chunks of 512 (num_proc=6):  51%|█████     | 1076000/2105244 [00:56<00:49, 20701.69 examples/s]Grouping texts in chunks of 512 (num_proc=6):  51%|█████▏    | 1079000/2105244 [00:56<00:53, 19126.66 examples/s]Grouping texts in chunks of 512 (num_proc=6):  51%|█████▏    | 1082000/2105244 [00:57<00:48, 21170.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):  52%|█████▏    | 1085000/2105244 [00:57<00:56, 18074.38 examples/s]Grouping texts in chunks of 512 (num_proc=6):  52%|█████▏    | 1088000/2105244 [00:57<00:55, 18242.75 examples/s]Grouping texts in chunks of 512 (num_proc=6):  52%|█████▏    | 1090000/2105244 [00:57<00:56, 17997.32 examples/s]Grouping texts in chunks of 512 (num_proc=6):  52%|█████▏    | 1093000/2105244 [00:57<00:54, 18482.14 examples/s]Grouping texts in chunks of 512 (num_proc=6):  52%|█████▏    | 1095000/2105244 [00:57<00:54, 18665.59 examples/s]Grouping texts in chunks of 512 (num_proc=6):  52%|█████▏    | 1098000/2105244 [00:57<00:49, 20165.26 examples/s]Grouping texts in chunks of 512 (num_proc=6):  52%|█████▏    | 1101000/2105244 [00:58<00:52, 19234.27 examples/s]Grouping texts in chunks of 512 (num_proc=6):  52%|█████▏    | 1103000/2105244 [00:58<00:53, 18676.73 examples/s]Grouping texts in chunks of 512 (num_proc=6):  52%|█████▏    | 1105000/2105244 [00:58<00:54, 18304.17 examples/s]Grouping texts in chunks of 512 (num_proc=6):  53%|█████▎    | 1107000/2105244 [00:58<00:56, 17812.07 examples/s]Grouping texts in chunks of 512 (num_proc=6):  53%|█████▎    | 1111000/2105244 [00:58<00:46, 21472.80 examples/s]Grouping texts in chunks of 512 (num_proc=6):  53%|█████▎    | 1114000/2105244 [00:58<00:53, 18497.02 examples/s]Grouping texts in chunks of 512 (num_proc=6):  53%|█████▎    | 1118000/2105244 [00:59<00:54, 17985.66 examples/s]Grouping texts in chunks of 512 (num_proc=6):  53%|█████▎    | 1123000/2105244 [00:59<00:44, 22176.10 examples/s]Grouping texts in chunks of 512 (num_proc=6):  53%|█████▎    | 1126000/2105244 [00:59<00:50, 19454.08 examples/s]Grouping texts in chunks of 512 (num_proc=6):  54%|█████▎    | 1129000/2105244 [00:59<00:46, 21035.46 examples/s]Grouping texts in chunks of 512 (num_proc=6):  54%|█████▍    | 1132000/2105244 [00:59<00:51, 18855.37 examples/s]Grouping texts in chunks of 512 (num_proc=6):  54%|█████▍    | 1135000/2105244 [00:59<00:49, 19690.37 examples/s]Grouping texts in chunks of 512 (num_proc=6):  54%|█████▍    | 1138000/2105244 [01:00<00:52, 18421.50 examples/s]Grouping texts in chunks of 512 (num_proc=6):  54%|█████▍    | 1140000/2105244 [01:00<00:54, 17810.51 examples/s]Grouping texts in chunks of 512 (num_proc=6):  54%|█████▍    | 1143000/2105244 [01:00<00:49, 19484.29 examples/s]Grouping texts in chunks of 512 (num_proc=6):  54%|█████▍    | 1146000/2105244 [01:00<00:48, 19670.73 examples/s]Grouping texts in chunks of 512 (num_proc=6):  55%|█████▍    | 1149000/2105244 [01:00<00:48, 19631.23 examples/s]Grouping texts in chunks of 512 (num_proc=6):  55%|█████▍    | 1151000/2105244 [01:00<00:50, 18741.99 examples/s]Grouping texts in chunks of 512 (num_proc=6):  55%|█████▍    | 1153000/2105244 [01:00<00:53, 17874.70 examples/s]Grouping texts in chunks of 512 (num_proc=6):  55%|█████▍    | 1156000/2105244 [01:00<00:47, 19927.70 examples/s]Grouping texts in chunks of 512 (num_proc=6):  55%|█████▌    | 1159000/2105244 [01:01<00:54, 17417.15 examples/s]Grouping texts in chunks of 512 (num_proc=6):  55%|█████▌    | 1164000/2105244 [01:01<00:48, 19571.00 examples/s]Grouping texts in chunks of 512 (num_proc=6):  55%|█████▌    | 1166000/2105244 [01:01<00:47, 19594.18 examples/s]Grouping texts in chunks of 512 (num_proc=6):  56%|█████▌    | 1170000/2105244 [01:01<00:46, 20077.42 examples/s]Grouping texts in chunks of 512 (num_proc=6):  56%|█████▌    | 1173000/2105244 [01:01<00:46, 20213.83 examples/s]Grouping texts in chunks of 512 (num_proc=6):  56%|█████▌    | 1177000/2105244 [01:02<00:49, 18729.21 examples/s]Grouping texts in chunks of 512 (num_proc=6):  56%|█████▌    | 1181000/2105244 [01:02<00:43, 21193.82 examples/s]Grouping texts in chunks of 512 (num_proc=6):  56%|█████▌    | 1184000/2105244 [01:02<00:46, 19664.17 examples/s]Grouping texts in chunks of 512 (num_proc=6):  56%|█████▋    | 1187000/2105244 [01:02<00:44, 20489.60 examples/s]Grouping texts in chunks of 512 (num_proc=6):  57%|█████▋    | 1190000/2105244 [01:02<00:44, 20771.96 examples/s]Grouping texts in chunks of 512 (num_proc=6):  57%|█████▋    | 1193000/2105244 [01:02<00:46, 19509.47 examples/s]Grouping texts in chunks of 512 (num_proc=6):  57%|█████▋    | 1196000/2105244 [01:02<00:43, 20925.82 examples/s]Grouping texts in chunks of 512 (num_proc=6):  57%|█████▋    | 1199000/2105244 [01:03<00:48, 18692.23 examples/s]Grouping texts in chunks of 512 (num_proc=6):  57%|█████▋    | 1202000/2105244 [01:03<00:45, 19784.21 examples/s]Grouping texts in chunks of 512 (num_proc=6):  57%|█████▋    | 1205000/2105244 [01:03<00:47, 19069.13 examples/s]Grouping texts in chunks of 512 (num_proc=6):  57%|█████▋    | 1208000/2105244 [01:03<00:48, 18338.20 examples/s]Grouping texts in chunks of 512 (num_proc=6):  57%|█████▋    | 1210000/2105244 [01:03<00:50, 17891.86 examples/s]Grouping texts in chunks of 512 (num_proc=6):  58%|█████▊    | 1214000/2105244 [01:03<00:44, 19868.88 examples/s]Grouping texts in chunks of 512 (num_proc=6):  58%|█████▊    | 1216000/2105244 [01:04<00:49, 17856.88 examples/s]Grouping texts in chunks of 512 (num_proc=6):  58%|█████▊    | 1220000/2105244 [01:04<00:39, 22183.11 examples/s]Grouping texts in chunks of 512 (num_proc=6):  58%|█████▊    | 1223000/2105244 [01:04<00:47, 18523.36 examples/s]Grouping texts in chunks of 512 (num_proc=6):  58%|█████▊    | 1227000/2105244 [01:04<00:49, 17732.20 examples/s]Grouping texts in chunks of 512 (num_proc=6):  59%|█████▊    | 1232000/2105244 [01:04<00:37, 23033.92 examples/s]Grouping texts in chunks of 512 (num_proc=6):  59%|█████▊    | 1235000/2105244 [01:05<00:45, 19096.17 examples/s]Grouping texts in chunks of 512 (num_proc=6):  59%|█████▉    | 1239000/2105244 [01:05<00:45, 19077.60 examples/s]Grouping texts in chunks of 512 (num_proc=6):  59%|█████▉    | 1242000/2105244 [01:05<00:42, 20425.64 examples/s]Grouping texts in chunks of 512 (num_proc=6):  59%|█████▉    | 1245000/2105244 [01:05<00:42, 20417.99 examples/s]Grouping texts in chunks of 512 (num_proc=6):  59%|█████▉    | 1248000/2105244 [01:05<00:46, 18580.16 examples/s]Grouping texts in chunks of 512 (num_proc=6):  59%|█████▉    | 1252000/2105244 [01:05<00:46, 18196.06 examples/s]Grouping texts in chunks of 512 (num_proc=6):  60%|█████▉    | 1255000/2105244 [01:06<00:42, 20099.53 examples/s]Grouping texts in chunks of 512 (num_proc=6):  60%|█████▉    | 1258000/2105244 [01:06<00:44, 18910.18 examples/s]Grouping texts in chunks of 512 (num_proc=6):  60%|█████▉    | 1261000/2105244 [01:06<00:43, 19285.87 examples/s]Grouping texts in chunks of 512 (num_proc=6):  60%|██████    | 1264000/2105244 [01:06<00:42, 19880.91 examples/s]Grouping texts in chunks of 512 (num_proc=6):  60%|██████    | 1267000/2105244 [01:06<00:47, 17822.89 examples/s]Grouping texts in chunks of 512 (num_proc=6):  60%|██████    | 1272000/2105244 [01:06<00:38, 21539.99 examples/s]Grouping texts in chunks of 512 (num_proc=6):  61%|██████    | 1275000/2105244 [01:07<00:43, 19023.36 examples/s]Grouping texts in chunks of 512 (num_proc=6):  61%|██████    | 1278000/2105244 [01:07<00:40, 20496.38 examples/s]Grouping texts in chunks of 512 (num_proc=6):  61%|██████    | 1281000/2105244 [01:07<00:45, 18204.57 examples/s]Grouping texts in chunks of 512 (num_proc=6):  61%|██████    | 1284000/2105244 [01:07<00:40, 20193.58 examples/s]Grouping texts in chunks of 512 (num_proc=6):  61%|██████    | 1287000/2105244 [01:07<00:46, 17680.89 examples/s]Grouping texts in chunks of 512 (num_proc=6):  61%|██████▏   | 1291000/2105244 [01:07<00:39, 20549.86 examples/s]Grouping texts in chunks of 512 (num_proc=6):  61%|██████▏   | 1294000/2105244 [01:08<00:44, 18295.15 examples/s]Grouping texts in chunks of 512 (num_proc=6):  62%|██████▏   | 1298000/2105244 [01:08<00:46, 17312.10 examples/s]Grouping texts in chunks of 512 (num_proc=6):  62%|██████▏   | 1302000/2105244 [01:08<00:38, 20858.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):  62%|██████▏   | 1305000/2105244 [01:08<00:41, 19363.29 examples/s]Grouping texts in chunks of 512 (num_proc=6):  62%|██████▏   | 1308000/2105244 [01:08<00:39, 20293.84 examples/s]Grouping texts in chunks of 512 (num_proc=6):  62%|██████▏   | 1311000/2105244 [01:08<00:40, 19821.58 examples/s]Grouping texts in chunks of 512 (num_proc=6):  62%|██████▏   | 1314000/2105244 [01:09<00:41, 19143.26 examples/s]Grouping texts in chunks of 512 (num_proc=6):  63%|██████▎   | 1317000/2105244 [01:09<00:39, 20081.82 examples/s]Grouping texts in chunks of 512 (num_proc=6):  63%|██████▎   | 1320000/2105244 [01:09<00:38, 20248.79 examples/s]Grouping texts in chunks of 512 (num_proc=6):  63%|██████▎   | 1323000/2105244 [01:09<00:39, 19759.00 examples/s]Grouping texts in chunks of 512 (num_proc=6):  63%|██████▎   | 1326000/2105244 [01:09<00:39, 19523.34 examples/s]Grouping texts in chunks of 512 (num_proc=6):  63%|██████▎   | 1329000/2105244 [01:09<00:39, 19732.20 examples/s]Grouping texts in chunks of 512 (num_proc=6):  63%|██████▎   | 1331000/2105244 [01:10<00:44, 17447.24 examples/s]Grouping texts in chunks of 512 (num_proc=6):  63%|██████▎   | 1335000/2105244 [01:10<00:35, 21603.30 examples/s]Grouping texts in chunks of 512 (num_proc=6):  64%|██████▎   | 1338000/2105244 [01:10<00:40, 18827.15 examples/s]Grouping texts in chunks of 512 (num_proc=6):  64%|██████▎   | 1341000/2105244 [01:10<00:36, 21001.39 examples/s]Grouping texts in chunks of 512 (num_proc=6):  64%|██████▍   | 1344000/2105244 [01:10<00:40, 18596.10 examples/s]Grouping texts in chunks of 512 (num_proc=6):  64%|██████▍   | 1347000/2105244 [01:10<00:38, 19890.71 examples/s]Grouping texts in chunks of 512 (num_proc=6):  64%|██████▍   | 1350000/2105244 [01:10<00:40, 18710.98 examples/s]Grouping texts in chunks of 512 (num_proc=6):  64%|██████▍   | 1353000/2105244 [01:11<00:39, 19091.87 examples/s]Grouping texts in chunks of 512 (num_proc=6):  64%|██████▍   | 1356000/2105244 [01:11<00:39, 19101.32 examples/s]Grouping texts in chunks of 512 (num_proc=6):  65%|██████▍   | 1360000/2105244 [01:11<00:37, 19881.07 examples/s]Grouping texts in chunks of 512 (num_proc=6):  65%|██████▍   | 1363000/2105244 [01:11<00:37, 19542.66 examples/s]Grouping texts in chunks of 512 (num_proc=6):  65%|██████▍   | 1366000/2105244 [01:11<00:38, 19034.52 examples/s]Grouping texts in chunks of 512 (num_proc=6):  65%|██████▌   | 1369000/2105244 [01:11<00:35, 20665.32 examples/s]Grouping texts in chunks of 512 (num_proc=6):  65%|██████▌   | 1372000/2105244 [01:12<00:40, 17965.08 examples/s]Grouping texts in chunks of 512 (num_proc=6):  65%|██████▌   | 1377000/2105244 [01:12<00:38, 19073.89 examples/s]Grouping texts in chunks of 512 (num_proc=6):  66%|██████▌   | 1379000/2105244 [01:12<00:37, 19150.98 examples/s]Grouping texts in chunks of 512 (num_proc=6):  66%|██████▌   | 1383000/2105244 [01:12<00:33, 21475.81 examples/s]Grouping texts in chunks of 512 (num_proc=6):  66%|██████▌   | 1386000/2105244 [01:12<00:38, 18834.86 examples/s]Grouping texts in chunks of 512 (num_proc=6):  66%|██████▌   | 1390000/2105244 [01:13<00:37, 19113.21 examples/s]Grouping texts in chunks of 512 (num_proc=6):  66%|██████▌   | 1392000/2105244 [01:13<00:37, 19204.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):  66%|██████▋   | 1396000/2105244 [01:13<00:37, 18719.65 examples/s]Grouping texts in chunks of 512 (num_proc=6):  66%|██████▋   | 1399000/2105244 [01:13<00:35, 19992.84 examples/s]Grouping texts in chunks of 512 (num_proc=6):  67%|██████▋   | 1402000/2105244 [01:13<00:34, 20630.15 examples/s]Grouping texts in chunks of 512 (num_proc=6):  67%|██████▋   | 1405000/2105244 [01:13<00:35, 19473.32 examples/s]Grouping texts in chunks of 512 (num_proc=6):  67%|██████▋   | 1408000/2105244 [01:13<00:33, 20588.46 examples/s]Grouping texts in chunks of 512 (num_proc=6):  67%|██████▋   | 1411000/2105244 [01:14<00:36, 19109.84 examples/s]Grouping texts in chunks of 512 (num_proc=6):  67%|██████▋   | 1414000/2105244 [01:14<00:36, 19190.88 examples/s]Grouping texts in chunks of 512 (num_proc=6):  67%|██████▋   | 1417000/2105244 [01:14<00:33, 20510.53 examples/s]Grouping texts in chunks of 512 (num_proc=6):  67%|██████▋   | 1420000/2105244 [01:14<00:37, 18128.67 examples/s]Grouping texts in chunks of 512 (num_proc=6):  68%|██████▊   | 1424000/2105244 [01:14<00:33, 20526.32 examples/s]Grouping texts in chunks of 512 (num_proc=6):  68%|██████▊   | 1427000/2105244 [01:14<00:36, 18781.11 examples/s]Grouping texts in chunks of 512 (num_proc=6):  68%|██████▊   | 1430000/2105244 [01:15<00:32, 20616.27 examples/s]Grouping texts in chunks of 512 (num_proc=6):  68%|██████▊   | 1433000/2105244 [01:15<00:35, 19152.46 examples/s]Grouping texts in chunks of 512 (num_proc=6):  68%|██████▊   | 1436000/2105244 [01:15<00:32, 20319.51 examples/s]Grouping texts in chunks of 512 (num_proc=6):  68%|██████▊   | 1439000/2105244 [01:15<00:35, 18787.82 examples/s]Grouping texts in chunks of 512 (num_proc=6):  68%|██████▊   | 1442000/2105244 [01:15<00:32, 20356.85 examples/s]Grouping texts in chunks of 512 (num_proc=6):  69%|██████▊   | 1445000/2105244 [01:15<00:35, 18839.40 examples/s]Grouping texts in chunks of 512 (num_proc=6):  69%|██████▊   | 1447000/2105244 [01:15<00:35, 18443.66 examples/s]Grouping texts in chunks of 512 (num_proc=6):  69%|██████▉   | 1450000/2105244 [01:16<00:35, 18214.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):  69%|██████▉   | 1453000/2105244 [01:16<00:35, 18419.25 examples/s]Grouping texts in chunks of 512 (num_proc=6):  69%|██████▉   | 1456000/2105244 [01:16<00:33, 19584.52 examples/s]Grouping texts in chunks of 512 (num_proc=6):  69%|██████▉   | 1459000/2105244 [01:16<00:35, 18294.58 examples/s]Grouping texts in chunks of 512 (num_proc=6):  69%|██████▉   | 1463000/2105244 [01:16<00:31, 20443.63 examples/s]Grouping texts in chunks of 512 (num_proc=6):  70%|██████▉   | 1466000/2105244 [01:16<00:31, 20004.49 examples/s]Grouping texts in chunks of 512 (num_proc=6):  70%|██████▉   | 1469000/2105244 [01:17<00:31, 19906.19 examples/s]Grouping texts in chunks of 512 (num_proc=6):  70%|██████▉   | 1472000/2105244 [01:17<00:32, 19469.24 examples/s]Grouping texts in chunks of 512 (num_proc=6):  70%|███████   | 1474000/2105244 [01:17<00:32, 19150.23 examples/s]Grouping texts in chunks of 512 (num_proc=6):  70%|███████   | 1477000/2105244 [01:17<00:31, 20183.10 examples/s]Grouping texts in chunks of 512 (num_proc=6):  70%|███████   | 1480000/2105244 [01:17<00:31, 19817.65 examples/s]Grouping texts in chunks of 512 (num_proc=6):  70%|███████   | 1483000/2105244 [01:17<00:32, 18916.23 examples/s]Grouping texts in chunks of 512 (num_proc=6):  71%|███████   | 1487000/2105244 [01:17<00:30, 20209.71 examples/s]Grouping texts in chunks of 512 (num_proc=6):  71%|███████   | 1490000/2105244 [01:18<00:31, 19771.59 examples/s]Grouping texts in chunks of 512 (num_proc=6):  71%|███████   | 1493000/2105244 [01:18<00:30, 20234.24 examples/s]Grouping texts in chunks of 512 (num_proc=6):  71%|███████   | 1496000/2105244 [01:18<00:31, 19238.26 examples/s]Grouping texts in chunks of 512 (num_proc=6):  71%|███████   | 1499000/2105244 [01:18<00:29, 20822.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):  71%|███████▏  | 1502000/2105244 [01:18<00:32, 18526.34 examples/s]Grouping texts in chunks of 512 (num_proc=6):  71%|███████▏  | 1505000/2105244 [01:18<00:29, 20627.83 examples/s]Grouping texts in chunks of 512 (num_proc=6):  72%|███████▏  | 1508000/2105244 [01:19<00:32, 18581.03 examples/s]Grouping texts in chunks of 512 (num_proc=6):  72%|███████▏  | 1511000/2105244 [01:19<00:29, 20002.19 examples/s]Grouping texts in chunks of 512 (num_proc=6):  72%|███████▏  | 1514000/2105244 [01:19<00:32, 18428.66 examples/s]Grouping texts in chunks of 512 (num_proc=6):  72%|███████▏  | 1517000/2105244 [01:19<00:29, 19972.64 examples/s]Grouping texts in chunks of 512 (num_proc=6):  72%|███████▏  | 1520000/2105244 [01:19<00:31, 18555.00 examples/s]Grouping texts in chunks of 512 (num_proc=6):  72%|███████▏  | 1523000/2105244 [01:19<00:28, 20217.67 examples/s]Grouping texts in chunks of 512 (num_proc=6):  72%|███████▏  | 1526000/2105244 [01:20<00:31, 18339.68 examples/s]Grouping texts in chunks of 512 (num_proc=6):  73%|███████▎  | 1528000/2105244 [01:20<00:31, 18320.06 examples/s]Grouping texts in chunks of 512 (num_proc=6):  73%|███████▎  | 1532000/2105244 [01:20<00:28, 20433.04 examples/s]Grouping texts in chunks of 512 (num_proc=6):  73%|███████▎  | 1535000/2105244 [01:20<00:29, 19163.29 examples/s]Grouping texts in chunks of 512 (num_proc=6):  73%|███████▎  | 1539000/2105244 [01:20<00:28, 20010.49 examples/s]Grouping texts in chunks of 512 (num_proc=6):  73%|███████▎  | 1542000/2105244 [01:20<00:28, 20052.58 examples/s]Grouping texts in chunks of 512 (num_proc=6):  73%|███████▎  | 1545000/2105244 [01:20<00:28, 19686.63 examples/s]Grouping texts in chunks of 512 (num_proc=6):  74%|███████▎  | 1548000/2105244 [01:21<00:30, 18012.12 examples/s]Grouping texts in chunks of 512 (num_proc=6):  74%|███████▎  | 1551000/2105244 [01:21<00:28, 19611.11 examples/s]Grouping texts in chunks of 512 (num_proc=6):  74%|███████▍  | 1554000/2105244 [01:21<00:31, 17639.13 examples/s]Grouping texts in chunks of 512 (num_proc=6):  74%|███████▍  | 1558000/2105244 [01:21<00:25, 21581.33 examples/s]Grouping texts in chunks of 512 (num_proc=6):  74%|███████▍  | 1561000/2105244 [01:21<00:29, 18388.36 examples/s]Grouping texts in chunks of 512 (num_proc=6):  74%|███████▍  | 1565000/2105244 [01:21<00:25, 21601.68 examples/s]Grouping texts in chunks of 512 (num_proc=6):  74%|███████▍  | 1568000/2105244 [01:22<00:28, 18657.45 examples/s]Grouping texts in chunks of 512 (num_proc=6):  75%|███████▍  | 1572000/2105244 [01:22<00:25, 21056.30 examples/s]Grouping texts in chunks of 512 (num_proc=6):  75%|███████▍  | 1575000/2105244 [01:22<00:29, 17982.55 examples/s]Grouping texts in chunks of 512 (num_proc=6):  75%|███████▌  | 1579000/2105244 [01:22<00:31, 16885.21 examples/s]Grouping texts in chunks of 512 (num_proc=6):  75%|███████▌  | 1585000/2105244 [01:23<00:28, 18263.12 examples/s]Grouping texts in chunks of 512 (num_proc=6):  76%|███████▌  | 1590000/2105244 [01:23<00:23, 21869.86 examples/s]Grouping texts in chunks of 512 (num_proc=6):  76%|███████▌  | 1593000/2105244 [01:23<00:27, 18657.70 examples/s]Grouping texts in chunks of 512 (num_proc=6):  76%|███████▌  | 1597000/2105244 [01:23<00:24, 21131.83 examples/s]Grouping texts in chunks of 512 (num_proc=6):  76%|███████▌  | 1600000/2105244 [01:23<00:26, 19327.73 examples/s]Grouping texts in chunks of 512 (num_proc=6):  76%|███████▌  | 1603000/2105244 [01:23<00:24, 20614.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):  76%|███████▋  | 1606000/2105244 [01:24<00:26, 19058.17 examples/s]Grouping texts in chunks of 512 (num_proc=6):  76%|███████▋  | 1609000/2105244 [01:24<00:26, 18843.91 examples/s]Grouping texts in chunks of 512 (num_proc=6):  77%|███████▋  | 1611000/2105244 [01:24<00:27, 17733.83 examples/s]Grouping texts in chunks of 512 (num_proc=6):  77%|███████▋  | 1615000/2105244 [01:24<00:26, 18313.43 examples/s]Grouping texts in chunks of 512 (num_proc=6):  77%|███████▋  | 1617000/2105244 [01:24<00:26, 18535.31 examples/s]Grouping texts in chunks of 512 (num_proc=6):  77%|███████▋  | 1621000/2105244 [01:24<00:25, 19112.10 examples/s]Grouping texts in chunks of 512 (num_proc=6):  77%|███████▋  | 1623000/2105244 [01:25<00:25, 18902.99 examples/s]Grouping texts in chunks of 512 (num_proc=6):  77%|███████▋  | 1625000/2105244 [01:25<00:25, 18606.76 examples/s]Grouping texts in chunks of 512 (num_proc=6):  77%|███████▋  | 1628000/2105244 [01:25<00:26, 18320.54 examples/s]Grouping texts in chunks of 512 (num_proc=6):  77%|███████▋  | 1631000/2105244 [01:25<00:23, 20002.19 examples/s]Grouping texts in chunks of 512 (num_proc=6):  78%|███████▊  | 1634000/2105244 [01:25<00:25, 18158.99 examples/s]Grouping texts in chunks of 512 (num_proc=6):  78%|███████▊  | 1637000/2105244 [01:25<00:22, 20605.66 examples/s]Grouping texts in chunks of 512 (num_proc=6):  78%|███████▊  | 1640000/2105244 [01:25<00:25, 18004.76 examples/s]Grouping texts in chunks of 512 (num_proc=6):  78%|███████▊  | 1643000/2105244 [01:26<00:23, 19775.63 examples/s]Grouping texts in chunks of 512 (num_proc=6):  78%|███████▊  | 1646000/2105244 [01:26<00:23, 19379.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):  78%|███████▊  | 1649000/2105244 [01:26<00:24, 18688.28 examples/s]Grouping texts in chunks of 512 (num_proc=6):  78%|███████▊  | 1652000/2105244 [01:26<00:23, 19454.40 examples/s]Grouping texts in chunks of 512 (num_proc=6):  79%|███████▊  | 1655000/2105244 [01:26<00:24, 18016.81 examples/s]Grouping texts in chunks of 512 (num_proc=6):  79%|███████▉  | 1658000/2105244 [01:26<00:22, 19451.22 examples/s]Grouping texts in chunks of 512 (num_proc=6):  79%|███████▉  | 1661000/2105244 [01:27<00:23, 18891.44 examples/s]Grouping texts in chunks of 512 (num_proc=6):  79%|███████▉  | 1663000/2105244 [01:27<00:23, 19123.44 examples/s]Grouping texts in chunks of 512 (num_proc=6):  79%|███████▉  | 1666000/2105244 [01:27<00:21, 20625.80 examples/s]Grouping texts in chunks of 512 (num_proc=6):  79%|███████▉  | 1669000/2105244 [01:27<00:25, 17138.94 examples/s]Grouping texts in chunks of 512 (num_proc=6):  79%|███████▉  | 1672000/2105244 [01:27<00:23, 18617.35 examples/s]Grouping texts in chunks of 512 (num_proc=6):  80%|███████▉  | 1674000/2105244 [01:27<00:23, 18520.21 examples/s]Grouping texts in chunks of 512 (num_proc=6):  80%|███████▉  | 1677000/2105244 [01:27<00:20, 20973.97 examples/s]Grouping texts in chunks of 512 (num_proc=6):  80%|███████▉  | 1680000/2105244 [01:28<00:23, 18384.91 examples/s]Grouping texts in chunks of 512 (num_proc=6):  80%|███████▉  | 1683000/2105244 [01:28<00:20, 20611.08 examples/s]Grouping texts in chunks of 512 (num_proc=6):  80%|████████  | 1686000/2105244 [01:28<00:23, 17926.70 examples/s]Grouping texts in chunks of 512 (num_proc=6):  80%|████████  | 1689000/2105244 [01:28<00:20, 20444.22 examples/s]Grouping texts in chunks of 512 (num_proc=6):  80%|████████  | 1692000/2105244 [01:28<00:23, 17688.68 examples/s]Grouping texts in chunks of 512 (num_proc=6):  81%|████████  | 1696000/2105244 [01:28<00:18, 22086.13 examples/s]Grouping texts in chunks of 512 (num_proc=6):  81%|████████  | 1699000/2105244 [01:29<00:21, 18831.85 examples/s]Grouping texts in chunks of 512 (num_proc=6):  81%|████████  | 1702000/2105244 [01:29<00:20, 19904.06 examples/s]Grouping texts in chunks of 512 (num_proc=6):  81%|████████  | 1705000/2105244 [01:29<00:21, 18319.04 examples/s]Grouping texts in chunks of 512 (num_proc=6):  81%|████████  | 1708000/2105244 [01:29<00:20, 19058.80 examples/s]Grouping texts in chunks of 512 (num_proc=6):  81%|████████▏ | 1711000/2105244 [01:29<00:20, 18959.20 examples/s]Grouping texts in chunks of 512 (num_proc=6):  81%|████████▏ | 1714000/2105244 [01:29<00:19, 20467.58 examples/s]Grouping texts in chunks of 512 (num_proc=6):  82%|████████▏ | 1717000/2105244 [01:29<00:21, 17916.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):  82%|████████▏ | 1720000/2105244 [01:30<00:19, 20115.82 examples/s]Grouping texts in chunks of 512 (num_proc=6):  82%|████████▏ | 1723000/2105244 [01:30<00:21, 17439.39 examples/s]Grouping texts in chunks of 512 (num_proc=6):  82%|████████▏ | 1727000/2105244 [01:30<00:19, 19177.39 examples/s]Grouping texts in chunks of 512 (num_proc=6):  82%|████████▏ | 1730000/2105244 [01:30<00:19, 18930.79 examples/s]Grouping texts in chunks of 512 (num_proc=6):  82%|████████▏ | 1734000/2105244 [01:30<00:19, 18867.97 examples/s]Grouping texts in chunks of 512 (num_proc=6):  82%|████████▏ | 1736000/2105244 [01:30<00:20, 18434.36 examples/s]Grouping texts in chunks of 512 (num_proc=6):  83%|████████▎ | 1740000/2105244 [01:31<00:18, 19673.78 examples/s]Grouping texts in chunks of 512 (num_proc=6):  83%|████████▎ | 1742000/2105244 [01:31<00:19, 18690.83 examples/s]Grouping texts in chunks of 512 (num_proc=6):  83%|████████▎ | 1745000/2105244 [01:31<00:17, 20858.15 examples/s]Grouping texts in chunks of 512 (num_proc=6):  83%|████████▎ | 1748000/2105244 [01:31<00:19, 17950.25 examples/s]Grouping texts in chunks of 512 (num_proc=6):  83%|████████▎ | 1750000/2105244 [01:31<00:19, 18267.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):  83%|████████▎ | 1754000/2105244 [01:31<00:19, 17876.99 examples/s]Grouping texts in chunks of 512 (num_proc=6):  84%|████████▎ | 1758000/2105244 [01:32<00:15, 21705.43 examples/s]Grouping texts in chunks of 512 (num_proc=6):  84%|████████▎ | 1761000/2105244 [01:32<00:18, 18440.51 examples/s]Grouping texts in chunks of 512 (num_proc=6):  84%|████████▍ | 1765000/2105244 [01:32<00:16, 21146.09 examples/s]Grouping texts in chunks of 512 (num_proc=6):  84%|████████▍ | 1768000/2105244 [01:32<00:18, 18592.92 examples/s]Grouping texts in chunks of 512 (num_proc=6):  84%|████████▍ | 1772000/2105244 [01:32<00:15, 21358.53 examples/s]Grouping texts in chunks of 512 (num_proc=6):  84%|████████▍ | 1775000/2105244 [01:32<00:17, 18888.80 examples/s]Grouping texts in chunks of 512 (num_proc=6):  84%|████████▍ | 1778000/2105244 [01:33<00:16, 19943.90 examples/s]Grouping texts in chunks of 512 (num_proc=6):  85%|████████▍ | 1781000/2105244 [01:33<00:17, 19026.49 examples/s]Grouping texts in chunks of 512 (num_proc=6):  85%|████████▍ | 1784000/2105244 [01:33<00:17, 18772.16 examples/s]Grouping texts in chunks of 512 (num_proc=6):  85%|████████▍ | 1786000/2105244 [01:33<00:18, 17448.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):  85%|████████▌ | 1790000/2105244 [01:33<00:16, 18944.80 examples/s]Grouping texts in chunks of 512 (num_proc=6):  85%|████████▌ | 1792000/2105244 [01:33<00:17, 17527.94 examples/s]Grouping texts in chunks of 512 (num_proc=6):  85%|████████▌ | 1795000/2105244 [01:34<00:15, 19555.29 examples/s]Grouping texts in chunks of 512 (num_proc=6):  85%|████████▌ | 1798000/2105244 [01:34<00:17, 17540.08 examples/s]Grouping texts in chunks of 512 (num_proc=6):  86%|████████▌ | 1802000/2105244 [01:34<00:13, 21974.74 examples/s]Grouping texts in chunks of 512 (num_proc=6):  86%|████████▌ | 1805000/2105244 [01:34<00:15, 18867.94 examples/s]Grouping texts in chunks of 512 (num_proc=6):  86%|████████▌ | 1809000/2105244 [01:34<00:16, 17867.70 examples/s]Grouping texts in chunks of 512 (num_proc=6):  86%|████████▌ | 1812000/2105244 [01:34<00:15, 18867.63 examples/s]Grouping texts in chunks of 512 (num_proc=6):  86%|████████▌ | 1815000/2105244 [01:35<00:14, 20206.45 examples/s]Grouping texts in chunks of 512 (num_proc=6):  86%|████████▋ | 1818000/2105244 [01:35<00:15, 18630.58 examples/s]Grouping texts in chunks of 512 (num_proc=6):  87%|████████▋ | 1822000/2105244 [01:35<00:15, 17805.84 examples/s]Grouping texts in chunks of 512 (num_proc=6):  87%|████████▋ | 1825000/2105244 [01:35<00:14, 19118.74 examples/s]Grouping texts in chunks of 512 (num_proc=6):  87%|████████▋ | 1828000/2105244 [01:35<00:16, 17259.34 examples/s]Grouping texts in chunks of 512 (num_proc=6):  87%|████████▋ | 1832000/2105244 [01:35<00:13, 20674.39 examples/s]Grouping texts in chunks of 512 (num_proc=6):  87%|████████▋ | 1835000/2105244 [01:36<00:14, 19038.26 examples/s]Grouping texts in chunks of 512 (num_proc=6):  87%|████████▋ | 1838000/2105244 [01:36<00:13, 19879.20 examples/s]Grouping texts in chunks of 512 (num_proc=6):  87%|████████▋ | 1841000/2105244 [01:36<00:13, 19194.76 examples/s]Grouping texts in chunks of 512 (num_proc=6):  88%|████████▊ | 1844000/2105244 [01:36<00:12, 20479.96 examples/s]Grouping texts in chunks of 512 (num_proc=6):  88%|████████▊ | 1847000/2105244 [01:36<00:13, 19471.64 examples/s]Grouping texts in chunks of 512 (num_proc=6):  88%|████████▊ | 1850000/2105244 [01:36<00:12, 20462.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):  88%|████████▊ | 1853000/2105244 [01:37<00:12, 19821.38 examples/s]Grouping texts in chunks of 512 (num_proc=6):  88%|████████▊ | 1856000/2105244 [01:37<00:13, 18444.98 examples/s]Grouping texts in chunks of 512 (num_proc=6):  88%|████████▊ | 1860000/2105244 [01:37<00:11, 21702.58 examples/s]Grouping texts in chunks of 512 (num_proc=6):  88%|████████▊ | 1863000/2105244 [01:37<00:13, 18572.93 examples/s]Grouping texts in chunks of 512 (num_proc=6):  89%|████████▊ | 1867000/2105244 [01:37<00:11, 20245.93 examples/s]Grouping texts in chunks of 512 (num_proc=6):  89%|████████▉ | 1870000/2105244 [01:37<00:12, 18428.70 examples/s]Grouping texts in chunks of 512 (num_proc=6):  89%|████████▉ | 1874000/2105244 [01:38<00:12, 19249.54 examples/s]Grouping texts in chunks of 512 (num_proc=6):  89%|████████▉ | 1876000/2105244 [01:38<00:12, 18705.48 examples/s]Grouping texts in chunks of 512 (num_proc=6):  89%|████████▉ | 1880000/2105244 [01:38<00:11, 19550.42 examples/s]Grouping texts in chunks of 512 (num_proc=6):  89%|████████▉ | 1882000/2105244 [01:38<00:11, 19450.32 examples/s]Grouping texts in chunks of 512 (num_proc=6):  90%|████████▉ | 1886000/2105244 [01:38<00:09, 22959.37 examples/s]Grouping texts in chunks of 512 (num_proc=6):  90%|████████▉ | 1889000/2105244 [01:38<00:11, 19119.23 examples/s]Grouping texts in chunks of 512 (num_proc=6):  90%|████████▉ | 1892874/2105244 [01:39<00:11, 19236.69 examples/s]Grouping texts in chunks of 512 (num_proc=6):  90%|█████████ | 1895874/2105244 [01:39<00:11, 18146.96 examples/s]Grouping texts in chunks of 512 (num_proc=6):  90%|█████████ | 1898874/2105244 [01:39<00:11, 17843.40 examples/s]Grouping texts in chunks of 512 (num_proc=6):  90%|█████████ | 1900874/2105244 [01:39<00:12, 16749.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):  90%|█████████ | 1903874/2105244 [01:39<00:11, 17605.68 examples/s]Grouping texts in chunks of 512 (num_proc=6):  91%|█████████ | 1905874/2105244 [01:39<00:12, 15685.14 examples/s]Grouping texts in chunks of 512 (num_proc=6):  91%|█████████ | 1908874/2105244 [01:40<00:11, 16690.93 examples/s]Grouping texts in chunks of 512 (num_proc=6):  91%|█████████ | 1910874/2105244 [01:40<00:12, 15527.22 examples/s]Grouping texts in chunks of 512 (num_proc=6):  91%|█████████ | 1913874/2105244 [01:40<00:11, 17036.53 examples/s]Grouping texts in chunks of 512 (num_proc=6):  91%|█████████ | 1915874/2105244 [01:40<00:12, 15301.13 examples/s]Grouping texts in chunks of 512 (num_proc=6):  91%|█████████ | 1917874/2105244 [01:40<00:11, 15662.57 examples/s]Grouping texts in chunks of 512 (num_proc=6):  91%|█████████ | 1919874/2105244 [01:40<00:12, 15127.96 examples/s]Grouping texts in chunks of 512 (num_proc=6):  91%|█████████▏| 1921874/2105244 [01:40<00:12, 14695.76 examples/s]Grouping texts in chunks of 512 (num_proc=6):  91%|█████████▏| 1924874/2105244 [01:41<00:11, 15235.77 examples/s]Grouping texts in chunks of 512 (num_proc=6):  92%|█████████▏| 1926874/2105244 [01:41<00:11, 15645.12 examples/s]Grouping texts in chunks of 512 (num_proc=6):  92%|█████████▏| 1929874/2105244 [01:41<00:11, 15207.79 examples/s]Grouping texts in chunks of 512 (num_proc=6):  92%|█████████▏| 1932874/2105244 [01:41<00:10, 16429.07 examples/s]Grouping texts in chunks of 512 (num_proc=6):  92%|█████████▏| 1934874/2105244 [01:41<00:11, 14891.94 examples/s]Grouping texts in chunks of 512 (num_proc=6):  92%|█████████▏| 1937874/2105244 [01:41<00:10, 15832.63 examples/s]Grouping texts in chunks of 512 (num_proc=6):  92%|█████████▏| 1939874/2105244 [01:42<00:11, 14847.38 examples/s]Grouping texts in chunks of 512 (num_proc=6):  92%|█████████▏| 1942874/2105244 [01:42<00:10, 15528.78 examples/s]Grouping texts in chunks of 512 (num_proc=6):  92%|█████████▏| 1944874/2105244 [01:42<00:10, 15254.90 examples/s]Grouping texts in chunks of 512 (num_proc=6):  93%|█████████▎| 1947874/2105244 [01:42<00:10, 15022.61 examples/s]Grouping texts in chunks of 512 (num_proc=6):  93%|█████████▎| 1949874/2105244 [01:42<00:09, 15759.80 examples/s]Grouping texts in chunks of 512 (num_proc=6):  93%|█████████▎| 1952874/2105244 [01:43<00:10, 14813.30 examples/s]Grouping texts in chunks of 512 (num_proc=6):  93%|█████████▎| 1954748/2105244 [01:43<00:09, 15375.91 examples/s]Grouping texts in chunks of 512 (num_proc=6):  93%|█████████▎| 1957748/2105244 [01:43<00:10, 14498.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):  93%|█████████▎| 1959748/2105244 [01:43<00:09, 14576.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):  93%|█████████▎| 1961748/2105244 [01:43<00:10, 13078.61 examples/s]Grouping texts in chunks of 512 (num_proc=6):  93%|█████████▎| 1963748/2105244 [01:43<00:10, 13275.15 examples/s]Grouping texts in chunks of 512 (num_proc=6):  93%|█████████▎| 1965748/2105244 [01:44<00:11, 12275.87 examples/s]Grouping texts in chunks of 512 (num_proc=6):  93%|█████████▎| 1967748/2105244 [01:44<00:10, 13208.73 examples/s]Grouping texts in chunks of 512 (num_proc=6):  94%|█████████▎| 1969748/2105244 [01:44<00:11, 11884.18 examples/s]Grouping texts in chunks of 512 (num_proc=6):  94%|█████████▎| 1971748/2105244 [01:44<00:10, 13268.17 examples/s]Grouping texts in chunks of 512 (num_proc=6):  94%|█████████▍| 1973748/2105244 [01:44<00:11, 11591.69 examples/s]Grouping texts in chunks of 512 (num_proc=6):  94%|█████████▍| 1976748/2105244 [01:44<00:09, 13742.12 examples/s]Grouping texts in chunks of 512 (num_proc=6):  94%|█████████▍| 1978748/2105244 [01:45<00:11, 11421.09 examples/s]Grouping texts in chunks of 512 (num_proc=6):  94%|█████████▍| 1981748/2105244 [01:45<00:10, 11525.72 examples/s]Grouping texts in chunks of 512 (num_proc=6):  94%|█████████▍| 1984748/2105244 [01:45<00:09, 13163.51 examples/s]Grouping texts in chunks of 512 (num_proc=6):  94%|█████████▍| 1986748/2105244 [01:45<00:10, 11797.06 examples/s]Grouping texts in chunks of 512 (num_proc=6):  94%|█████████▍| 1988748/2105244 [01:45<00:09, 12556.94 examples/s]Grouping texts in chunks of 512 (num_proc=6):  95%|█████████▍| 1990748/2105244 [01:46<00:09, 12205.90 examples/s]Grouping texts in chunks of 512 (num_proc=6):  95%|█████████▍| 1992748/2105244 [01:46<00:09, 12242.90 examples/s]Grouping texts in chunks of 512 (num_proc=6):  95%|█████████▍| 1994748/2105244 [01:46<00:08, 12387.95 examples/s]Grouping texts in chunks of 512 (num_proc=6):  95%|█████████▍| 1996748/2105244 [01:46<00:08, 12091.75 examples/s]Grouping texts in chunks of 512 (num_proc=6):  95%|█████████▍| 1998748/2105244 [01:46<00:08, 12571.51 examples/s]Grouping texts in chunks of 512 (num_proc=6):  95%|█████████▌| 2000748/2105244 [01:46<00:08, 11833.85 examples/s]Grouping texts in chunks of 512 (num_proc=6):  95%|█████████▌| 2002748/2105244 [01:47<00:08, 12187.50 examples/s]Grouping texts in chunks of 512 (num_proc=6):  95%|█████████▌| 2004748/2105244 [01:47<00:08, 11734.49 examples/s]Grouping texts in chunks of 512 (num_proc=6):  95%|█████████▌| 2006748/2105244 [01:47<00:07, 12312.77 examples/s]Grouping texts in chunks of 512 (num_proc=6):  95%|█████████▌| 2008748/2105244 [01:47<00:08, 11558.76 examples/s]Grouping texts in chunks of 512 (num_proc=6):  96%|█████████▌| 2010748/2105244 [01:47<00:07, 12676.09 examples/s]Grouping texts in chunks of 512 (num_proc=6):  96%|█████████▌| 2012748/2105244 [01:47<00:08, 11367.43 examples/s]Grouping texts in chunks of 512 (num_proc=6):  96%|█████████▌| 2014748/2105244 [01:48<00:07, 12774.40 examples/s]Grouping texts in chunks of 512 (num_proc=6):  96%|█████████▌| 2016748/2105244 [01:48<00:07, 11438.80 examples/s]Grouping texts in chunks of 512 (num_proc=6):  96%|█████████▌| 2018748/2105244 [01:48<00:06, 12994.20 examples/s]Grouping texts in chunks of 512 (num_proc=6):  96%|█████████▌| 2020748/2105244 [01:48<00:07, 11971.13 examples/s]Grouping texts in chunks of 512 (num_proc=6):  96%|█████████▌| 2022748/2105244 [01:48<00:06, 13083.57 examples/s]Grouping texts in chunks of 512 (num_proc=6):  96%|█████████▌| 2024748/2105244 [01:48<00:06, 12203.51 examples/s]Grouping texts in chunks of 512 (num_proc=6):  96%|█████████▋| 2026748/2105244 [01:48<00:05, 13115.85 examples/s]Grouping texts in chunks of 512 (num_proc=6):  96%|█████████▋| 2028748/2105244 [01:49<00:06, 12268.12 examples/s]Grouping texts in chunks of 512 (num_proc=6):  96%|█████████▋| 2030748/2105244 [01:49<00:05, 12601.13 examples/s]Grouping texts in chunks of 512 (num_proc=6):  97%|█████████▋| 2032748/2105244 [01:49<00:05, 12798.16 examples/s]Grouping texts in chunks of 512 (num_proc=6):  97%|█████████▋| 2034748/2105244 [01:49<00:05, 12566.36 examples/s]Grouping texts in chunks of 512 (num_proc=6):  97%|█████████▋| 2036622/2105244 [01:49<00:04, 13760.81 examples/s]Grouping texts in chunks of 512 (num_proc=6):  97%|█████████▋| 2038622/2105244 [01:49<00:05, 11774.37 examples/s]Grouping texts in chunks of 512 (num_proc=6):  97%|█████████▋| 2040622/2105244 [01:50<00:07, 9204.16 examples/s] Grouping texts in chunks of 512 (num_proc=6):  97%|█████████▋| 2042622/2105244 [01:50<00:05, 10815.02 examples/s]Grouping texts in chunks of 512 (num_proc=6):  97%|█████████▋| 2044622/2105244 [01:50<00:05, 10206.20 examples/s]Grouping texts in chunks of 512 (num_proc=6):  97%|█████████▋| 2046622/2105244 [01:50<00:06, 8727.82 examples/s] Grouping texts in chunks of 512 (num_proc=6):  97%|█████████▋| 2048622/2105244 [01:51<00:05, 9922.01 examples/s]Grouping texts in chunks of 512 (num_proc=6):  97%|█████████▋| 2050622/2105244 [01:51<00:05, 9466.09 examples/s]Grouping texts in chunks of 512 (num_proc=6):  98%|█████████▊| 2052622/2105244 [01:51<00:06, 8725.72 examples/s]Grouping texts in chunks of 512 (num_proc=6):  98%|█████████▊| 2054622/2105244 [01:51<00:05, 9501.16 examples/s]Grouping texts in chunks of 512 (num_proc=6):  98%|█████████▊| 2056622/2105244 [01:51<00:05, 9010.78 examples/s]Grouping texts in chunks of 512 (num_proc=6):  98%|█████████▊| 2058622/2105244 [01:52<00:05, 9168.44 examples/s]Grouping texts in chunks of 512 (num_proc=6):  98%|█████████▊| 2059622/2105244 [01:52<00:05, 8843.94 examples/s]Grouping texts in chunks of 512 (num_proc=6):  98%|█████████▊| 2061622/2105244 [01:52<00:04, 9514.22 examples/s]Grouping texts in chunks of 512 (num_proc=6):  98%|█████████▊| 2062622/2105244 [01:52<00:04, 8553.65 examples/s]Grouping texts in chunks of 512 (num_proc=6):  98%|█████████▊| 2064622/2105244 [01:52<00:04, 9961.03 examples/s]Grouping texts in chunks of 512 (num_proc=6):  98%|█████████▊| 2066622/2105244 [01:53<00:04, 9258.39 examples/s]Grouping texts in chunks of 512 (num_proc=6):  98%|█████████▊| 2068622/2105244 [01:53<00:04, 8158.69 examples/s]Grouping texts in chunks of 512 (num_proc=6):  98%|█████████▊| 2071622/2105244 [01:53<00:03, 8478.75 examples/s]Grouping texts in chunks of 512 (num_proc=6):  99%|█████████▊| 2074496/2105244 [01:54<00:03, 8501.07 examples/s]Grouping texts in chunks of 512 (num_proc=6):  99%|█████████▊| 2077496/2105244 [01:54<00:03, 8570.16 examples/s]Grouping texts in chunks of 512 (num_proc=6):  99%|█████████▉| 2079496/2105244 [01:54<00:03, 7754.52 examples/s]Grouping texts in chunks of 512 (num_proc=6):  99%|█████████▉| 2081496/2105244 [01:55<00:03, 7219.17 examples/s]Grouping texts in chunks of 512 (num_proc=6):  99%|█████████▉| 2083496/2105244 [01:55<00:03, 6895.61 examples/s]Grouping texts in chunks of 512 (num_proc=6):  99%|█████████▉| 2085496/2105244 [01:55<00:02, 6658.18 examples/s]Grouping texts in chunks of 512 (num_proc=6):  99%|█████████▉| 2087496/2105244 [01:56<00:02, 6450.54 examples/s]Grouping texts in chunks of 512 (num_proc=6):  99%|█████████▉| 2089496/2105244 [01:56<00:02, 6382.02 examples/s]Grouping texts in chunks of 512 (num_proc=6):  99%|█████████▉| 2091496/2105244 [01:56<00:02, 6314.23 examples/s]Grouping texts in chunks of 512 (num_proc=6):  99%|█████████▉| 2093496/2105244 [01:56<00:01, 6290.33 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|█████████▉| 2095370/2105244 [01:57<00:01, 6295.48 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|█████████▉| 2097370/2105244 [01:57<00:01, 6000.57 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|█████████▉| 2098370/2105244 [01:57<00:01, 5124.42 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|█████████▉| 2099370/2105244 [01:58<00:01, 4565.29 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|█████████▉| 2100370/2105244 [01:58<00:01, 4127.99 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|█████████▉| 2101370/2105244 [01:58<00:01, 3765.01 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|█████████▉| 2102370/2105244 [01:59<00:00, 3552.33 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|█████████▉| 2103370/2105244 [01:59<00:00, 3389.67 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|█████████▉| 2104370/2105244 [01:59<00:00, 3280.22 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|██████████| 2105244/2105244 [02:00<00:00, 3207.56 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|██████████| 2105244/2105244 [02:00<00:00, 17438.00 examples/s]
Concatenating 6 shards
01/05/2026 14:38:07 - INFO - datasets.arrow_dataset - Concatenating 6 shards
Process #0 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00000_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Process #0 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00000_of_00006.arrow
Process #1 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00001_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Process #1 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00001_of_00006.arrow
Process #2 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00002_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Process #2 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00002_of_00006.arrow
Process #3 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00003_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Process #3 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00003_of_00006.arrow
Process #4 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00004_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Process #4 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00004_of_00006.arrow
Process #5 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00005_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Process #5 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00005_of_00006.arrow
Spawning 6 processes
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Spawning 6 processes
Grouping texts in chunks of 512 (num_proc=6):   0%|          | 0/3000 [00:00<?, ? examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00004_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00004_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00000_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00000_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00005_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00005_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00001_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00001_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00002_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00002_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00003_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/validation/cache-6d79dc68332bfbba_00003_of_00006.arrow
Grouping texts in chunks of 512 (num_proc=6):  17%|█▋        | 500/3000 [00:00<00:01, 2077.29 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|██████████| 3000/3000 [00:00<00:00, 7793.42 examples/s]
Concatenating 6 shards
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Concatenating 6 shards
Process #0 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00000_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Process #0 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00000_of_00006.arrow
Process #1 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00001_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Process #1 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00001_of_00006.arrow
Process #2 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00002_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Process #2 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00002_of_00006.arrow
Process #3 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00003_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Process #3 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00003_of_00006.arrow
Process #4 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00004_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Process #4 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00004_of_00006.arrow
Process #5 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00005_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Process #5 will write at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00005_of_00006.arrow
Spawning 6 processes
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Spawning 6 processes
Grouping texts in chunks of 512 (num_proc=6):   0%|          | 0/282635 [00:00<?, ? examples/s]Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00000_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00000_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00004_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00004_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00002_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00002_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00001_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00001_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00003_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00003_of_00006.arrow
Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00005_of_00006.arrow
01/05/2026 14:38:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/work/prompt/dpc/dataset/arxiv_oai_splits_2024-05/test/cache-680a20396d827bc0_00005_of_00006.arrow
Grouping texts in chunks of 512 (num_proc=6):   0%|          | 1000/282635 [00:00<01:52, 2493.59 examples/s]Grouping texts in chunks of 512 (num_proc=6):   2%|▏         | 7000/282635 [00:00<00:26, 10598.66 examples/s]Grouping texts in chunks of 512 (num_proc=6):   5%|▍         | 13000/282635 [00:01<00:19, 13777.05 examples/s]Grouping texts in chunks of 512 (num_proc=6):   7%|▋         | 19000/282635 [00:01<00:17, 15116.40 examples/s]Grouping texts in chunks of 512 (num_proc=6):   9%|▉         | 25000/282635 [00:01<00:16, 16076.04 examples/s]Grouping texts in chunks of 512 (num_proc=6):  11%|█         | 31000/282635 [00:02<00:15, 16544.10 examples/s]Grouping texts in chunks of 512 (num_proc=6):  13%|█▎        | 37000/282635 [00:02<00:14, 16740.80 examples/s]Grouping texts in chunks of 512 (num_proc=6):  15%|█▌        | 43000/282635 [00:02<00:13, 17179.69 examples/s]Grouping texts in chunks of 512 (num_proc=6):  17%|█▋        | 48000/282635 [00:02<00:11, 20920.99 examples/s]Grouping texts in chunks of 512 (num_proc=6):  18%|█▊        | 51000/282635 [00:03<00:12, 18028.29 examples/s]Grouping texts in chunks of 512 (num_proc=6):  19%|█▉        | 55000/282635 [00:03<00:14, 16227.57 examples/s]Grouping texts in chunks of 512 (num_proc=6):  21%|██        | 60000/282635 [00:03<00:10, 20370.30 examples/s]Grouping texts in chunks of 512 (num_proc=6):  22%|██▏       | 63000/282635 [00:03<00:12, 17664.75 examples/s]Grouping texts in chunks of 512 (num_proc=6):  24%|██▎       | 67000/282635 [00:04<00:13, 16394.05 examples/s]Grouping texts in chunks of 512 (num_proc=6):  25%|██▌       | 72000/282635 [00:04<00:10, 19789.68 examples/s]Grouping texts in chunks of 512 (num_proc=6):  27%|██▋       | 75000/282635 [00:04<00:12, 17272.69 examples/s]Grouping texts in chunks of 512 (num_proc=6):  28%|██▊       | 79000/282635 [00:05<00:16, 12629.33 examples/s]Grouping texts in chunks of 512 (num_proc=6):  29%|██▉       | 83000/282635 [00:05<00:12, 15707.09 examples/s]Grouping texts in chunks of 512 (num_proc=6):  30%|███       | 86000/282635 [00:05<00:13, 14096.00 examples/s]Grouping texts in chunks of 512 (num_proc=6):  32%|███▏      | 91000/282635 [00:05<00:12, 15235.54 examples/s]Grouping texts in chunks of 512 (num_proc=6):  34%|███▎      | 95000/282635 [00:05<00:10, 17755.50 examples/s]Grouping texts in chunks of 512 (num_proc=6):  35%|███▍      | 98000/282635 [00:06<00:12, 15332.44 examples/s]Grouping texts in chunks of 512 (num_proc=6):  36%|███▌      | 102000/282635 [00:06<00:10, 17868.47 examples/s]Grouping texts in chunks of 512 (num_proc=6):  37%|███▋      | 105000/282635 [00:06<00:10, 16793.66 examples/s]Grouping texts in chunks of 512 (num_proc=6):  38%|███▊      | 108000/282635 [00:06<00:09, 17841.64 examples/s]Grouping texts in chunks of 512 (num_proc=6):  39%|███▉      | 110000/282635 [00:06<00:10, 15823.18 examples/s]Grouping texts in chunks of 512 (num_proc=6):  40%|████      | 114000/282635 [00:06<00:09, 18252.72 examples/s]Grouping texts in chunks of 512 (num_proc=6):  41%|████      | 116000/282635 [00:07<00:10, 16100.90 examples/s]Grouping texts in chunks of 512 (num_proc=6):  42%|████▏     | 120000/282635 [00:07<00:08, 18436.57 examples/s]Grouping texts in chunks of 512 (num_proc=6):  43%|████▎     | 122000/282635 [00:07<00:09, 16316.71 examples/s]Grouping texts in chunks of 512 (num_proc=6):  45%|████▍     | 126000/282635 [00:07<00:08, 18534.01 examples/s]Grouping texts in chunks of 512 (num_proc=6):  45%|████▌     | 128000/282635 [00:07<00:09, 16245.61 examples/s]Grouping texts in chunks of 512 (num_proc=6):  47%|████▋     | 132000/282635 [00:08<00:08, 18278.93 examples/s]Grouping texts in chunks of 512 (num_proc=6):  47%|████▋     | 134000/282635 [00:08<00:09, 16432.98 examples/s]Grouping texts in chunks of 512 (num_proc=6):  49%|████▉     | 138000/282635 [00:08<00:08, 17998.70 examples/s]Grouping texts in chunks of 512 (num_proc=6):  50%|████▉     | 140000/282635 [00:08<00:08, 16661.89 examples/s]Grouping texts in chunks of 512 (num_proc=6):  51%|█████     | 144000/282635 [00:08<00:07, 18334.55 examples/s]Grouping texts in chunks of 512 (num_proc=6):  52%|█████▏    | 146000/282635 [00:08<00:08, 16661.42 examples/s]Grouping texts in chunks of 512 (num_proc=6):  53%|█████▎    | 150000/282635 [00:09<00:07, 18512.19 examples/s]Grouping texts in chunks of 512 (num_proc=6):  54%|█████▍    | 152000/282635 [00:09<00:07, 16438.15 examples/s]Grouping texts in chunks of 512 (num_proc=6):  55%|█████▌    | 156000/282635 [00:09<00:06, 18469.54 examples/s]Grouping texts in chunks of 512 (num_proc=6):  56%|█████▌    | 158000/282635 [00:09<00:07, 16728.40 examples/s]Grouping texts in chunks of 512 (num_proc=6):  57%|█████▋    | 162000/282635 [00:09<00:06, 18532.12 examples/s]Grouping texts in chunks of 512 (num_proc=6):  58%|█████▊    | 164000/282635 [00:09<00:07, 16566.79 examples/s]Grouping texts in chunks of 512 (num_proc=6):  59%|█████▉    | 168000/282635 [00:10<00:06, 18624.61 examples/s]Grouping texts in chunks of 512 (num_proc=6):  60%|██████    | 170000/282635 [00:10<00:06, 16338.08 examples/s]Grouping texts in chunks of 512 (num_proc=6):  62%|██████▏   | 174000/282635 [00:10<00:05, 18731.31 examples/s]Grouping texts in chunks of 512 (num_proc=6):  62%|██████▏   | 176000/282635 [00:10<00:06, 16559.13 examples/s]Grouping texts in chunks of 512 (num_proc=6):  64%|██████▎   | 180000/282635 [00:10<00:05, 18735.06 examples/s]Grouping texts in chunks of 512 (num_proc=6):  64%|██████▍   | 182000/282635 [00:10<00:05, 16811.51 examples/s]Grouping texts in chunks of 512 (num_proc=6):  66%|██████▌   | 186000/282635 [00:11<00:05, 18798.81 examples/s]Grouping texts in chunks of 512 (num_proc=6):  67%|██████▋   | 188000/282635 [00:11<00:05, 16727.99 examples/s]Grouping texts in chunks of 512 (num_proc=6):  68%|██████▊   | 192000/282635 [00:11<00:04, 18587.00 examples/s]Grouping texts in chunks of 512 (num_proc=6):  69%|██████▊   | 194000/282635 [00:11<00:05, 16599.86 examples/s]Grouping texts in chunks of 512 (num_proc=6):  70%|███████   | 198000/282635 [00:11<00:04, 18380.99 examples/s]Grouping texts in chunks of 512 (num_proc=6):  71%|███████   | 200000/282635 [00:11<00:04, 16555.20 examples/s]Grouping texts in chunks of 512 (num_proc=6):  72%|███████▏  | 204000/282635 [00:12<00:04, 18782.11 examples/s]Grouping texts in chunks of 512 (num_proc=6):  73%|███████▎  | 206000/282635 [00:12<00:04, 16369.49 examples/s]Grouping texts in chunks of 512 (num_proc=6):  74%|███████▍  | 210000/282635 [00:12<00:03, 18997.78 examples/s]Grouping texts in chunks of 512 (num_proc=6):  75%|███████▌  | 212000/282635 [00:12<00:04, 16494.71 examples/s]Grouping texts in chunks of 512 (num_proc=6):  76%|███████▋  | 216000/282635 [00:12<00:03, 19380.80 examples/s]Grouping texts in chunks of 512 (num_proc=6):  77%|███████▋  | 218000/282635 [00:12<00:03, 16689.40 examples/s]Grouping texts in chunks of 512 (num_proc=6):  79%|███████▊  | 222000/282635 [00:13<00:03, 19215.76 examples/s]Grouping texts in chunks of 512 (num_proc=6):  79%|███████▉  | 224000/282635 [00:13<00:03, 16621.94 examples/s]Grouping texts in chunks of 512 (num_proc=6):  81%|████████  | 228000/282635 [00:13<00:02, 19278.03 examples/s]Grouping texts in chunks of 512 (num_proc=6):  81%|████████▏ | 230000/282635 [00:13<00:03, 16666.97 examples/s]Grouping texts in chunks of 512 (num_proc=6):  83%|████████▎ | 234000/282635 [00:13<00:02, 19279.45 examples/s]Grouping texts in chunks of 512 (num_proc=6):  83%|████████▎ | 236000/282635 [00:13<00:02, 16747.92 examples/s]Grouping texts in chunks of 512 (num_proc=6):  85%|████████▍ | 240000/282635 [00:14<00:02, 19244.98 examples/s]Grouping texts in chunks of 512 (num_proc=6):  86%|████████▌ | 242000/282635 [00:14<00:02, 16582.71 examples/s]Grouping texts in chunks of 512 (num_proc=6):  87%|████████▋ | 246000/282635 [00:14<00:01, 19342.52 examples/s]Grouping texts in chunks of 512 (num_proc=6):  88%|████████▊ | 248000/282635 [00:14<00:02, 16277.00 examples/s]Grouping texts in chunks of 512 (num_proc=6):  89%|████████▉ | 252000/282635 [00:14<00:01, 19446.01 examples/s]Grouping texts in chunks of 512 (num_proc=6):  90%|█████████ | 255000/282635 [00:14<00:01, 17944.10 examples/s]Grouping texts in chunks of 512 (num_proc=6):  91%|█████████▏| 258000/282635 [00:15<00:01, 18485.62 examples/s]Grouping texts in chunks of 512 (num_proc=6):  92%|█████████▏| 260000/282635 [00:15<00:01, 16213.54 examples/s]Grouping texts in chunks of 512 (num_proc=6):  93%|█████████▎| 264000/282635 [00:15<00:01, 18428.25 examples/s]Grouping texts in chunks of 512 (num_proc=6):  94%|█████████▍| 266000/282635 [00:15<00:01, 16274.77 examples/s]Grouping texts in chunks of 512 (num_proc=6):  96%|█████████▌| 270000/282635 [00:15<00:00, 18551.30 examples/s]Grouping texts in chunks of 512 (num_proc=6):  96%|█████████▌| 272000/282635 [00:15<00:00, 16676.41 examples/s]Grouping texts in chunks of 512 (num_proc=6):  98%|█████████▊| 276000/282635 [00:16<00:00, 18658.62 examples/s]Grouping texts in chunks of 512 (num_proc=6):  98%|█████████▊| 278106/282635 [00:16<00:00, 16806.86 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|█████████▉| 281423/282635 [00:16<00:00, 19762.43 examples/s]Grouping texts in chunks of 512 (num_proc=6): 100%|██████████| 282635/282635 [00:16<00:00, 16854.03 examples/s]
Concatenating 6 shards
01/05/2026 14:38:25 - INFO - datasets.arrow_dataset - Concatenating 6 shards
Traceback (most recent call last):
  File "/home/work/prompt/dpc/autocompressor/train.py", line 292, in <module>
    main()
  File "/home/work/prompt/dpc/autocompressor/train.py", line 109, in main
    if "train" not in lm_datasets:
TypeError: argument of type 'NoneType' is not iterable
[2026-01-05 14:38:28,192] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2299368) of binary: /home/work/.conda/envs/prompt4/bin/python3.10
Traceback (most recent call last):
  File "/home/work/.conda/envs/prompt4/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/work/.conda/envs/prompt4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-01-05_14:38:28
  host      : main1
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2299368)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
